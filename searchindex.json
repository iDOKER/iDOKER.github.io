{"categories":[{"title":"使用教程","uri":"https://blog.standuke.top/categories/%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"},{"title":"内部分享","uri":"https://blog.standuke.top/categories/%E5%86%85%E9%83%A8%E5%88%86%E4%BA%AB/"},{"title":"技术分析","uri":"https://blog.standuke.top/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/"},{"title":"操作系统","uri":"https://blog.standuke.top/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"部署教程","uri":"https://blog.standuke.top/categories/%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/"},{"title":"零碎小问题","uri":"https://blog.standuke.top/categories/%E9%9B%B6%E7%A2%8E%E5%B0%8F%E9%97%AE%E9%A2%98/"}],"posts":[{"content":"👌 2021-07-06 Linux 定时单次及周期任务  FileInfo Filename - Linux 定时单次及周期任务 Version - v1.0.2107（2021/07/06 ~ 2021/07/08） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - Linux single scheduled and periodic tasks / at batch cron anacron\n 版本修订记录：\nv1.0.2107：2021-07-06：建立 Linux 定时单次及周期任务 文档，修订人：nuo\n[TOC]\n适用场景 单次任务  单一系统更新任务，例如公司产品需要指定时间更新，并且有更新脚本等保障措施，那么可以使用单次任务完成更新操作，同时结合 at 的邮件反馈机制，可以讲更新结果通过邮件告知 文件有效期，例如某文件在当日某一时刻前可供下载，过后则不允许下载。那么可以通过单次的定时操作，完成文件权限或者删除文件的操作，减少人工介入  周期任务  定期的日志文件归档、上报「系统运行状态等」 定期更新本地缓存、例如 locate 数据库信息等 定期的系统更新或者应用产品更新 「毒」某些病毒会使用 crond 来检测后台是否在运行，这也是我遇到的一个案例  注意事项 ⚠️ 所有的定期任务都是用系统时间，也就是如下输出的 Local time 作为时间标准的。请在使用定期任务时明确当前系统时间。\n \u0026gt;root ~ [vpc]# timedatectl Local time: 二 2021-06-29 13:45:54 CST Universal time: 二 2021-06-29 05:45:54 UTC RTC time: 二 2021-06-29 05:45:54 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yes NTP synchronized: yes RTC in local TZ: no DST active: n/a  ⚠️ 对于 crond 来说\n不到三小时的本地时间变化，如夏令时变化引起的时间变化，将会以如下特殊方式处理。这种处理方式只适用于在特定时间「变动的时间区间内」运行的作业，并且时间调整超过一小时，正常调度的任务会被更积极的调度。\n 如果时间向前调整一小时，那些本应在已跳过的时间间隔内运行的作业将立即运行。相反，如果时间向后调整，则相同任务只会运行一次，将避免运行两次。 超过 3 小时的时间变化被认为是对时钟或时区的更正，会立即使用新的时间。  差异总结 功能差异  at：仅执行一次，指定时间节点执行一次，错过后不会再执行 batch：仅执行一次，前提是系统负载需要够低，一般是到点且负载低于 0.8 时执行 cron：周期性执行，关机时过了时间点的任务不会再执行 anacron：执行停机期间错过的工作任务  其他差异  检查频率：at 和 batch 都是计划运行一次，cron 是按 crontab 反复运行，三者在默认情况下都是每分钟检查一次要运行的任务 其他要求：at 和 cron 是到点就触发，batch 是到点且负载值足够低（默认小于0.8）时触发 注：at 和 batch 均由 atd 负责调度（老一些的系统上是 crond 调度 atrun 再处理），cron 由 crond 调度   单次任务 at / batch  应用名：at 服务名：atd 命令行工具：at batch\n 在 CentOS 7.9 操作系统中 at 与 batch 的 man 手册相同\nat 和 batch 从标准输入或指定文件中读取命令，这些命令将在指定时间使用 /bin/sh 执行，在 at 程序下共有如下几个命令\n at：在指定时间执行命令 atq：列出当前用户的待处理作业，超级用户 root 会列出每个人的工作。输出行的格式（每个作业一行）：作业号、日期、小时、队列和用户名。 atrm：删除由作业编号标识的作业。 batch：在系统负载水平允许时批量执行命令；换句话说，当平均负载低于 0.8 或调用 atd 时指定的值时。  介绍  系统 man 手册翻译\n at 允许相当复杂的时间规范，扩展了 POSIX.2 标准。它接受 HH:MM 形式的时间以在一天中的特定时间运行作业。「如果时间已经过去，则会使用下一天的那一刻执行。」还可以指定午夜、中午或下午茶时间「下午 4 点」，并且可以设置一个以 AM 或 PM 为后缀的一天中的时间，以便在早上或晚上运行。也可以明确哪一天作业将运行，通过以月份名称日的形式给出一个带有可选年份的日期，或者给出一个形式为 MMDD[CC]YY, MM/DD/[CC]YY, DD.MM.[CC]YY or [CC]YY-MM-DD。规格日期必须遵循一天中的时间规范。还可以给出像 now + count time-units 这样的时间，其中时间单位可以是分钟、小时、天或周，也可以告诉 at 通过在时间后缀今天来运行今天的作业，并通过在时间后缀以明天来运行明天的作业。\n例如，要在三天后的下午 4 点运行作业，可以使用 at 4pm + 3 days，在 7 月 31 日上午 10:00 运行作业，可以使用 at 10am Jul 31，然后在明天凌晨 1 点运行，可以使用 at 1am tomorrow。\n时间规范的定义可以在 /usr/share/doc/at-3.1.13/timespec 中找到。\n对于 at 和批处理，从标准输入或使用 -f 选项指定的文件中读取命令并执行。工作目录、环境（变量除外） BASH_VERSINFO、DISPLAY、EUID、GROUPS、SHELLOPTS、TERM、UID 和 _) 和 umask 从调用时起保留。\n由于 at 当前作为 setuid 程序实现，因此也不会导出其他环境变量（例如 LD_LIBRARY_PATH 或 LD_PRELOAD）。这在未来可能会改变。作为解决方法，设置这些变量在您的工作中明确显示。\n从 su(1) shell 调用的 at - 或批处理 - 命令将保留当前用户 ID。用户将收到来自他的命令的标准错误和标准输出（如果有）。邮件将被发送使用命令 /usr/sbin/sendmail。如果从 su(1) shell 执行 at，登录 shell 的所有者将收到邮件。\n超级用户在任何情况下都可以使用这些命令。对于其他用户，使用 at 的权限由文件 /etc/at.allow 和 /etc/at.deny 决定。有关详细信息，请参阅 at.allow(5)。两个文件都存在有 ，则黑名单失效，只有白名单的配置生效。\nat 队列存放在 /var/spool/at 目录中，可手动进取看任务、删任务。\n安装 yum -y install at systemctl start atd.service systemctl enable atd.service  参数 -V 将版本号打印到标准错误并退出。 -q 队列：使用指定的队列。队列名称由单个字母组成，有效的队列指定范围从 a 到 z 和 A 到 Z。a 队列是 at 的默认值，b 队列是 batch 的默认值。具有更高字母的队列有更高的运行优先级。特殊队列 `=` 是为当前正在运行的作业保留的。如果将作业提交到以大写字母指定的队列，则该作业将被视为在作业时提交到 batch 处理。一旦到达时间，batch 程序匹配平均负载的处理规则。如果给 atq 一个特定的队列，它只会显示该队列中待处理的作业。 -m 在作业完成时向用户发送邮件，即使没有输出。 -M 从不向用户发送邮件。 -f file 从文件而不是标准输入读取作业。 -t time 指定作业运行时间，格式为 [[CC]YY]MMDDhhmm[.ss] -l 是 atq 的别名。 -r 是 atrm 的别名。 -d 是 atrm 的别名。 -b 是 batch 的别名。 -v 显示在读取作业之前将执行作业的时间。显示的时间格式为“Thu Feb 20 14:50:00 1997”。 -c + 作业 id 将命令行上列出的作业转换为标准输出「也就是看这个任务具体的内容」。  示例  定期删除一个文件  [root@localhost.local ~]# at 22:00 at\u0026gt; rm -rf /var/www/html/demo.txt at\u0026gt; \u0026lt;EOT\u0026gt; job 2 at Sat Jul 1 22:00:00 201 ----------------------- # 在22:10点 at 22:00 # 删除 /var/www/html/demo.txt 文件 at\u0026gt; rm -rf /var/www/html/demo.txt # Ctrl+d 结束输入 at\u0026gt; \u0026lt;EOT\u0026gt; # 提示 第二个任务在 22:00进行 job 2 at Sat Jul 1 22:00:00 201  时间写法与使用案例 # HH:MM 02:00 =\u0026gt; 在今日的 02:00 进行，若该时刻已过，则明天此时执行任务 # HH:MM YYYY-MM-DD 02:00 2021-09-20 =\u0026gt; 指定 2021 年 9 月 20 日执行任务 # HH:MM[am|pm] [Month] [Date] 04:00 pm March 17 =\u0026gt; 指定下一个 3 月 17 日下午 4:00 执行任务 17:20 tomorrow =\u0026gt; 明天的 17:20 执行任务 # HH:MM[am|pm] + number [minutes|hours|days|weeks] 在某个时间点再加几个时间后才进行该项任务 now + 5 minutes =\u0026gt; 当前时间 5 分钟后执行任务 02 pm + 3 days =\u0026gt; 3 天后的下午 2:00 执行任务  batch batch 用法与 at 一致，两者差异也只有 batch 会考虑系统负载，用的时候把 at 换成 batch 就行了。\n周期任务 cron / anacron cron  应用名：cron 系统服务：crond 命令行工具：crontab crond\n 介绍  系统 man 手册翻译\n Cron 在 /var/spool/cron 中搜索以 /etc/passwd 中的帐户命名的 crontab 文件；找到的 crontab 被加载到内存中。Cron 还搜索 /etc/anacrontab 和任何文件，所以 crontab -e 修改完后需要重启下 crond 服务。但是是否需要重启是看操作系统的，请往下看。\n有两种方法可以检查 crontables 中的更改。第一种方法是检查文件的修改时间。第二种方法是使用 inotify 支持。 inotify 的使用记录在守护进程启动后的 /var/log/cron 日志。 inotify 支持检查所有 crontables 中的更改并仅在检测到更改时访问硬盘。使用 modtime 选项时，Cron 每分钟检查其 crontables 的 modtime 以检查任何更改并重新加载已更改的 crontables。之后不需要重启Cron 一些 crontables 被修改。当 inotify 无法初始化时，也会使用 modtime 选项。\nCron 检查这些文件和目录：\n /etc/crontab  系统 crontab。现在该文件默认为空。最初它通常用于运行每日、每周、每月的工作。默认情况下，这些作业现在通过 anacron 运行，它读取\n /etc/anacrontab  后面会提到\n /etc/cron.d/  包含为不同用户存储的系统 cronjobs 的目录。\n /var/spool/cron  包含由 crontab 命令创建的用户 crontable 的目录。\n注意，在 CentOS 7.0+ 系统中只要更改 crontab，crontab 命令就会更新 spool 目录的 modtime。所以就不用重启 crond 服务。\n使用 如下为 系统任务 的编写格式，同样适用于所有的 crontab 任务编写。\n \u0026gt;root ~ [node1]# cat /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed   *(星号)  代表任何时刻都接受的意思！举例来说，范例一内那个日、月、周都是 * ， 就代表著『不论何月、何日的礼拜几的 12:00 都运行后续命令』的意思！\n ,(逗号) 代表分隔时段的意思。举例来说，如果要下达的工作是 3:00 与 6:00 时，就会是： 0 3,6 * * * command 时间参数还是有五栏，不过第二栏是 3,6 ，代表 3 与 6 都适用！ -(减号) 代表一段时间范围内，举例来说， 8 点到 12 点之间的每小时的 20 分都进行一项工作： 20 8-12 * * * command 仔细看到第二栏变成 8-12 喔！代表 8,9,10,11,12 都适用的意思！ /n(斜线) 那个 n 代表数字，亦即是『每隔 n 单位间隔』的意思，例如每五分钟进行一次，则： */5 * * * * command 很简单吧！用 * 与 /5 来搭配，也可以写成 0-59/5 ，相同意思！  普通用户 定时任务文档存放在 /var/spool/cron/demo\ncrontab -e ： 修改定时任务 crontab -l ： 查看自己的定时任务 crontab -r ： 删除所有定时任务\ncrontab -u ：只有 root 才能进行这个任务，亦即帮其他使用者创建/移除 crontab 工作排程；\n系统任务 定时任务文档存放在 /etc/crontab\n所有的修改删除等操作，直接编辑任务文档 /etc/crontab 即可，cron 会每分钟去读取一次 /etc/crontab 与 /var/spool/cron 里面的数据内容\nanacron anacron 并不需要额外的配置，使用默认值即可\n简介  系统 man 手册翻译 + 互联网资料\n Anacron 用于定期执行命令，频率以天为单位。与 cron(8) 不同，它不假设机器连续运行。因此，它可以用于不是一天 24 小时运行的机器来控制日常工作、每周工作和每月工作。\n对于每个作业，Anacron 会检查该作业是否在过去 n 天内执行过，其中 n 是为该作业指定的时间段。如果作业在 n 天或更长时间内未执行，则 Anacron 在等待指定为延迟参数的分钟数后运行作业的 shell 命令。命令退出后，Anacron 将日期（不包括小时）记录在该作业的特殊时间戳文件中，因此它知道何时再次执行该作业。\nanacron 并不是用来取代 crontab 的，anacron 存在的目的就在於我们上头提到的，在处理非 24 小时一直启动的 Linux 系统的 crontab 的运行！所以 anacron 并不能指定何时运行某项任务， 而是以天为单位或者是在启动后立刻进行 anacron 的动作，他会去侦测停机期间应该进行但是并没有进行的 crontab 任务，并将该任务运行一遍后，anacron 就会自动停止了。\n那么 anacron 又是怎么知道我们的系统啥时关机的呢？这就得要使用 anacron 读取的时间记录档 (timestamps) 了！ anacron 会去分析现在的时间与时间记录档所记载的上次运行 anacron 的时间，两者比较后若发现有差异，此时 anacron 就会开始运行未进行的 crontab 任务了！ 所以 anacron 其实也是透过 crontab 来运行的！因此 anacron 运行的时间通常有两个，一个是系统启动期间运行，一个是写入 crontab 的排程中。\n运行原理 anacron 可以理解为一个时间戳工具，判断时间是否连续，如果不连续，那么就执行下中间不连续时间的 cron 工作任务。也就是说 anacron 其实是通过 cron 来运行的，可以在 /etc/cron*/*ana* 内看到，是由 cron 来调用 anacron 来实现的\n \u0026gt;root /etc/cron.d [node1]# cat /etc/anacrontab # /etc/anacrontab: configuration file for anacron # See anacron(8) and anacrontab(5) for details. SHELL=/bin/sh PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # the maximal random delay added to the base delay of the jobs RANDOM_DELAY=45 # the jobs will be started during the following hours only START_HOURS_RANGE=3-22 #period in days delay in minutes job-identifier command 1\t5\tcron.daily\tnice run-parts /etc/cron.daily 7\t25\tcron.weekly\tnice run-parts /etc/cron.weekly @monthly 45\tcron.monthly\tnice run-parts /etc/cron.monthly   由 /etc/anacrontab 分析到 cron.daily 这项工作名称的天数为 1 天； 由 /var/spool/anacron/cron.daily 取出最近一次运行 anacron 的时间戳记； 由上个步骤与目前的时间比较，若差异天数为 1 天以上 (含 1 天)，就准备进行命令； 若准备进行命令，根据 /etc/anacrontab 的配置，将延迟 5 分钟 延迟时间过后，开始运行后续命令，亦即『 run-parts /etc/cron.daily 』这串命令； 运行完毕后， anacron 程序结束。  使用 -f 强制执行所有作业，忽略任何时间戳。 -u 将所有作业的时间戳更新为当前日期，但不运行任何作业。 -s 序列化作业的执行。 Anacron 不会在前一个工作完成之前开始新工作。 -n 立即运行作业并忽略 /etc/anacrontab 文件中的指定延迟。此选项意味着 -s。 -d 不会将 Anacron 分叉到后台。在这种模式下，Anacron 将向标准错误以及系统日志输出信息性消息。任何作业的输出都由 Anacron 邮寄。 -q 将任何消息抑制为标准错误。仅适用于 -d。 -t some_anacrontab 使用指定的 anacrontab，而不是 /etc/anacrontab 默认的。 -T Anacrontab 测试。测试 /etc/anacrontab 配置文件的有效性。如果文件中有错误，它会显示在标准输出中并且 Anacron 返回值 1。有效的 anacrontabs 返回值 0。 -S spooldir 使用指定的 spooldir 来存储时间戳。希望自己运行 anacron 的用户需要此选项。 -V 打印版本信息，然后退出。 -h 打印简短的使用信息，然后退出。   at 与 cron 权限设置 由于两者的权限配置方案极其相似，所以将两者的配置剥离出来放在一起，便于对比。\nat 在 CentOS 7.9 系统中，安装完操作系统后默认会有 /etc/at.deny 配置文件，\n at.deny  在这个 at.deny 文件内的用户则不能使用 at，没有在这个 at.deny 文件中的用户，就可使用 at，\n at.allow  同样的还有 /etc/at.allow 这个文件，写在这个文件中的使用者才能使用 at ，没有在这个文件中的使用者则不能使用 at (即使没有写在 at.deny 当中)。\n如果两个文件都存在，那么依照最小权限，仅 /etc/at.allow 用户可使用 at。 如果两个文件都不存在，那么只有 root 可使用 at。\n修改配置的话，里面一行一个用户名即可。\ncron 与 at 类似，\n在 CentOS 7.9 系统中，安装完操作系统后默认会有 /etc/cron.deny 配置文件，\n /etc/cron.deny：  在这个 cron.deny 文件内的用户则不能使用 cron，没有在这个 cron.deny 文件中的用户，就可使用 cron，\n /etc/cron.allow：  同样的还有 /etc/cron.allow 这个文件，写在这个文件中的使用者才能使用 cron ，没有在这个文件中的使用者则不能使用 cron (即使没有写在 cron.deny 当中)。\n修改配置的话，里面一行一个用户名即可。\n如果两个文件都存在，那么依照最小权限，仅 /etc/cron.allow 用户可使用 cron。 如果两个文件都不存在，那么只有 root 可使用 cron。\ndemo 用户创建了周期任务，那么 demo 的任务会记录到 /var/spool/cron/demo cron 运行的每一项工作都会被纪录到 /var/log/cron 日志中\n写在最后 说实话，这文档写的糟心，一个是网上资料太多，又太乱，没有一个是条理清楚、干干净净的；另一个是没想到有那么多要涉及到的，里面的细节还是非常多的。man 手册帮助挺大的，也总算把这几个定时任务给理了一遍。\n参考资料 http://cn.linux.vbird.org/linux_basic/0430cron.php\n","id":0,"section":"posts","summary":"👌 2021-07-06 Linux 定时单次及周期任务 FileInfo Filename - Linux 定时单次及周期任务 Version - v1.0.2107（2021/07/06 ~ 2021/07/08） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - Linux single","tags":["CentOS","Linux"],"title":"Linux 定时单次及周期任务","uri":"https://blog.standuke.top/2021/07/2021-07-06-linux-%E5%AE%9A%E6%97%B6%E5%8D%95%E6%AC%A1%E5%8F%8A%E5%91%A8%E6%9C%9F%E4%BB%BB%E5%8A%A1/","year":"2021"},{"content":"👌 2021-06-26 Linux 时间全解  FileInfo Filename - Linux 时间全解 Version - v1.1.2107（2021/06/26 ~ 2021/07/01） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - Linux time solution\n 版本修订记录：\nv1.0.2106：2021-06-26：建立 Linux 时间全解文档，修订人：nuo v1.1.2107：2021-07-01：新增 CentOS 与 Ubuntu 时间同步相关区别，修订人：nuo\n[TOC]\n简介 作为一切皆文件的 Linux 操作系统，日志的记录、定时任务的执行，甚至些许程序的配置「MySQL」也极度依赖系统时间，故系统时间在操作系统运行时尤为重要。和 Windows 一样，Linux 也分为本地时间用于手动设置和使用 ntp 方式自动同步的远程时间。\n⚠️ 值得注意的是，考虑到文件的生成也会获取系统时间作为文件的时间戳，建议在安装操作系统时就将主板上的硬件时间同步，或者在安装操作系统时手动将时间校准。\n在本文中将会涉及 CentOS 如下与时间相关的命令以及与时间相关的配置文件。同时稍有提及 Ubuntu 内的差异及其配置。\n timedatectl date chrony ntp / ntpdate  相关名词介绍 了解相关时间名词有利于理解后期相关术语的讲解，此处以 CentOS 内 timedatectl 标准输出作为样例。\n \u0026gt;root ~ [vpc]# timedatectl Local time: 二 2021-06-29 13:45:54 CST Universal time: 二 2021-06-29 05:45:54 UTC RTC time: 二 2021-06-29 05:45:54 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yes NTP synchronized: yes RTC in local TZ: no DST active: n/a   UTC 「Universal time: 二 2021-06-29 05:45:54 UTC」\n 协调世界时「UTC - Coordinated Universal Time」。地球分为二十四时区，每个时区都有自己的当地时间。在国际无线电通信场合，为了统一起见，使用一个统一的时间，称为协调世界时「UTC - Universal Time Coordinated」。\n GMT\n 格林尼治标准时间「Greenwich Mean Time Zone」。指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。「UTC 与 GMT时间基本相同」\n CTS 「Local time: 二 2021-06-29 13:45:54 CST」\n 中国标准时间「CST – China Standard Time」。GMT + 8 = UTC + 8 = CST\n DST\n 夏令时，部分国家使用，在中国不使用。所以在国外服务器配置系统时间时需要注意。\n RTC 硬件时间 「RTC time: 二 2021-06-29 05:45:54」\n RTC「Real-Time Clock」或 CMOS / BIOS 时间，一般在主板上靠电池供电，服务器断电后也会继续运行。仅保存日期时间数值，无法保存时区和夏令时设置。\n Local time 系统时间 / 本地时间 「Local time: 二 2021-06-29 13:45:54 CST」\n 服务器启动时复制 RTC 时间，之后独立运行，保存了时间、时区和夏令时设置。所以一般来说，本地的 RTC 最好保存 UTC 时间，系统时间依照操作系统内配置自己计算最终的时间。\n  ⚠️ 硬件时间「RTC」与 本地时间「Local time」  在 timedatectl set-local-rtc yes 设置为 yes 时，会出现警告。「这个地方鄙视一下 阿里云，也算是一个坑，阿里云主机硬件『RTC』时间没有使用国际上通用的 UTC 时间，而是采用当地时间……」\n# 告警如下 Warning: The system is configured to read the RTC time in the local time zone. This mode can not be fully supported. It will create various problems with time zone changes and daylight saving time adjustments. The RTC time is never updated, it relies on external facilities to maintain it. If at all possible, use RTC in UTC by calling 'timedatectl set-local-rtc 0'.  例如如果 RTC 时间与系统时间不一致，那么 MySQL 在重启或者关闭时就会报错 InnoDB: Waiting for page_cleaner to finish flushing of buffer pool，原因就是 系统时间与mysql缓存的时间不一致，这时就需要把系统时间改在 MySQL 正常运行的时间之后。再将 timedatectl set-local-rtc no 设置为 no。\n所以在配置使用 timedatectl 去修改时间时会同时配置系统时间「例如命令 date -s」和硬件时间「例如命令 hwclock -w」，而硬件时间 RTC 的具体值是否和系统时间一致则由 set-local-rtc 来配置。\n时间配置命令 timedatectl 简介 在名词介绍部分已经稍有提及 timedatectl 命令，其中的概念很关键，务必要看。\ntimedatectl 是 systemd-timedated.service 系统服务的命令行客户端，是在 RHEL7 及 CentOS7 中新增的 systemd 的一部分，用于系统时间管理。在 CentOS 7 系统上，建议使用 timedatectl 而不是 date、hwclock 命令来调整时间。在 Ubuntu 系统上，也采用 timedatectl 来管理时间，但是在 Ubuntu 系统上时间的管理流程稍有不同。\n在最新的 Ubuntu 版本中，timedatectl 替代了老旧的 ntpdate。默认情况下，timedatectl 在系统启动的时候会立刻同步时间，并在稍后网络连接激活后通过 socket 再次检查一次。如果已安装了 ntpdate / ntp，timedatectl 会退而让你使用之前的设置。这样确保了两个时间同步服务不会相互冲突，同时在你升级的时候还保留原本的行为和配置。但这也意味着从旧版本的发行版升级时ntp/ntpdate 仍会安装，因此会导致新的基于 systemd 的时间服务被禁用。\n在最新的 Ubuntu 版本中，timesyncd 替代了 ntpd 的客户端的部分。默认情况下 timesyncd 会定期检测并同步时间。它还会在本地存储更新的时间，以便在系统重启时做时间单步调整。通过 timedatectl 和 timesyncd 设置的当前时间状态和时间配置，可以使用 timedatectl status命令来进行确认。而在 CentOS 7 中，不存在 timesyncd 服务，是由 chrony 来作为 ntpd 的客户端的部分。\n CentOS 7.0 +  timedatectl -\u0026gt; systemd-timedated.service -\u0026gt; chronyd.service 「配置文件 /etc/chrony.conf」\n Ubuntu 16.04 LTS + 1  timedatectl -\u0026gt; systemd-timedated.service -\u0026gt; timesyncd.service 「配置文件 /etc/systemd/timesyncd.conf」\ntimedatectl 能做到：修改系统时间、修改 RTC 时间、修改系统时区、设置 NTP 时间同步、查看当前系统时间状态。一般来说使用 timedatectl 已经能满足日常对于时间操作的需求了。\n时间同步配置 对于时间、时区修改较为简单，这里着重介绍下 timedatectl 内的 NTP 相关原理以及配置。\n timedatectl 的 NTP 同步流程  使用 timedatectl 配置 NTP 客户端服务打开，systemd-timedated.service 收到 NTP 打开的信息，由 systemd-timedated.service 打开 chronyd.service 来启动 NTP，用于连接 服务端。timedatectl 内的 NTP 只能实现 NTP 的客户端角色，同时同步策略也较为激进「时间相差大则直接修改，相差小则慢慢追赶」，比较适合频繁启动的业务场景。\n 开启 timedatectl 的 NTP 同步  开启 timedatectl 的 NTP 同步需要系统安装 NTP 客户端「ntpd 或者 chrony，Ubuntu 还可以安装 timesyncd」，否则会有 Failed to set ntp: NTP not supported. 的报错。\ntimedatectl set-ntp true  修改配置为开启状态，再使用 timedatectl 查看 NTP enabled、NTP synchronized 同步状态即可。如果没有安装 chrony 等同步软件，可参考如下注意事项的 timedatectl 输出。\n注意事项 ⚠️ 手动安装操作系统时，会提示是否打开 NTP 时钟同步，如果选择打开那么会默认安装 chrony 相关软件用于系统时间同步，如果不打开，则不会安装 chrony，如此系统时间将不会同步。\n 安装系统时，不开启 NTP，timedatectl 的输出，也就是没有 NTP 客户端的情况。   \u0026gt;root ~ [node1]# timedatectl Local time: 六 2021-06-26 10:53:42 CST Universal time: 六 2021-06-26 02:53:42 UTC RTC time: 六 2021-06-26 10:53:26 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: n/a NTP synchronized: no RTC in local TZ: no DST active: n/a   安装系统时，开启 NTP，timedatectl 的输出   \u0026gt;root ~ [node1]# timedatectl Local time: 六 2021-06-26 11:15:36 CST Universal time: 六 2021-06-26 03:15:36 UTC RTC time: 六 2021-06-26 03:15:36 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yes NTP synchronized: yes RTC in local TZ: no DST active: n/a   如果安装系统时不开启 NTP，chrony 为后期安装，那 timedatectl 的输出如下。同时需要手动开启 NTP 同步，NTP enabled: no 才会变成 yes。   \u0026gt;root ~ [node1]# timedatectl Local time: 六 2021-06-26 11:15:36 CST Universal time: 六 2021-06-26 03:15:36 UTC RTC time: 六 2021-06-26 03:15:36 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: no NTP synchronized: no RTC in local TZ: no DST active: n/a  date 此处省略 我感觉一行命令就可以了……「网上对于 date 命令的介绍很多」\ndate +\u0026quot;%Y-%m-%d %H:%M\u0026quot;  chrony Chrony 是一个 NTP 客户端的替代品。它可以更快地同步系统时钟，时间精度更高，对于一直不在线的系统尤其有用。chronyd 较小，它使用较少的内存，只在必要时才唤醒 CPU，这样可以更好地节省电能。即使网络拥塞较长时间，它也能很好地运行同步时间。它由两个程序组成，分别是 chronyd 和 chronyc。chronyd 是一个后台运行的守护进程，用于调整内核中运行的系统时钟和时钟服务器同步。它确定计算机增减时间的比率，并对此进行补偿。chronyc 提供了一个用户界面，用于监控性能并进行多样化的配置。\n安装 chrony 软件包 yum install -y chrony  修改配置 # controller - server * + server 127.127.1.0 iburst + allow 192.168.10.0/24 # node - server * + server controller iburst  启动服务，并设置开机自启动 systemctl start chronyd \u0026amp;\u0026amp; systemctl enable chronyd  ntp 安装 ntp 软件包 yum -y install ntp  备份配置 # 配置各节点 ntpd 配置文件 cp /etc/ntp.conf{,.bak}  修改配置 # 管理节点使用本地时钟源,执行以下语句即可 cat \u0026lt;\u0026lt;EOF\u0026gt;/etc/ntp.conf driftfile /var/lib/ntp/drift restrict default kod nomodify notrap nopeer noquery restrict -6 default kod nomodify notrap nopeer noquery restrict 127.0.0.1 restrict -6 ::1 server 127.127.1.0 iburst includefile /etc/ntp/crypto/pw keys /etc/ntp/keys EOF # 其他节点的时钟源为管理节点，执行以下语句即可 cat \u0026lt;\u0026lt;EOF\u0026gt;/etc/ntp.conf driftfile /var/lib/ntp/drift restrict default kod nomodify notrap nopeer noquery restrict -6 default kod nomodify notrap nopeer noquery restrict 127.0.0.1 restrict -6 ::1 server node1 iburst includefile /etc/ntp/crypto/pw keys /etc/ntp/keys EOF  手动设置时间，写入硬件时钟\n「CentOS 7 务必使用 timedatectl 来操作」\n# 修改各节点时间,时间为当前时间 date -s \u0026quot;2019-11-30 16:07:00\u0026quot; # 写入硬件时钟 hwclock -w  启动服务，并设置开机自启动 # 各节点启动服务 systemctl start ntpd # 各节点设置开机自启动 systemctl enable ntpd  手动配置时钟 手动配置完时钟后一定要同步到硬件时钟里\ntimedatectl set-time \u0026quot;20:01:09\u0026quot;  date -s \u0026quot;20:01:09\u0026quot;  时钟同步状态校验  timedatectl  timedatectl status \u0026gt;root ~ [node1]# timedatectl status Local time: 二 2021-06-29 16:47:25 CST Universal time: 二 2021-06-29 08:47:25 UTC RTC time: 二 2021-06-29 08:47:25 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yes NTP synchronized: yes RTC in local TZ: no DST active: n/a   chrony  chronyc sources -v chronyc tracking \u0026gt;root ~ [node1]# chronyc sources -v 210 Number of sources = 4 .-- Source mode '^' = server, '=' = peer, '#' = local clock. / .- Source state '*' = current synced, '+' = combined , '-' = not combined, | / '?' = unreachable, 'x' = time may be in error, '~' = time too variable. || .- xxxx [ yyyy ] +/- zzzz || Reachability register (octal) -. | xxxx = adjusted offset, || Log2(Polling interval) --. | | yyyy = measured offset, || \\ | | zzzz = estimated error. || | | \\ MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^- tock.ntp.infomaniak.ch 1 10 377 22m +12ms[ +12ms] +/- 104ms ^* 120.25.115.20 2 10 377 307 +423us[ +432us] +/- 18ms ^- ntp1.flashdance.cx 2 10 377 664 +8908us[+8917us] +/- 154ms ^+ 119.28.183.184 2 10 337 884 -462us[ -453us] +/- 32ms   ntp  ntpq -p ntpstat  参考资料 https://www.iamhippo.com/2020-01/1306.html https://blog.csdn.net/weixin_34270606/article/details/91881851 https://ywnz.com/linuxml/5215.html https://www.cnblogs.com/opsprobe/p/13779933.html\n  Since Ubuntu 16.04 timedatectl / timesyncd (which are part of systemd) replace most of ntpdate / ntp. @ https://ubuntu.com/server/docs/network-ntp \u0026#x21a9;\u0026#xfe0e;\n   ","id":1,"section":"posts","summary":"👌 2021-06-26 Linux 时间全解 FileInfo Filename - Linux 时间全解 Version - v1.1.2107（2021/06/26 ~ 2021/07/01） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - Linux time solution 版本修订记录： v1","tags":["Linux","CentOS"],"title":"Linux 时间全解","uri":"https://blog.standuke.top/2021/06/2021-06-26-linux-%E6%97%B6%E9%97%B4%E5%85%A8%E8%A7%A3/","year":"2021"},{"content":"👌 2021-05-19 阿里云主机 EIP 致使 FTP 无法连接  上午收到了个协助工单，期间交手了两位同事都没解决掉的 ftp 奇特现象，就转到我这边了。 文中涉及到的相关 公网 IP 地址均特殊化处理\n [TOC]\n现象 Linux 使用自带 ftp 命令或者 Windows 使用资源管理器访问阿里云主机搭建的 ftp 服务，无论是主动模式还是被动模式均只能建立命令端口「21 端口」连接，无法创建数据端口连接，导致只能登录用户而不能展现文件夹以及上传下载数据。现场 21 端口使用 2100 替代。\n 表现 1  使用主动模式或者被动模式均无法显示目录信息\n 表现 2  使用 lftp 客户端或者 Windows 下的 WinSCP 软件可 正常使用 此云主机的 ftp 服务「奇怪之处」其实是 lftp 程序还支持 FXP，允许数据绕过客户端直接在两个 FTP 服务器之间传输。\n故障排查  检查 系统环境「无问题」  操作系统环境、内核信息、系统防火墙、SELinux 状态\n[root@aliyun ~]# cat /etc/redhat-release CentOS release 6.5 (Final) [root@aliyun ~]# uname -a Linux aliyun 2.6.32-696.28.1.el6.i686 #1 SMP Wed May 9 23:34:25 UTC 2018 i686 i686 i386 GNU/Linux [root@aliyun ~]# getenforce Disabled [root@aliyun ~]# service iptables status iptables: Firewall is not running.  强制修改主被动连接模式  服务端端口开放信息\n[root@aliyun ~]# netstat -antpl | grep ftp tcp 0 0 172.17.9.135:21485 0.0.0.0:* LISTEN 3756/vsftpd tcp 0 0 0.0.0.0:2100 0.0.0.0:* LISTEN 1671/vsftpd tcp 0 0 172.17.9.135:2100 125.120.45.15:54654 ESTABLISHED 3756/vsftpd  客户端端口开放信息\n \u0026gt;root ~ [Node1]# netstat -antlp | grep ftp tcp 0 0 192.168.0.130:60330 0.0.0.0:* LISTEN 3415/ftp tcp 0 0 192.168.0.130:54654 123.56.241.199:2100 ESTABLISHED 3415/ftp  此时 切换 ftp 主被动模式出现如下状态\n \u0026gt;root ~ [Node1]# ftp ftp\u0026gt; open 123.56.241.199 2100 Connected to 123.56.241.199 (123.56.241.199). 220 (vsFTPd 2.2.2) Name (123.56.241.199:root): ftpuser_1 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp\u0026gt; ls 227 Entering Passive Mode (172,17,9,135,83,237). ftp: connect: 没有到主机的路由 ftp\u0026gt; pass Passive mode off. ftp\u0026gt; ls 500 Illegal PORT command. ftp: bind: 地址已在使用 ftp\u0026gt; ls 500 Illegal PORT command.  tcpdump 抓包分析  17:01:02.917229 IP 172.17.9.135.ftp \u0026gt; 60.191.16.170.25460: Flags [P.], seq 78:97, ack 44, win 227, options [nop,nop,TS val 6760674 ecr 4083902134], length 19  简而言之，就是本地开放了 ftp 的数据端口，但是一直在侦听状态，于 第二步 出现的情况一致。\n原因分析 按照故障排查，基本可以确定问题出现在网络访问层面，且本地 ftp 工作正常「例如能够打开命令端口正常登录，正常打开数据传输接口监听连接」，只有在打开数据传输接口监听连接时，没有客户端去与其建立连接。\n所以能确定故障在 客户端无法访问服务端的数据接口\n查看云主机的 IP 信息，发现在云主机上并没有 公网 IP 地址，只有一个内网 IP 地址。所以能够确定导致此现象的原因在于阿里云内部映射公网的 NAT 机制。\n[root@aliyun ~]# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:16:3e:14:47:0f brd ff:ff:ff:ff:ff:ff inet 172.17.9.135/20 brd 172.17.15.255 scope global eth0  也就是说整体数据流思路为\n 客户端请求服务端 21 命令端口「用户可登录」 客户端请求下载文件或者展示目录信息: 客户端通过 21 端口将请求发送至服务端，服务端收到后打开本地随机端口「例如21423」作为数据端口，并把此 IP:端口 信息通过命令端口 21 发送至客户端  问题就出现在这里，这里的 IP:端口 信息，由于云主机只有内网 IP ，所以这里返回给客户端的 IP:端口信息 为 172.17.9.135:21423 而不是 123.56.241.199:21423 所以客户端当然无法访问 一个内网 IP 啦\n解决方案 阿里云对于 公网 IP 有产品叫做 EIP 弹性公网IP（Elastic IP Address，简称 EIP）支持绑定弹性网卡 ENI（Elastic Network Interface）。通过绑定弹性网卡，您可以构造出更健壮、更灵活、扩展性更强的IT解决方案，同时让单台服务器具备多个公网IP的能力。\n按照 产品设计 EIP 有以下工作模式\n 普通模式「云主机上只有一个内网 IP，通过 NAT 方式映射到公网」 EIP 网卡可见模式「云主机上能看到公网 IP，相当于直接一台公网机器」     比较点 普通模式 EIP网卡可见模式     EIP在操作系统内部的弹性网卡上是否可见 否 是「通过ifconfig或ipconfig获取网卡的公网IP地址。」   EIP 支持绑定弹性网卡的类型 主弹性网卡和辅助弹性网卡 仅支持绑定辅助弹性网卡   主弹性网卡允许绑定的 EIP 数量 1个 不支持绑定主弹性网卡   辅助弹性网卡允许绑定的EIP数量 取决于辅助弹性网卡的私网IP数量「EIP和辅助弹性网卡的私网IP地址一一映射，如辅助弹性网卡上共有10个私网IP地址，最多可为此弹性网卡绑定10个EIP。」 1个「网卡可见模式下，EIP只能绑定辅助弹性网卡上的主私网IP。」   EIP 绑定辅助弹性网卡，辅助弹性网卡的私网功能是否可用 是 否   支持的协议类型 EIP作为NAT ALG（NAT应用层网关）部署时，不支持如H.323、SIP、DNS、RTSP等协议 EIP可支持全部IP协议类型，支持FTP、H.323、SIP、DNS、RTSP、TFTP等协议    https://help.aliyun.com/document_detail/88991.htm?spm=a2c4g.11186623.2.8.26a81689kaKLht https://help.aliyun.com/knowledge_detail/185319.html?spm=5176.11065259.1996646101.searchclickresult.502375a7WG8E4C\n 所以\n问题就出在 EIP 工作模式为「普通模式」，普通模式不支持 FTP 协议，也只有「网卡可见模式」能实现返回命令端口信息 IP:端口 为 123.56.241.199:21423\n EIP 网卡可见模式功能使 EIP 在网卡上可见，解决了上述问题。在 EIP 网卡可见模式下：\n EIP 替换辅助弹性网卡的私网 IP，辅助弹性网卡将变为一个纯公网网卡，私网功能不再可用。 EIP 在操作系统内部的弹性网卡上可见，可直接通过 ifconfig 或 ipconfig 获取网卡上的公网 IP 地址。 EIP 可支持全部 IP 协议类型，支持 FTP、H.323、SIP、DNS、RTSP、TFTP 等协议。 一个辅助弹性网卡仅支持绑定一个 EIP。  总结 最终更换 EIP 工作模式为「网卡可见模式」就解决了此次原本可以不存在的故障……\n修改完「网卡可见模式」后在操作系统内可见公网 IP 如下「eth1」\n1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:16:3f:00:79:8e brd ff:ff:ff:ff:ff:ff inet 192.168.11.161/24 brd 192.168.11.255 scope global dynamic eth0 valid_lft 315084196sec preferred_lft 315084196sec inet6 fe80::216:3fff:fe00:798e/64 scope link valid_lft forever preferred_lft forever 3: eth1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:16:3e:13:10:f7 brd ff:ff:ff:ff:ff:ff inet 123.56.241.199/22 brd 121.196.247.255 scope global dynamic eth1 valid_lft 315084199sec preferred_lft 315084199sec inet6 fe80::216:3eff:fe13:10f7/64 scope link valid_lft forever preferred_lft forever  https://help.aliyun.com/document_detail/98641.htm?spm=a2c4g.11186623.2.6.26a81689kaKLht\n云主机厂商的网络环境，还是要多加了解，对于数据流向要清楚网络的实现方式，关键时候还是要回到官方文档。\n","id":2,"section":"posts","summary":"👌 2021-05-19 阿里云主机 EIP 致使 FTP 无法连接 上午收到了个协助工单，期间交手了两位同事都没解决掉的 ftp 奇特现象，就转到我这边了。 文中涉及到的相关 公网 IP 地址均特","tags":["Aliyun","EIP"],"title":"阿里云主机 EIP 致使 FTP 无法连接","uri":"https://blog.standuke.top/2021/05/2021-05-19-%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%BB%E6%9C%BA-eip-%E8%87%B4%E4%BD%BF-ftp-%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5/","year":"2021"},{"content":"👌 2021-05-08 OpenStack Wallaby 部署4 安置服务-placement  FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/08 ~ 2021/05/10） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Placement installation of OpenStack Wallaby deployment\n 版本修订记录：\nv1.0.2105：2021-05-08：建立 OpenStack Wallaby 部署4 安置服务-placement，修订人：standuke\n[TOC]\nMariaDB 创建用户  创建数据库  CREATE DATABASE placement;  授予权限  PLACEMENT_DBPASS = PLACEMENT\nGRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost' \\ IDENTIFIED BY 'PLACEMENT_DBPASS'; GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' \\ IDENTIFIED BY 'PLACEMENT_DBPASS'; flush privileges;  keystone 创建相关信息 生效管理员用户 . admin-openrc  创建用户、服务  创建 placement 用户  openstack user create --domain default --password-prompt placement +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | c5a59f718c1e41e4a38add5cce840372 | | name | placement | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+  赋予 placement 用户到 service 项目中的 admin 角色  此处的 service 项目已经在 keystone 的 2. 创建服务「Service」 步骤完成了，所以只需要赋予角色即可\nopenstack role add --project service --user placement admin 该命令不提供任何输出。  创建 glance 服务实体  openstack service create --name placement --description \u0026quot;Placement API\u0026quot; placement +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Placement API | | enabled | True | | id | afa22a1b206d44a79234c535e82d1bb3 | | name | placement | | type | placement | +-------------+----------------------------------+  创建服务 endpoint openstack endpoint create --region RegionOne placement public http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | d5488a2138bf4692aa0b672801b4c612 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | afa22a1b206d44a79234c535e82d1bb3 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne placement internal http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 0c06139bed0544709a08347df76d2153 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | afa22a1b206d44a79234c535e82d1bb3 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne placement admin http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 9f2649d5d3544b52a6ccc7256c29dbb6 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | afa22a1b206d44a79234c535e82d1bb3 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+  部署 palcement 安装软件包 apt install placement-api  修改配置文件  编辑 /etc/placement/placement.conf 文件并完成以下操作  PLACEMENT_PASS = PLACEMENT_DBPASS =\u0026gt; PLACEMENT\nvim /etc/placement/placement.conf [placement_database] # ... connection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller/placement [api] # ... auth_strategy = keystone [keystone_authtoken] # ... auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = placement password = PLACEMENT_PASS  初始化 placement 数据库  su -s /bin/sh -c \u0026quot;placement-manage db sync\u0026quot; placement  重启 http systemctl restart apache2.service  截至目前 apache2 服务状态如下\n● apache2.service - The Apache HTTP Server Loaded: loaded (/lib/systemd/system/apache2.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2021-05-08 14:58:53 CST; 9s ago Docs: https://httpd.apache.org/docs/2.4/ Process: 19552 ExecStart=/usr/sbin/apachectl start (code=exited, status=0/SUCCESS) Main PID: 19565 (apache2) Tasks: 95 (limit: 308840) Memory: 54.3M CGroup: /system.slice/apache2.service ├─19565 /usr/sbin/apache2 -k start ├─19566 (wsgi:keystone-pu -k start ├─19567 (wsgi:keystone-pu -k start ├─19568 (wsgi:keystone-pu -k start ├─19569 (wsgi:keystone-pu -k start ├─19570 (wsgi:keystone-pu -k start ├─19571 (wsgi:placement-a -k start ├─19572 (wsgi:placement-a -k start ├─19573 (wsgi:placement-a -k start ├─19574 (wsgi:placement-a -k start ├─19575 (wsgi:placement-a -k start ├─19576 /usr/sbin/apache2 -k start └─19577 /usr/sbin/apache2 -k start  里程碑 生效管理员用户 . admin-openrc  查看状态 placement-status upgrade check apt install python3-pip pip3 install osc-placement root@node1:~# openstack --os-placement-api-version 1.2 resource class list --sort-column name +----------------------------+ | name | +----------------------------+ | DISK_GB | | FPGA | | IPV4_ADDRESS | | MEMORY_MB | | MEM_ENCRYPTION_CONTEXT | | NET_BW_EGR_KILOBIT_PER_SEC | | NET_BW_IGR_KILOBIT_PER_SEC | | NUMA_CORE | | NUMA_MEMORY_MB | | NUMA_SOCKET | | NUMA_THREAD | | PCI_DEVICE | | PCPU | | PGPU | | SRIOV_NET_VF | | VCPU | | VGPU | | VGPU_DISPLAY_HEAD | +----------------------------+  ","id":3,"section":"posts","summary":"👌 2021-05-08 OpenStack Wallaby 部署4 安置服务-placement FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/08 ~ 2021/05/10） Author - standuke Email - shadowdoker@gmail.com","tags":["OpenStack","Virtualization"],"title":"OpenStack Wallaby 部署4 安置服务 Placement","uri":"https://blog.standuke.top/2021/05/2021-05-08-openstack-wallaby-%E9%83%A8%E7%BD%B24-%E5%AE%89%E7%BD%AE%E6%9C%8D%E5%8A%A1-placement/","year":"2021"},{"content":"👌 2021-05-08 OpenStack Wallaby 部署3 镜像服务-glance  FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/08 ~ 2021/05/10） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Glance installation of OpenStack Wallaby deployment\n 版本修订记录：\nv1.0.2105：2021-05-07：建立 OpenStack Wallaby 部署3 镜像服务-glance，修订人：standuke\n[TOC]\nMariaDB 创建用户  创建数据库  CREATE DATABASE glance;  授予权限  GLANCE_DBPASS = GLANCE\nGRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\ IDENTIFIED BY 'GLANCE_DBPASS'; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \\ IDENTIFIED BY 'GLANCE_DBPASS'; flush privileges;  keystone 创建相关信息 生效管理员用户 . admin-openrc  创建用户、服务  创建 glance 用户  openstack user create --domain default --password-prompt glance +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 47d82b6275844ddb9ef9053a20892521 | | name | glance | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+  赋予 glance 用户、service 项目 admin 角色  此处的 service 项目已经在 keystone 的 2. 创建服务「Service」 步骤完成了，所以只需要赋予角色即可\nopenstack role add --project service --user glance admin 该命令不提供任何输出。  创建 glance 服务实体  openstack service create --name glance --description \u0026quot;OpenStack Image\u0026quot; image +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Image | | enabled | True | | id | 8894d10830b84a6aa333d2534745656c | | name | glance | | type | image | +-------------+----------------------------------+  创建服务 endpoint openstack endpoint create --region RegionOne image public http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | aaabde94a26341d39e93e41cd8aa0407 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 8894d10830b84a6aa333d2534745656c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 646ca2a253c14386b2d85bf53c8ddee8 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 8894d10830b84a6aa333d2534745656c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 47a440c573e24bd4b3aec173903b8f17 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 8894d10830b84a6aa333d2534745656c | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+  部署 glance 安装软件包 apt install glance  修改配置文件  编辑 /etc/glance/glance-api.conf 文件  GLANCE_DBPASS = GLANCE\nvim /etc/glance/glance-api.conf [database] # ... connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = glance password = GLANCE_PASS [paste_deploy] # ... flavor = keystone [glance_store] # ... stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/  初始化 glance 数据库  su -s /bin/sh -c \u0026quot;glance-manage db_sync\u0026quot; glance Upgraded database to: wallaby_contract01, current revision(s): wallaby_contract01 INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. Database is synced successfully.  启动 glance systemctl start glance-api.service systemctl enable glance-api.service  里程碑 下载测试用镜像 wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img  上传镜像至 glance  使用 qcow2 磁盘格式，raw 格式和公共可见将 img 上传 glance 服务，以便所有项目都可以访问  glance image-create --name \u0026quot;cirros\u0026quot; \\ --file cirros-0.4.0-x86_64-disk.img \\ --disk-format qcow2 --container-format bare \\ --visibility=public +------------------+----------------------------------------------------------------------------------+ | Property | Value | +------------------+----------------------------------------------------------------------------------+ | checksum | 443b7623e27ecf03dc9e01ee93f67afe | | container_format | bare | | created_at | 2021-05-08T06:18:45Z | | disk_format | qcow2 | | id | f824fa97-8e8e-4229-8bc6-8204ba8a2f46 | | min_disk | 0 | | min_ram | 0 | | name | cirros | | os_hash_algo | sha512 | | os_hash_value | 6513f21e44aa3da349f248188a44bc304a3653a04122d8fb4535423c8e1d14cd6a153f735bb0982e | | | 2161b5b5186106570c17a9e58b64dd39390617cd5a350f78 | | os_hidden | False | | owner | b78ed759bf184f21bb0a1461d5d9607d | | protected | False | | size | 12716032 | | status | active | | tags | [] | | updated_at | 2021-05-08T06:18:45Z | | virtual_size | 46137344 | | visibility | public | +------------------+----------------------------------------------------------------------------------+  确认上传成功  glance image-list +--------------------------------------+--------+ | ID | Name | +--------------------------------------+--------+ | f824fa97-8e8e-4229-8bc6-8204ba8a2f46 | cirros | +--------------------------------------+--------+  ","id":4,"section":"posts","summary":"👌 2021-05-08 OpenStack Wallaby 部署3 镜像服务-glance FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/08 ~ 2021/05/10） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Glance","tags":["OpenStack","Virtualization"],"title":"OpenStack Wallaby 部署3 镜像服务 Glance","uri":"https://blog.standuke.top/2021/05/2021-05-08-openstack-wallaby-%E9%83%A8%E7%BD%B23-%E9%95%9C%E5%83%8F%E6%9C%8D%E5%8A%A1-glance/","year":"2021"},{"content":"👌 2021-05-08 OpenStack Wallaby 部署2 身份认证-keystone  FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/07 ~ 2021/05/10） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Keystone installation of OpenStack Wallaby deployment\n 版本修订记录：\nv1.0.2105：2021-05-07：建立 OpenStack Wallaby 部署2 身份认证-keystone，修订人：standuke\n[TOC]\n计划 首先完成最小化安装「最小化安装清单如下」，后期逐步添加相关服务，例如 Ceph 等。\n最小化安装清单\nAt a minimum, you need to install the following services. Install the services in the order specified below: Identity service – keystone installation for Wallaby Image service – glance installation for Wallaby Placement service – placement installation for Wallaby Compute service – nova installation for Wallaby Networking service – neutron installation for Wallaby We advise to also install the following components after you have installed the minimal deployment services: Dashboard – horizon installation for Wallaby Block Storage service – cinder installation for Wallaby  keystone 安装 概述 OpenStack 身份服务提供了一个集成点，用于管理身份验证，授权和服务目录。\n身份服务通常是用户与之交互的第一项服务。身份验证后，最终用户可以使用其身份访问其他 OpenStack 服务。同样，其他 OpenStack 服务利用身份服务来确保用户是他们认可的人，并发现其他服务在部署中的位置。身份服务还可以与某些外部用户管理系统（例如LDAP）集成。\n用户和服务可以使用由身份服务管理的服务目录来查找其他服务。顾名思义，服务目录是 OpenStack 部署中可用服务的集合。每个服务可以具有一个或多个端点「endpoint」，并且每个端点可以是以下三种类型之一：admin，internal 或 public。在生产环境中，出于安全原因，不同的终结点类型可能驻留在暴露给不同类型的用户的单独网络上。例如，公共 API 网络可能在 Internet 上可见，因此客户可以管理其云。 admin API 网络可能仅限于管理云基础架构的组织内的运营商。内部 API 网络可能仅限于包含 OpenStack 服务的主机。此外，OpenStack 支持多个区域以实现可伸缩性。为简单起见，本指南将管理网络用于所有端点类型和默认端点、RegionOne 区域。身份服务中创建的区域，服务和端点共同构成了部署的服务目录。部署中的每个OpenStack 服务都需要一个服务条目，并在认证服务中存储相应的端点。这可以在安装和配置了身份服务之后完成。\n身份服务包含以下组件：\n服务器 集中式服务器使用 RESTful 接口提供身份验证和授权服务。\n驱动 驱动程序或服务后端已集成到集中式服务器。它们用于访问 OpenStack 外部存储库中的身份信息，并且可能已经存在于部署 OpenStack 的基础架构中（例如，SQL 数据库或 LDAP 服务器）。\n模组 中间件模块在使用身份服务的 OpenStack 组件的地址空间中运行。这些模块拦截服务请求，提取用户凭据，然后将它们发送到集中式服务器进行授权。中间件模块和 OpenStack 组件之间的集成使用 Python Web 服务器网关接口。\nMariaDB 创建用户  创建数据库  CREATE DATABASE keystone;  授予权限  GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \\ IDENTIFIED BY 'KEYSTONE_DBPASS'; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \\ IDENTIFIED BY 'KEYSTONE_DBPASS'; flush privileges;  安装 keystone  安装软件包  apt install keystone  修改配置文件 /etc/keystone/keystone.conf 添加数据库访问、token 提供者  vim /etc/keystone/keystone.conf [database] # ... connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@192.168.2.11/keystone [token] # ... provider = fernet  初始化 MariaDB 数据库  su -s /bin/sh -c \u0026quot;keystone-manage db_sync\u0026quot; keystone  进入数据库查看是否完成数据库初始化\nMariaDB [keystone]\u0026gt; show tables; +------------------------------------+ | Tables_in_keystone | +------------------------------------+ | access_rule | | access_token | | application_credential | | application_credential_access_rule | | application_credential_role | | assignment | | config_register | | consumer | | credential | | endpoint | | endpoint_group | | expiring_user_group_membership | | federated_user | | federation_protocol | | group | | id_mapping | | identity_provider | | idp_remote_ids | | implied_role | | limit | | local_user | | mapping | | migrate_version | | nonlocal_user | | password | | policy | | policy_association | | project | | project_endpoint | | project_endpoint_group | | project_option | | project_tag | | region | | registered_limit | | request_token | | revocation_event | | role | | role_option | | sensitive_config | | service | | service_provider | | system_assignment | | token | | trust | | trust_role | | user | | user_group_membership | | user_option | | whitelisted_config | +------------------------------------+ 49 rows in set (0.000 sec)  初始化 fernet 密钥存储库  在 --keystone-user 和 --keystone-group 标志用于指定将用于运行 keystone 操作系统的用户/组。提供这些是为了允许在另一个操作系统用户/组下运行 keystone。在下面的示例中，我们称为 user＆group keystone。keystone 用户和组在安装 keystone 软件包时就自动创建了。\nkeystone-manage fernet_setup --keystone-user keystone --keystone-group keystone keystone-manage credential_setup --keystone-user keystone --keystone-group keystone  初始化 keystone 服务  ADMIN_PASS = ADMIN\nkeystone-manage bootstrap --bootstrap-password ADMIN_PASS \\ --bootstrap-admin-url http://192.168.2.11:5000/v3/ \\ --bootstrap-internal-url http://192.168.2.11:5000/v3/ \\ --bootstrap-public-url http://192.168.2.11:5000/v3/ \\ --bootstrap-region-id RegionOne  配置 Apache HTTP 服务器  编辑 /etc/apache2/apache2.conf 文件并配置 ServerName 选项以引用控制器节点\nvim /etc/apache2/apache2.conf 第 70 行 新增 ServerName 192.168.2.11  重启 http 服务  systemctl restart apache2.service  创建环境变量来配置管理帐户  这里的参数来自第 5. 初始化 keystone 服务 时配置的参数\ncd ~ vim admin.profile $ export OS_USERNAME=admin $ export OS_PASSWORD=ADMIN $ export OS_PROJECT_NAME=admin $ export OS_USER_DOMAIN_NAME=Default $ export OS_PROJECT_DOMAIN_NAME=Default $ export OS_AUTH_URL=http://192.168.2.11:5000/v3 $ export OS_IDENTITY_API_VERSION=3  里程碑 查看已有的 keystone 信息  生效环境变量  source admin.profile  查看 初始化 keystone 时创建的 默认信息  root@node1:~# openstack domain list +---------+---------+---------+--------------------+ | ID | Name | Enabled | Description | +---------+---------+---------+--------------------+ | default | Default | True | The default domain | +---------+---------+---------+--------------------+ root@node1:~# openstack user list +----------------------------------+-------+ | ID | Name | +----------------------------------+-------+ | 3c1af2df3a2747319e3789b0d98789b6 | admin | +----------------------------------+-------+ root@node1:~# openstack project list +----------------------------------+-------+ | ID | Name | +----------------------------------+-------+ | b78ed759bf184f21bb0a1461d5d9607d | admin | +----------------------------------+-------+  创建域，项目，用户和角色 身份服务为每个 OpenStack 服务提供身份验证服务。身份验证服务使用域，项目，用户和角色的组合。\n 创建域 「Region」  在 初始化 keystone 时已经创建了「Default」域，创建新域「example」可使用如下命令\nopenstack domain create --description \u0026quot;An Example Domain\u0026quot; example +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | An Example Domain | | enabled | True | | id | 2d949dc2d33c4c649c6cff24dccb6ff1 | | name | example | | options | {} | | tags | [] | +-------------+----------------------------------+  创建服务「Service」  在 OpenStack 中，组件提供的服务也是需要注册到 keystone 上的，可使用如下命令创建新的服务「service」，并将服务放置于 1. 创建域 「Region」 创建的「example」域内。\nopenstack project create --domain default --description \u0026quot;Service Project\u0026quot; service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | 76df0ebcc4e241f18e30c8ee9229e37e | | is_domain | False | | name | service | | options | {} | | parent_id | default | | tags | [] | +-------------+----------------------------------+  创建普通项目、普通用户、普通角色  openstack project create --domain default --description \u0026quot;Demo Project\u0026quot; myproject +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Demo Project | | domain_id | default | | enabled | True | | id | 0b6996d9ce8d490ab7df57ff7e4180a9 | | is_domain | False | | name | myproject | | options | {} | | parent_id | default | | tags | [] | +-------------+----------------------------------+ openstack user create --domain default --password-prompt myuser +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | adf2c52ba7ef451db99db43a7365fcc0 | | name | myuser | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ openstack role create myrole +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | None | | id | 81b6d4a225fa4f7a8180595e30277747 | | name | myrole | | options | {} | +-------------+----------------------------------+  将 角色 赋予 项目、用户  openstack role add --project myproject --user myuser myrole 该命令不提供任何输出  验证操作  取消设置临时变量 OS_AUTH_URL 和 OS_PASSWORD 环境变量  先查看已有的环境变量 echo $OS_AUTH_URL echo $OS_PASSWORD 取消环境变量 unset OS_AUTH_URL OS_PASSWORD 再查看环境变量是否被取消成功 echo $OS_AUTH_URL echo $OS_PASSWORD  以 admin 用户身份请求身份验证令牌  openstack --os-auth-url http://192.168.2.11:5000/v3 \\ --os-project-domain-name Default --os-user-domain-name Default \\ --os-project-name admin --os-username admin token issue 手工输入密码 ADMIN +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2021-05-08T04:33:29+0000 | | id | gAAAAABglgaJne9RksPFIDM0WlpBIT_Y2Y8cKevLynELsQOr5pV2bxVVG4lu8USDydpIGmVYrP0FeDzUPkKanJUZomBJugxNdtKhguf4xPecLnETz0lSDvoQHBOK10_5NLUceMMw6SqUOe3ckARfC_9KeTQ8t9teM1cn7iUrSM5zgaNh-jpHDCY | | project_id | b78ed759bf184f21bb0a1461d5d9607d | | user_id | 3c1af2df3a2747319e3789b0d98789b6 | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+  以 myuser 用户身份请求身份验证令牌  openstack --os-auth-url http://node1:5000/v3 --os-project-domain-name Default --os-user-domain-name Default --os-project-name myproject --os-username myuser token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2021-05-08T04:34:47+0000 | | id | gAAAAABglgbXPr-VXj5k5Kzt3j-ZLBYLERJfLJ1rUuNBBxykpJzXwaOBe4Lbfajif4xC2J_7_Vh7OkheX5mwF_FqPeHghgLw-35mM3t1uUreDG5YuoqGSfvnMm0JPVLX6reU_XpIELkf-zpJRcx0v8K-GDzIFdnxXo2wfdITHaZ26TvPQZk94Q4 | | project_id | 0b6996d9ce8d490ab7df57ff7e4180a9 | | user_id | adf2c52ba7ef451db99db43a7365fcc0 | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+  创建 OpenStack 客户端环境脚本 目的，用户快速切换客户端环境，减少输用户名、密码次数\n官方：前面的部分使用了环境变量和命令选项的组合，以通过openstack客户端与Identity Service进行交互。为了提高客户端操作的效率，OpenStack支持简单的客户端环境脚本，也称为OpenRC文件。这些脚本通常包含所有客户端的通用选项，但也支持唯一选项。\n admin-openrc  ADMIN_PASS = ADMIN\nexport OS_PROJECT_DOMAIN_NAME=Default export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_NAME=admin export OS_USERNAME=admin export OS_PASSWORD=ADMIN_PASS export OS_AUTH_URL=http://node1:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2   demo-openrc  DEMO_PASS = myuser\nexport OS_PROJECT_DOMAIN_NAME=Default export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_NAME=myproject export OS_USERNAME=myuser export OS_PASSWORD=DEMO_PASS export OS_AUTH_URL=http://node1:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2  使用环境变量\n. admin-openrc  使用环境变量获取令牌\nopenstack token issue  ","id":5,"section":"posts","summary":"👌 2021-05-08 OpenStack Wallaby 部署2 身份认证-keystone FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/07 ~ 2021/05/10） Author - standuke Email - shadowdoker@gmail.com DescriptionKey","tags":["OpenStack","Virtualization"],"title":"OpenStack Wallaby 部署2 身份认证 Keystone","uri":"https://blog.standuke.top/2021/05/2021-05-08-openstack-wallaby-%E9%83%A8%E7%BD%B22-%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81-keystone/","year":"2021"},{"content":"👌 2021-05-07 OpenStack Wallaby 部署1 操作系统及基础环境  FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/07 ~ 2021/05/09） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Operating system and basic environment of OpenStack Wallaby deployment\n 版本修订记录：\nv1.0.2105：2021-05-07：建立 OpenStack Wallaby 部署1 操作系统及基础环境，修订人：standuke\n[TOC]\n操作系统环境准备 ==以下操作系统环境准备每个节点都需要做==\n操作系统安装 此次部署操作系统为 ubuntu-20.04.2-live-server-amd64.iso\n操作系统便利设置  配置 ssh-key 免密登陆 启用 root 用户 配置 允许 root 用户登陆  操作系统新增 deb 源 sudo add-apt-repository cloud-archive:wallaby  参考资料： https://wiki.ubuntu.com/OpenStack/CloudArchive\n更新操作系统 apt update \u0026amp;\u0026amp; apt dist-upgrade  如果更新包含了内核更新，那需要重启系统\n安装 OpenStack 客户端 仅适用于 Ubuntu 20.04 LTS\napt install python3-openstackclient  NTP 时间同步  NTP Server  Controller「NTP Server只需配置一台服务器即可」\n安装 Chrony 作为 NTP 服务段，此时系统会自动禁用 mask 系统默认安装的 timedatectl 内包含的 systemd-timesyncd\napt install chrony  修改 chrony 配置文件\nvim /etc/chrony/chrony.conf # 作出如下修改即可 pool ntp.ubuntu.com iburst maxsources 4 server 127.127.1.0 iburst allow 192.168.2.0/24 allow 192.168.10.0/24  查看 配置的本地 NTP Server 是否生效\nroot@node1:~# chronyc sources 210 Number of sources = 5 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^? localhost 0 8 0 - +0ns[ +0ns] +/- 0ns ^? golem.canonical.com 0 6 0 - +0ns[ +0ns] +/- 0ns ^* chilipepper.canonical.com 2 6 377 52 +3446us[+4892us] +/- 149ms ^+ pugot.canonical.com 2 6 377 52 -5135us[-5135us] +/- 168ms ^+ alphyn.canonical.com 2 6 377 51 +14ms[ +14ms] +/- 209ms   NTP Client  由于系统安装时会默认安装 ntp 服务 `` 所以只需要在 NTP 时间同步服务器池内添加本地服务器地址即可。\nvim /etc/systemd/timesyncd.conf [Time] NTP=192.168.2.11  使用 timedatectl 来查看是否生效\nroot@node2:~# timedatectl show-timesync SystemNTPServers=192.168.2.11 FallbackNTPServers=ntp.ubuntu.com ServerName=192.168.2.11 ServerAddress=192.168.2.11 RootDistanceMaxUSec=5s PollIntervalMinUSec=32s PollIntervalMaxUSec=34min 8s PollIntervalUSec=1min 4s Frequency=0 root@node2:~# timedatectl timesync-status Server: 192.168.2.11 (192.168.2.11) Poll interval: 8min 32s (min: 32s; max 34min 8s) Leap: normal Version: 4 Stratum: 3 Reference: 5BBD59C6 Precision: 1us (-24) Root distance: 185.188ms (max: 5s) Offset: -37.208ms Delay: 91us Jitter: 26.196ms Packet count: 6 Frequency: +91.680ppm  参考资料： https://zh.codepre.com/how-to-5498.html\n主机名及域名 本次环境使用修改 hosts 文件方式完成域名解析\nvim /etc/hosts root@node1:~# cat /etc/hosts 127.0.0.1 localhost 127.0.1.1 node1 192.168.2.11 node1 node1.nuo.com controller 192.168.2.12 node2 node2.nuo.com compute 192.168.2.13 node3 node3.nuo.com storage  关闭防火墙及 SELinux 关闭防火墙 ufw disable 关闭 SELinux apt install policycoreutils root@node1:~# sestatus SELinux status: disabled  安装 OpenStack 环境依赖 ==以下软件环境依赖均安装于 Controller 节点==\nMariaDB「MySQL」数据库 大多数 OpenStack 服务都使用 SQL 数据库来存储信息。该数据库通常在控制器节点上运行。本指南中的过程根据发行版使用 MariaDB 或 MySQL。OpenStack 服务还支持其他 SQL 数据库，包括 PostgreSQL。\n 安装 MariaDB 包「python3-pymysql 只针对于 Ubuntu 20.04 LTS」  apt install mariadb-server python3-pymysql  创建并编辑 /etc/mysql/mariadb.conf.d/99-openstack.cnf 文件同时修改相关配置  vim /etc/mysql/mariadb.conf.d/99-openstack.cnf [mysqld] bind-address = 192.168.2.11 default-storage-engine = innodb innodb_file_per_table = on max_connections = 4096 collation-server = utf8_general_ci character-set-server = utf8  启动 MariaDB  systemctl start mariadb.service systemctl restart mariadb.service「默认服务应该是自动启动了，所以只要重启服务即可」 systemctl enable mariadb.service  使用 如下脚本完成对于 MariaDB 数据库的初始化  mysql_secure_installation 测试环境 root 密码 1212  RocketMQ「消息队列」 OpenStack 使用消息队列来协调服务之间的操作和状态信息。消息队列服务通常在控制器节点上运行。OpenStack 支持多种消息队列服务，包括 RabbitMQ，Qpid 和 ZeroMQ。但是，打包 OpenStack 的大多数发行版都支持特定的消息队列服务。本指南实现了 RabbitMQ 消息队列服务，因为大多数发行版都支持该服务。如果您希望实施其他消息队列服务，请查阅与其相关的文档。\n 安装软件包  apt install rabbitmq-server  添加 openstack 用户  root@node1:～# rabbitmqctl add_user openstack OPENSTACK Adding user \u0026quot;openstack\u0026quot; ...  允许用户配置，写入和读取访问权限openstack  root@node1:~# rabbitmqctl set_permissions openstack \u0026quot;.*\u0026quot; \u0026quot;.*\u0026quot; \u0026quot;.*\u0026quot; Setting permissions for user \u0026quot;openstack\u0026quot; in vhost \u0026quot;/\u0026quot; ...  Memcached 服务的身份服务身份验证机制使用 Memcached 来缓存令牌。memcached 服务通常在控制器节点上运行。对于生产部署，我们建议启用防火墙，身份验证和加密的组合以对其进行保护。\n 安装软件包  apt install memcached python3-memcache  编辑 /etc/memcached.conf 文件并将服务配置为使用控制器节点的管理 IP 地址。这是为了允许其他节点通过管理网络进行访问  vim /etc/memcached.conf 第 35 行 修改 - -l 127.0.0.1 + -l 192.168.2.11  重启 Memcached 服务  systemctl restart memcached.service systemctl enable memcached.service Synchronizing state of memcached.service with SysV service script with /lib/systemd/systemd-sysv-install. Executing: /lib/systemd/systemd-sysv-install enable memcached  etcd OpenStack 服务可以使用 etcd（分布式可靠键值存储）进行分布式键锁定，存储配置，跟踪服务活动性和其他情况。\n 安装etcd软件包  apt install etcd  编辑 /etc/default/etcd 文件，并设置 ETCD_INITIAL_CLUSTER，ETCD_INITIAL_ADVERTISE_PEER_URLS，ETCD_ADVERTISE_CLIENT_URLS，ETCD_LISTEN_CLIENT_URLS 控制器节点，以使经由管理网络通过其他节点的访问的管理IP地址「安装完 etcd 后，默认的配置文件是空的」  vim /etc/default/etcd ETCD_NAME=\u0026quot;controller\u0026quot; ETCD_DATA_DIR=\u0026quot;/var/lib/etcd\u0026quot; ETCD_INITIAL_CLUSTER_STATE=\u0026quot;new\u0026quot; ETCD_INITIAL_CLUSTER_TOKEN=\u0026quot;etcd-cluster-01\u0026quot; ETCD_INITIAL_CLUSTER=\u0026quot;controller=http://192.168.2.11:2380\u0026quot; ETCD_INITIAL_ADVERTISE_PEER_URLS=\u0026quot;http://192.168.2.11:2380\u0026quot; ETCD_ADVERTISE_CLIENT_URLS=\u0026quot;http://192.168.2.11:2379\u0026quot; ETCD_LISTEN_PEER_URLS=\u0026quot;http://0.0.0.0:2380\u0026quot; ETCD_LISTEN_CLIENT_URLS=\u0026quot;http://192.168.2.11:2379\u0026quot;  重新启动 etcd 服务，并开机自启  systemctl enable etcd systemctl restart etcd  ","id":6,"section":"posts","summary":"👌 2021-05-07 OpenStack Wallaby 部署1 操作系统及基础环境 FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.0.2105（2021/05/07 ~ 2021/05/09） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Operating system and","tags":["OpenStack","Virtualization"],"title":"OpenStack Wallaby 部署1 操作系统及基础环境","uri":"https://blog.standuke.top/2021/05/2021-05-07-openstack-wallaby-%E9%83%A8%E7%BD%B21-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8F%8A%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/","year":"2021"},{"content":"👌 2021-05-06 OpenStack Wallaby 部署0 选型及整体介绍  FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.1.2105（2021/05/06 ~ 2021/05/11） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Introduction to OpenStack Wallaby deployment\n 版本修订记录：\nv1.0.2105：2021-05-06：建立 OpenStack Wallaby 部署0 选型及整体介绍 文档，修订人：standuke v1.1.2105：2021-05-11：新增 OpenStack 简介、官方概念架构及逻辑架构配图、组件密码规划待下一版本修订，修订人：standuke\n[TOC]\n简介 https://docs.openstack.org/install-guide/openstack-services.html\nOpenStack 是一个由 NASA「美国国家航空航天局」和 Rackspace 合作研发并发起的，以 Apache 许可证授权的自由软件和开放源代码项目。 OpenStack 是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack 支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack 通过各种互补的服务 - 即组件，提供了基础设施即服务「IaaS」的解决方案，每个服务提供 API 以进行集成。 OpenStack 是一个旨在为公共及私有云的建设与管理提供软件的开源项目。OpenStack 项目的首要任务是简化云的部署过程并为其带来良好的可扩展性。\n与前期版本差异 Wallaby，是 OpenStack 的第 23 个发行版，其对基于角色的访问控制「RBAC」进行了改进，并与其他开源项目「包括 Ceph，Kubernetes 和 Prometheus」集成，以增强用于云原生应用程序的开放基础架构。\n 基于角色的访问控制策略格式从 JSON 迁移到 YAML，使 OpenStack 与 Kubernetes 更加同步。 OpenStack 内置了对开源 Ceph 后端驱动程序 Ceph iSCSI 的支持。除了其他新的 Cinder 存储驱动程序外，旧的驱动程序还增加了对新功能的支持，如恢复到快照和后端服务质量。 Kolla 现在已经添加了对 Prometheus V2 的支持。 Magnum API 服务已经更新了对 Kubernetes 和 containerd（一个标准的容器运行环境）的支持。 运营商可通过 Neutron 将网络端口中的固定 IP 地址路由到外部世界，而不受 IPv4 地址范围的限制。  参考资料： https://www.techrepublic.com/article/in-new-release-openstack-wallaby-reaches-out-to-kubernetes/\n说明  此次部署 各个组件密码 在本文当中使用环境变量替代，具体使用的密码可见 组件密码规划 部分 组件部署完毕之后会有一个 里程碑 用于检验组件是否工作正常，组件工作正常后建议在开展之后的部署工作。 部署采用的是最小化部署 OpenStack，再逐渐扩充组件丰富功能，最终目标是能够实现一套满足生产环境的架构「只是架构，参数等配置优化有时间有心情再写」  部署方案 此次部署 OpenStack 版本为 Wallaby，发行「release」日期为 2021 年 4 月 21 日。 部署方案为，计算与存储分离，计算节点只负责计算，管理节点只负责管理调度、镜像存储，存储将采用 Ceph 作为底层存储平台，为前端计算节点虚拟机提供存储资源池。\n部署资源规划 此次部署共使用 3 台物理服务器，对应的服务器角色如下\n   服务器名称 管理段 IP 地址 服务器配置 泛角色 操作系统     node1.nuo.com 192.168.2.11 64C256G Controller  Ubuntu Server 20.04.2 LTS   node2.nuo.com 192.168.2.12 64C256G Compute Ubuntu Server 20.04.2 LTS   node3.nuo.com 192.168.2.13 64C256G Storage Ubuntu Server 20.04.2 LTS    对于 在虚拟机环境部署 建议 3 台虚拟机「每台 4 核 8G 内存 60G 磁盘」或者 1 台虚拟机部署所有核心组件「配置 4 核 12G 内存 80G 磁盘」\n操作系统  对于 Ubuntu LTS 于 Ubuntu 官网可见 Ubuntu 服务器的长期支持版本将包含 OpenStack。同样地，安全更新也将支持至 2025 年 4 月，仅限 64 位平台。 对于 OpenStack 官方文档中使用的 Ubuntu 20.04.2 LTS 作为底层操作系统。 目前 OpenStack 支持如下操作系统平台 可见官网 https://docs.openstack.org/install-guide/preface.html OpenStack Wallaby is available for CentOS Stream 8. OpenStack Ussuri and Victoria are available for both CentOS 8 and RHEL 8. OpenStack Train and earlier are available on both CentOS 7 and RHEL 7. 考虑到 CentOS 后期官方不再维护且支持周期较短，故此次部署不采用 CentOS 操作系统。\n 如下为 泛角色 内部对应的组件规划「如下组件能保证 OpenStack 能够正常提供基础服务，后期在部署完成后计划逐步添加容器等其他服务组件」\n Controller OpenStack 环境依赖「MariaDB、etcd、RocketMQ、Memcached」 CINDER「后期使用 Ceph 替代」 NEUTRON KEYSTONE PLACEMENT GLANCE「后期存储于 Ceph 上」 HORIZON Compute NOVA NEUTRON Storage Ceph  如下为官方对于最小化部署 OpenStack 的组件要求\nMinimal deployment for Wallaby At a minimum, you need to install the following services. Install the services in the order specified below: Identity service – keystone installation for Wallaby Image service – glance installation for Wallaby Placement service – placement installation for Wallaby Compute service – nova installation for Wallaby Networking service – neutron installation for Wallaby We advise to also install the following components after you have installed the minimal deployment services: Dashboard – horizon installation for Wallaby Block Storage service – cinder installation for Wallaby  磁盘规划「测试环境」 node1「Controller」\nroot@node1:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 55.5M 1 loop /snap/core18/1997 loop1 7:1 0 67.6M 1 loop /snap/lxd/20326 loop2 7:2 0 69.9M 1 loop /snap/lxd/19188 loop3 7:3 0 31.1M 1 loop /snap/snapd/10707 loop4 7:4 0 55.4M 1 loop /snap/core18/1944 loop5 7:5 0 32.3M 1 loop /snap/snapd/11588 sda 8:0 0 1.1T 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi ├─sda2 8:2 0 1G 0 part /boot └─sda3 8:3 0 1.1T 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 200G 0 lvm / sdb 8:16 0 5.5T 0 disk root@node1:~# df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 126G 0 126G 0% /dev tmpfs tmpfs 26G 2.3M 26G 1% /run /dev/mapper/ubuntu--vg-ubuntu--lv ext4 196G 11G 176G 6% / tmpfs tmpfs 126G 0 126G 0% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs tmpfs 126G 0 126G 0% /sys/fs/cgroup /dev/sda2 ext4 976M 200M 710M 22% /boot /dev/loop0 squashfs 56M 56M 0 100% /snap/core18/1997 /dev/sda1 vfat 511M 7.9M 504M 2% /boot/efi /dev/loop1 squashfs 68M 68M 0 100% /snap/lxd/20326 /dev/loop2 squashfs 70M 70M 0 100% /snap/lxd/19188 /dev/loop3 squashfs 32M 32M 0 100% /snap/snapd/10707 /dev/loop4 squashfs 56M 56M 0 100% /snap/core18/1944 /dev/loop5 squashfs 33M 33M 0 100% /snap/snapd/11588 tmpfs tmpfs 26G 0 26G 0% /run/user/0 root@node1:~#  node2「Compute」\nroot@node2:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 55.5M 1 loop /snap/core18/1997 loop1 7:1 0 55.4M 1 loop /snap/core18/1944 loop2 7:2 0 67.6M 1 loop /snap/lxd/20326 loop3 7:3 0 69.9M 1 loop /snap/lxd/19188 loop4 7:4 0 32.3M 1 loop /snap/snapd/11588 loop5 7:5 0 31.1M 1 loop /snap/snapd/10707 sda 8:0 0 5.5T 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi ├─sda2 8:2 0 1G 0 part /boot └─sda3 8:3 0 5.5T 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 5.5T 0 lvm / root@node2:~# df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 126G 0 126G 0% /dev tmpfs tmpfs 26G 2.3M 26G 1% /run /dev/mapper/ubuntu--vg-ubuntu--lv ext4 5.5T 11G 5.2T 1% / tmpfs tmpfs 126G 0 126G 0% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs tmpfs 126G 0 126G 0% /sys/fs/cgroup /dev/sda2 ext4 976M 200M 710M 22% /boot /dev/loop0 squashfs 56M 56M 0 100% /snap/core18/1997 /dev/sda1 vfat 511M 7.9M 504M 2% /boot/efi /dev/loop1 squashfs 56M 56M 0 100% /snap/core18/1944 /dev/loop2 squashfs 68M 68M 0 100% /snap/lxd/20326 /dev/loop3 squashfs 70M 70M 0 100% /snap/lxd/19188 /dev/loop5 squashfs 32M 32M 0 100% /snap/snapd/10707 /dev/loop4 squashfs 33M 33M 0 100% /snap/snapd/11588 tmpfs tmpfs 26G 0 26G 0% /run/user/0 root@node2:~#  node3「Storage」\nroot@node3:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 55.4M 1 loop /snap/core18/1944 loop1 7:1 0 55.5M 1 loop /snap/core18/1997 loop2 7:2 0 69.9M 1 loop /snap/lxd/19188 loop3 7:3 0 31.1M 1 loop /snap/snapd/10707 loop4 7:4 0 67.6M 1 loop /snap/lxd/20326 loop5 7:5 0 32.3M 1 loop /snap/snapd/11588 sda 8:0 0 1.1T 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi ├─sda2 8:2 0 1G 0 part /boot └─sda3 8:3 0 1.1T 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 1.1T 0 lvm / sdb 8:16 0 1.1T 0 disk sdc 8:32 0 1.1T 0 disk sdd 8:48 0 1.1T 0 disk root@node3:~# df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 126G 0 126G 0% /dev tmpfs tmpfs 26G 2.6M 26G 1% /run /dev/mapper/ubuntu--vg-ubuntu--lv ext4 1.1T 11G 1.1T 2% / tmpfs tmpfs 126G 0 126G 0% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs tmpfs 126G 0 126G 0% /sys/fs/cgroup /dev/sda2 ext4 976M 200M 710M 22% /boot /dev/sda1 vfat 511M 7.9M 504M 2% /boot/efi /dev/loop0 squashfs 56M 56M 0 100% /snap/core18/1944 /dev/loop1 squashfs 56M 56M 0 100% /snap/core18/1997 /dev/loop2 squashfs 70M 70M 0 100% /snap/lxd/19188 /dev/loop3 squashfs 32M 32M 0 100% /snap/snapd/10707 /dev/loop5 squashfs 33M 33M 0 100% /snap/snapd/11588 /dev/loop4 squashfs 68M 68M 0 100% /snap/lxd/20326 tmpfs tmpfs 26G 0 26G 0% /run/user/0 root@node3:~#  部署网络规划 网段规划 此次采用官方「Networking Option 2: Self-service networks」自主管理网络\n 管理段 192.168.2.0/24  即相对于云服务商的内网环境，此次环境管理段与公网相通，用于部署安装调试，同时管理段与服务器 BMC 相通，便于调试\n 业务段 192.168.10.0/24  即相对于云服务商的外网环境，用户客户访问云服务\n网络架构 此次部署采用「Self-service networks」网络架构\n 下图来自官方对于 Provider networks 的组件部署架构   下图来自官方对于 Self-service networks 的组件部署架构  可见对于 Option 1 来说 Self-service networks 网络架构多了 L3 Agent 也就是多了，三层网络的路由功能，通过路由协议将虚拟网络与外界打通。\n组件密码规划    组件名称 用户名 密码 环境变量名称     MariaDB「MySQL」 root 1212 MARIADB_PASS   RabbitMQ openstack OPENSTACK RABBIT_PASS   keystone keystone KEYSTONE KEYSTONE_DBPASS   glance glance GLANCE GLANCE_DBPASS   keystone keystone KEYSTONE KEYSTONE_DBPASS   keystone keystone KEYSTONE KEYSTONE_DBPASS   keystone keystone KEYSTONE KEYSTONE_DBPASS   keystone keystone KEYSTONE KEYSTONE_DBPASS   keystone keystone KEYSTONE KEYSTONE_DBPASS    附录 架构  如下为 OpenStack 各个组件之间的关系「概念架构」  https://docs.openstack.org/install-guide/get-started-conceptual-architecture.html\n 如下为一种云的组织架构图「逻辑架构」  https://docs.openstack.org/install-guide/get-started-logical-architecture.html\n组件介绍 ==OpenStack Services「OpenStack 服务」== OpenStack 部署包含许多组件，这些组件提供用于访问基础结构资源的 API。如下列出了可以部署以向云最终用户提供此类资源的各种服务。\nCompute「计算资源」 NOVA - Compute Service「计算服务」 ZUN - Containers Service「容器服务」\nHardware Lifecycle「硬件生命周期」 IRONIC - Bare Metal Provisioning Service「裸机配置服务」 CYBORG - Lifecycle management of accelerators「加速器的生命周期管理」\nStorage「存储」 SWIFT - Object store「对象存储」 CINDER - Block Storage「块存储」 MANILA - Shared filesystems「共享文件系统」\nNetworking「网络」 NEUTRON - Networking「网络」 OCTAVIA - Load balancer「负载均衡」 DESIGNATE - DNS service「DNS 服务」\nShared Services「共享服务」 KEYSTONE - Identity service「身份认证服务」 PLACEMENT - Placement service「服务安置服务」 GLANCE - Image service「镜像服务」 BARBICAN - Key management「密钥管理服务」\nOrchestration HEAT - Orchestration「编排」 SENLIN - Clustering service「集群服务」 MISTRAL - Workflow service「工作流服务」 ZAQAR - Messaging Service「消息服务」 BLAZAR - Resource reservation service「资源预约服务」 AODH - Alarming Service「报警服务」\nWorkload Provisioning MAGNUM - Container Orchestration Engine Provisioning「容器编排配置引擎」 SAHARA - Big Data Processing Framework Provisioning「大数据处理框架配置」 TROVE - Database as a Service「数据库即服务」\nApplication Lifecycle MASAKARI - Instances High Availability Service「实例高可用性服务」 MURANO - Application Catalog「应用目录」 SOLUM - Software Development Lifecycle Automation「软件开发生命周期自动化」 FREEZER - Backup, Restore, and Disaster Recovery「备份，还原和灾难恢复」\nAPI Proxies EC2API - EC2 API proxy「EC2 API代理」\nWeb Frontend HORIZON - Dashboard「仪表盘」\n==Operations tooling「运维工具」== 这些服务提供主要针对云管理员和部署者的API，以帮助进行云操作。\nMonitoring services「监控服务」 CEILOMETER - Metering \u0026amp; Data Collection Service「计量和数据收集服务」 PANKO - Event, Metadata Indexing Service「事件，元数据索引服务」 MONASCA - Monitoring「监控」\nResource optimization「资源优化」 WATCHER - Optimization Service「优化服务」 VITRAGE - Root Cause Analysis service「根本原因分析服务」\nBilling / Business Logic「计费 / 业务逻辑」 ADJUTANT - Operations processes automation「运营流程自动化」 CLOUDKITTY - Billing and chargebacks「帐单和退款」\nTesting / Benchmark RALLY - Benchmarking tool「跑分工具标杆管理工具」 TEMPEST - The OpenStack Integration Test Suite「OpenStack集成测试套件」 PATROLE - The OpenStack RBAC Integration Test Suite「OpenStack RBAC集成测试套件」\n==Add-Ons to Services「附加服务」== 该软件可以作为其他 OpenStack 服务的附件或插件运行。\nSwift 附加组件 STOR - Computable object storage「可计算对象存储」\n==Integration enablers「其他系统整合」== 本节中的软件有助于将 OpenStack 组件集成到相邻的开放基础架构堆栈中。\nContainers「容器」 KURYR - OpenStack Networking integration for containers「容器的OpenStack网络集成」\nNFV TACKER - NFV Orchestration「NFV编排」\n","id":7,"section":"posts","summary":"👌 2021-05-06 OpenStack Wallaby 部署0 选型及整体介绍 FileInfo Filename - OpenStack Wallaby 部署简介 Version - v1.1.2105（2021/05/06 ~ 2021/05/11） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Introduction to OpenStack Wallaby deployment","tags":["OpenStack","Virtualization"],"title":"OpenStack Wallaby 部署0 选型及整体介绍","uri":"https://blog.standuke.top/2021/05/2021-05-06-openstack-wallaby-%E9%83%A8%E7%BD%B20-%E9%80%89%E5%9E%8B%E5%8F%8A%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D/","year":"2021"},{"content":"👌 2021-04-22 电脑状态 休眠 睡眠 关机等区别 Suspend「待机」  Does not turn off your computer. It puts the computer and all peripherals on a low power consumption mode. If the battery runs out or the computer turns off for some reason, the current session and unsaved changes will be lost.\n 不关闭计算机。它使计算机和所有外围设备处于低功耗模式。开机运行状态下数据存放在哪里，待机状态下也存放在哪里。如果电池耗尽或计算机因某种原因关闭，则当前会话和未保存的更改将丢失，相当于内存数据会丢失。\nSleep「睡眠」  Sleep mode is a power saving state that is similar to pausing a DVD movie. All actions on the computer are stopped, any open documents and applications are put in memory while the computer goes into a low-power state. The computer technically stays on, but only uses a bit of power. You can quickly resume normal, full-power operation within a few seconds. Sleep mode is basically the same thing as \u0026ldquo;Standby\u0026rdquo; mode.\n  Sleep mode is useful if you want to stop working for a short period of time. The computer doesn\u0026rsquo;t use much power in Sleep mode, but it does use some. Hibernate\n 睡眠模式与「待机」模式基本相同。 睡眠模式是一种省电状态，类似于暂停 DVD 电影或者暂停 CD 机、磁带机。当计算机进入低功耗状态时，计算机上的所有操作都将停止，所有打开的文档和应用程序都将放入内存。从技术上讲，这台电脑是开着的，但只消耗一点电。您可以在几秒钟内快速恢复正常、满功率运行。\nHibernate「休眠」  saves the state of your computer to the hard disk and completely powers off. When resuming, the saved state is restored to RAM.\n 将计算机的状态保存到硬盘上，即内存数据保存到硬盘上，并完全关闭电源。恢复时，保存的状态将恢复到内存。\n Hibernate mode is very similar to sleep, but instead of saving your open documents and running applications to your RAM, it saves them to your hard disk. This allows your computer to turn off entirely, which means once your computer is in Hibernate mode, it uses zero power. Once the computer is powered back on, it will resume everything where you left off. It just takes a bit longer to resume than sleep mode does (though with an SSD, the difference isn\u0026rsquo;t as noticeable as it is with traditional hard drives).\n Hibernate 模式与 sleep 非常相似，但它不会将打开的文档和正在运行的应用程序保存到 RAM 中，而是将它们保存到硬盘中。这允许您的计算机完全关闭，这意味着一旦您的计算机处于休眠模式，它使用零功率。一旦电脑重新开机，它将恢复您中断的所有操作。它只需要比睡眠模式长一点就可以恢复「对于SSD，这种差异不像传统硬盘那样明显」。\n Use this mode if you won\u0026rsquo;t be using your laptop for an extended period of time, and you don\u0026rsquo;t want to close your documents.\n 如果长时间不使用笔记本电脑，并且不想关闭文档，请使用此模式。\nHybrid Sleep「混合睡眠」  Hybrid Sleep mode is a combination of the Sleep and Hibernate modes meant for desktop computers. It puts any open documents and applications in memory and on your hard disk, and then puts your computer into a low-power state, allowing you to quickly wake the computer and resume your work. The Hybrid Sleep mode is enabled by default in Windows on desktop computers and disabled on laptops. When enabled, it automatically puts your computer into Hybrid Sleep mode when you put it into Sleep mode.\n  Hybrid Sleep mode is useful for desktop computers in case of a power outage. When power resumes, Windows can restore your work from the hard disk, if the memory is not accessible.\n 混合睡眠模式是指桌面计算机的睡眠模式和休眠模式的组合。它将任何打开的文档和应用程序放入内存和硬盘中，然后将计算机置于低功耗状态，从而使您能够快速唤醒计算机并恢复工作。混合睡眠模式默认在桌面计算机上的Windows中启用，在笔记本电脑上禁用。启用后，当您将计算机置于睡眠模式时，它会自动将计算机置于混合睡眠模式。 混合睡眠模式对于台式计算机在断电时非常有用。当电源恢复时，如果无法访问内存，Windows可以从硬盘还原工作。\n","id":8,"section":"posts","summary":"👌 2021-04-22 电脑状态 休眠 睡眠 关机等区别 Suspend「待机」 Does not turn off your computer. It puts the computer and all peripherals on a low power consumption mode. If the battery runs out or the computer turns off for some reason, the current session and unsaved changes will be lost. 不关闭","tags":["Windows","system"],"title":"电脑状态 休眠 睡眠 关机等区别","uri":"https://blog.standuke.top/2021/04/2021-04-22-%E7%94%B5%E8%84%91%E7%8A%B6%E6%80%81-%E4%BC%91%E7%9C%A0-%E7%9D%A1%E7%9C%A0-%E5%85%B3%E6%9C%BA%E7%AD%89%E5%8C%BA%E5%88%AB/","year":"2021"},{"content":"👌 2021-04-22 Linux 文件权限及文件夹说明 在工作中，利用特殊权限，往往可以事半功倍达到很多对于文件以及文件夹权限要求的设置，所以打算总结一下接触过的操作系统所涉及到的特殊文件权限，方便后期查看。本内容大致面向于 Linux 相关的操作系统。\n对于 类 Unix 操作系统，这里只涉及到了 CentOS ，其他的操作系统暂未涵盖进来。\n[TOC]\n类型说明 常规权限「l d r w x」  l: 链接文件或链接目录标识 d: 目录标识 r: 可读标识 w: 可写标识 x: 可执行标识  操作系统默认 / 目录的文件夹列表\ntotal 16 lrwxrwxrwx. 1 root root 7 Jan 8 2020 bin -\u0026gt; usr/bin dr-xr-xr-x. 5 root root 4096 Jan 8 2020 boot drwxr-xr-x. 20 root root 3240 Apr 22 23:19 dev drwxr-xr-x. 75 root root 8192 Apr 22 23:21 etc drwxr-xr-x. 2 root root 6 Apr 11 2018 home lrwxrwxrwx. 1 root root 7 Jan 8 2020 lib -\u0026gt; usr/lib lrwxrwxrwx. 1 root root 9 Jan 8 2020 lib64 -\u0026gt; usr/lib64 drwxr-xr-x. 2 root root 6 Apr 11 2018 media drwxr-xr-x. 2 root root 6 Apr 11 2018 mnt drwxr-xr-x. 3 root root 23 Nov 28 23:32 opt dr-xr-xr-x. 140 root root 0 Apr 22 23:18 proc dr-xr-x---. 2 root root 171 Nov 28 23:30 root drwxr-xr-x. 24 root root 720 Apr 22 23:20 run lrwxrwxrwx. 1 root root 8 Jan 8 2020 sbin -\u0026gt; usr/sbin drwxr-xr-x. 2 root root 6 Apr 11 2018 srv dr-xr-xr-x. 13 root root 0 Apr 22 23:19 sys drwxrwxrwt. 9 root root 161 Apr 22 23:19 tmp drwxr-xr-x. 13 root root 155 Jan 8 2020 usr drwxr-xr-x. 19 root root 267 Jan 8 2020 var  可读权限  对于文件，可读权限：可以对读取文件里的内容  用字符表示：r 用八进制表示：4\n 对于目录，可读权限：可以列出目录下的内容  用字符表示：r 用八进制表示：4\n可写权限   对于文件，可写权限：可以对文件进行更改 用字符表示：w 用八进制表示：2\n  对于目录，可写权限：可以在目录下创建文件或目录\n  用字符表示：w 用八进制表示：2\n可执行权限  对于文件，可写权限：可以执行该文件（脚本或命令）  用字符表示：x 用八进制表示：1\n 对于目录，可写权限：可以cd进入该目录  用字符表示：x 用八进制表示：1\n特殊权限「SUID SGID SBIT」  关于 Ss Tt 区别，可见示例部分\n SUID 示例 -rwsr-xr-x. 1 root root 27856 Aug 9 2019 /usr/bin/passwd SGID 示例 -rwxr-sr-x. 1 root root 13 Aug 8 2019 /opt/test/file1 SBIT 示例 drwxrwxrwt. 9 root root 161 Apr 22 23:19 /tmp  SUID「Setuid」  对于文件，Setuid：  用字符表示：s 用八进制表示：4000\n Setuid最常用的是配合执行权限 x 使用，例如，系统中内置命令 passwd ，它默认是带有 s 权限位， passwd 命令的主要功能是修改用户的密码，而修改密码的流程是：\n 将加密后的哈希值写入到 /etc/passwd 文件对应的用户条目中。 使用pwconv工具转换到 /etc/shadow 文件中。 而普通用户是没有权限修改 /etc/passwd 和 /etc/shadow 文件 在普通用户尝试执行 passwd，该 passwd 的所有者是root并且设置了 Suid ，因此 passwd 以 root 身份执行。  PS: 当你查看进程时，你会发现，进程不是普通用户，而是passwd工具的所有者（root）\nSGID「Setgid」  对于目录，Setgid：  用字符表示：s 用八进制表示：2000\n 当一个目录拥有sgid权限时，其他用户在该目录下创建文件或目录后，它会继承目录的id，即创建的文件或目录的属组为父目录的属组。\n [root@localhost data]# mkdir project [root@localhost data]# chmod 2777 project/ [root@localhost data]# ls -lh total 0 drwxrwsrwx 2 root root 6 Apr 20 23:42 project [root@localhost data]# su bob [bob@localhost data]$ mkdir project/test_for_bob [bob@localhost data]$ ls -lh project/ total 0 drwxrwsr-x 2 bob root 6 Apr 20 23:42 test_for_bob  SBIT「Sticky 粘滞位」  对于目录：  用字符表示：t 用八进制表示：1000\n /tmp目录就是使用了粘滞位 t，其作用是，在该目录下创建文件或目录后，仅允许其作者（所有者）进行删除操作。其他用户无法删除。\n SELinux 权限「.」 开启 SELinux 后创建的文件和目录都会在权限列显示这个点的，关闭 SELinux 后创建的文件和目录在权限列是不会显示这个点的，之前创建的文件或目录保持不变，权限列的点依然显示。\n[root@DCGH ~]# touch DCGH-later [root@DCGH ~]# mkdir DCGH-later-dir [root@DCGH ~]# ls -lZ -rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 DCGH drwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 DCGH-DIR -rw-r--r-- root root ? DCGH-later drwxr-xr-x root root ? DCGH-later-dir  ACL 权限「+」 加了ACL权限控制之后，之前具有SELinux属性的文件和目录的权限列最后一个位置全部变成了加号（+）。移除原来的ACL权限之后，恢复原样。如果加号存在，则已经有点的目录或文件，点的显示会被覆盖，但原来的SELinux属性保持不变。\n[root@DCGH ~]# setfacl -m u:dcgh:rwx * [root@DCGH ~]# ls -lZ -rw-rwxr--+ root root unconfined_u:object_r:admin_home_t:s0 DCGH drwxrwxr-x+ root root unconfined_u:object_r:admin_home_t:s0 DCGH-DIR drwxrwxr-x+ root root ? DCGH-DIR-later -rw-rwxr--+ root root ? DCGH-later [root@DCGH ~]# setfacl -b * [root@DCGH ~]# ls -lZ -rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 DCGH drwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 DCGH-DIR drwxr-xr-x root root ? DCGH-DIR-later -rw-r--r-- root root ? DCGH-later  权限控制举例 文件权限 用户对于文件的访问权限，取决于文件的用户权限部分，以及 特殊权限 和 ACL\n文件夹权限 示例，建立如下 目录结构\n. ├── level1 │ ├── file1 │ └── level11 │ └── file11 └── level2 3 directories, 2 files  用户能否在 level1 目录下创建或者访问由 level1 的目录权限决定，每个目录权限至管理目录自己的那一层级，例如 level11 目录下等创建文件夹或者访问操作，不受 level1 目录的权限限制。\numask 默认 0022\n 即使 umask 设置为 0000，后续创建文件的权限依然是 666。出于安全着想，执行权限必须手动添加。所以你会看到，目录权限为 777，而文件权限为 666\n 示例 lrwxrwxrwx. 1 root root 7 Oct 3 02:33 bin -\u0026gt; usr/bin   第一个字符的含义：  - 常规文件 b 块特殊文件 c 字符特殊文件 C 高性能（\u0026ldquo;连续数据\u0026rdquo;）文件 d 目录 D 门(Solaris 2.5及以上版本) l 符号链接 M 离线（\u0026ldquo;前已\u0026rdquo;）文件（Cray DMF） n 网络专用文件（HP-UX） p FIFO（命名管道） P 断开（Solaros 10及以上） s 套接字 ? 其他文件\n 第二个字符的含义：  r 属主的读权限\n 第三个字符的含义：  w 属主的写权限\n 第四个字符的含义：  x 属主的执行权限 S 设置了SUID，没有执行权限(权限无效) s 设置了SUID，具有执行权限\n 第五个字符的含义：  r 属组的读权限\n 第六个字符的含义：  w 属组的写权限\n 第七个字符的含义：  x 属组执行权限 S 设置了SGID，没有执行权限(权限无效) s 设置了SGID，具有执行权限\n 第八个字符的含义：  r 其他人的读权限\n 第九个字符的含义：  w 其他人的写权限\n 第十个字符的含义：  x 其他人的执行权限 T 设置了粘滞位，没有执行权限(权限无效) t 设置了粘滞位，具有执行权限\n 第十一个字符的含义：  . 没有任何其他替代访问方法的SELinux安全上下文（没有设置ACL） + 具有任何其他组合访问方法的SELinux安全上下文（设置了ACL）\n 第十二个字符的含义：该文件的硬链接数量 第十三个字符的含义：该文件的属主 第十四个字符的含义：该文件的属组 第十五个字符的含义：该文件的大小 第十六到第十八个字符的含义：最后一次修改的时间 第十九个字符的含义：文件或目录的名称 第二十个字符的含义：链接符号 第二十一个字符的含义：链接文件的源文件  其他系统的特殊权限标识 macOS 可使用如下命令查看 macOS 系统内相关的特殊权限标识\n If the file or directory has extended attributes, the permissions field printed by the -l option is followed by a \u0026lsquo;@\u0026rsquo; character. Otherwise, if the file or directory has extended security information, the permissions field printed by the -l option is followed by a \u0026lsquo;+\u0026rsquo; character.\n 如果文件或目录有扩展属性,则使用-l选项执行ls命令时，会在权限许可字段后面附加一个字符@。如果文件或目录有扩展安全信息，则使用-l选项执行ls命令时，会在权限许可字段后面附件一个字符+。\nls -l@ 或者 ls -l+  文件「unkonw.txt」、目录「Archive」、替身「Investment」相关特殊权限标识如下所示\ntotal 24 drwxr-xr-x 44 idoker staff 1408 4 8 16:10 Archive -rw-r--r--@ 1 idoker staff 888 2 22 17:26 Investment com.apple.FinderInfo\t32 com.apple.lastuseddate#PS\t16 drwxr-xr-x 21 idoker staff 672 3 15 00:33 TODO drwxr-xr-x 197 idoker staff 6304 3 22 11:21 Temp -rw-r--r--@ 1 idoker staff 952 2 22 17:03 Workspace com.apple.FinderInfo\t32 com.apple.lastuseddate#PS\t16 drwxr-xr-x 11 idoker staff 352 3 22 11:21 log -rw-r--r-- 1 idoker staff 2544 4 12 10:52 unkonw.txt  可使用 xattr 相关命令进行修改\nWindows Windows 开启 SMB 共享或者开启 ftp 共享，在 Linux 系统环境下相关权限如下所示\n待补充  参考资料 特殊权限 SUID、SGID、Sticky https://www.cnblogs.com/Q--T/p/7864795.html 刘合栋-Linux 权限位详解 https://www.cnblogs.com/liuhedong/p/10739718.html Linux中权限列中的加号及点的深度解读 https://www.linuxprobe.com/linux-authority-ask.html\n","id":9,"section":"posts","summary":"👌 2021-04-22 Linux 文件权限及文件夹说明 在工作中，利用特殊权限，往往可以事半功倍达到很多对于文件以及文件夹权限要求的设置，所以打算总结一下接触过的操作系统","tags":["Linux","CentOS"],"title":"Linux 文件权限及文件夹权限说明","uri":"https://blog.standuke.top/2021/04/2021-04-22-linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E5%8F%8A%E6%96%87%E4%BB%B6%E5%A4%B9%E6%9D%83%E9%99%90%E8%AF%B4%E6%98%8E/","year":"2021"},{"content":"👌 2021-04-11 frp 内网穿透 简介 https://gofrp.org/docs/overview/\n frp 是什么？  frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。\n 为什么使用 frp？  通过在具有公网 IP 的节点上部署 frp 服务端，可以轻松地将内网服务穿透到公网，同时提供诸多专业的功能特性，这包括：\n 客户端服务端通信支持 TCP、KCP 以及 Websocket 等多种协议。 采用 TCP 连接流式复用，在单个连接间承载更多请求，节省连接建立时间。 代理组间的负载均衡。 端口复用，多个服务通过同一个服务端端口暴露。 多个原生支持的客户端插件（静态文件查看，HTTP、SOCK5 代理等），便于独立使用 frp 客户端完成某些工作。 高度扩展性的服务端插件系统，方便结合自身需求进行功能扩展。 服务端和客户端 UI 页面。  安装配置  依赖 go 环境   编写配置文件，先通过 ./frps -c ./frps.ini 启动服务端，再通过 ./frpc -c ./frpc.ini 启动客户端。如果需要在后台长期运行，建议结合其他工具使用，例如 systemd 和 supervisor。\n frps「服务端」 以 ssh 配置为例，较好理解\n[common] bind_port = 7000  本地用于 frps 服务的端口，后期 frpc 会使用此端口与 frps 通讯确认参数\nfrpc「客户端」 以 ssh 配置为例，较好理解\n[common] server_addr = x.x.x.x server_port = 7000 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000  x.x.x.x 为公网服务器地址或域名\nfrp 会将请求 x.x.x.x:6000 的流量转发到内网机器的 22 端口。\nlocal_ip 和 local_port 配置为本地需要暴露到公网的服务地址和端口。remote_port 表示在 frp 服务端监听的端口，访问此端口的流量将会被转发到本地服务对应的端口。\n概念 frp 支持多种代理类型来适配不同的使用场景。\n   类型 描述     tcp 单纯的 TCP 端口映射，服务端会根据不同的端口路由到不同的内网服务。   udp 单纯的 UDP 端口映射，服务端会根据不同的端口路由到不同的内网服务。   http 针对 HTTP 应用定制了一些额外的功能，例如修改 Host Header，增加鉴权。   https 针对 HTTPS 应用定制了一些额外的功能。   stcp 安全的 TCP 内网代理，需要在被访问者和访问者的机器上都部署 frpc，不需要在服务端暴露端口。   sudp 安全的 UDP 内网代理，需要在被访问者和访问者的机器上都部署 frpc，不需要在服务端暴露端口。   xtcp 点对点内网穿透代理，功能同 stcp，但是流量不需要经过服务器中转。   tcpmux 支持服务端 TCP 端口的多路复用，通过同一个端口访问不同的内网服务。    参考资料 frp内网穿透部署搭建教程，内网端口暴露给了外网 https://cloud.tencent.com/developer/article/1720395 用开源免费的内网穿透工具 frp，实现远程桌面和文件传输 https://sspai.com/post/60852 使用frp进行内网穿透 https://sspai.com/post/52523\n","id":10,"section":"posts","summary":"👌 2021-04-11 frp 内网穿透 简介 https://gofrp.org/docs/overview/ frp 是什么？ frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服","tags":["frp","Network"],"title":"frp 内网穿透","uri":"https://blog.standuke.top/2021/04/2021-04-11-frp-%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/","year":"2021"},{"content":"👌 2021-02-25 Mac with Time Machine  FileInfo Filename - Mac with Time Machine Version - v1.1.2102（2021/02/25 ~ 2021/02/26） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - Mac Time Machine\n 版本修订记录：\nv1.0.2102：2021-02-25：建立 Mac with Time Machine 手册 v1.1.2102：2021-02-26：添加本地快照信息、时间线颜色说明和磁盘加密说明\nTime Machine 简介 Time Machine 是 Mac 的内置备份功能。可以使用 Time Machine 对所有文件进行自动备份，包括应用、音乐、照片、电子邮件、文稿和系统文件。通过备份，当原始文件从 Mac 永久性删除或者 Mac 中的硬盘（或 SSD）被抹掉或更换时，可以从备份恢复文件。\n[TOC]\n备份机制 增量备份，macOS 可以通过 FSEvents 监视文件系统变化，这点类似 Linux 的 inotify 机制。Time Machine 通过 FSEvents 对系统的所有变化进行持续的追踪，当发现过去一小时的系统发生变化以后，Time Machine 只对那些变化的文件进行备份。 「Time Machine 进行的第一次备份，备份文件可能会很大，因此可能需要一段比较长的时间才能完成。但是当第一次备份完成后，后来的每个后续备份应该都比较小（备份也会更快），因为后面的备份只是增量备份。」\n 本地快照「只要本地磁盘空间允许」 过去 24 小时的每小时备份 过去一个月的每日备份 过去所有月份的每周备份  本地快照「本地快照占用的空间标记为 可清除」\n 如果可用储存空间小于总储存空间的 20%，则 TM 会移除本地快照，从最旧的快照开始，直到可用储存空间超过总储存空间的 20%。 如果可用储存空间小于总储存空间的 10% 或不到 5GB，则 TM 会快速移除本地快照。如果只剩下一个快照，TM 会停止创建新快照。随着可用空间不断变大，TM 首先会使用新的快照替换以前的快照，最终会照常创建快照。\n 备份介质 详细可见参考资料： https://support.apple.com/zh-cn/HT202784\n 连接到 Mac 的外置 USB 驱动器、雷雳驱动器或 FireWire 驱动器 USB 连接的移动硬盘 支持通过 SMB 进行\u0026quot;时间机器\u0026quot;备份的联网储存 (NAS) 设备 Windows 共享或者 NAS 设备上的 SMB 共享 共享为\u0026quot;时间机器\u0026quot;备份目标位置的 Mac 把其他的 Mac 作为备份磁盘 Mac 电脑 \u0026gt;「设置」\u0026gt;「共享」\u0026gt;「共享文件」\u0026gt;「添加共享文件夹后右键文件夹高级选项」 连接到 AirPort Extreme 基站 (802.11ac) 或 AirPort 时间返回舱的外置驱动器 AirPort Extreme 设备 AirPort 时间返回舱 AirPort 设备  开启 Time Machine Mac 电脑 \u0026gt;「设置」\u0026gt;「Time Machine」打开即可\n同时需要满足如下几个要求\n Time Machine 备份留下足够的空间。建议容量是 Mac 磁盘空间的 2～4 倍 移动硬盘的磁盘文件系统格式需要为 HFS+ 或 APFS「如果不是则会在设置 Time Machine 的时候提示抹掉磁盘」  是否加密  看个人需求 加密耗时很久，酌情考虑「加密过程可以不用一次性完成，在正常退出外置硬盘并关机之后，下次再接入时磁盘会继续加密进程。」 磁盘每次接入挂载时会提示输入密码  其他选项  如果您备份到多个磁盘，可以按住 Option 键，然后从\u0026quot;时间机器\u0026quot;菜单中选取\u0026quot;浏览其他备份磁盘\u0026quot;。 要从备份中排除某些项目，请打开\u0026quot;时间机器\u0026quot;偏好设置，点按\u0026quot;选项\u0026quot;，然后点按\u0026quot;添加\u0026quot;(+) 按钮以添加要排除的项目。要停止排除某个项目（例如，外置硬盘驱动器），请选择相应的项目并点按\u0026quot;移除\u0026quot;(–) 按钮。 如果您使用\u0026quot;时间机器\u0026quot;备份至 某一网络磁盘，可以验证这些备份以确保它们处于良好状态。按住 Option 键，然后从\u0026quot;时间机器\u0026quot;菜单中选取\u0026quot;验证备份\u0026quot;。 「验证备份只有网络磁盘作为备份介质才可用」  从备份恢复 从 Time Machine 菜单中选择 \u0026ldquo;进入 Time Machine\u0026rdquo;\n 时间线 亮红色 刻度标记是可立即从本地快照或备份驱动器恢复的备份。在备份驱动器不可用时，只有本地快照是亮红色的。 暗红色 刻度标记是在备份驱动器可用后，可从该驱动器恢复的备份。在这之前，屏幕上的窗口堆栈会为该备份显示一个空白窗口。\n本地副本均为可用状态而显示成 亮红色，不在本地的副本一律都显示成 暗红色。如果您接入之前执行备份使用的硬盘，TM 会识别到所有可用副本并显示为 亮红色。\n 选择需要恢复的文件即可\n手动删除备份 默认的，Time Machine 遇到磁盘空间不够下次备份时，会自动清理以往的备份。 对于手动删除备份，一般来说由于备份文件体积巨大，删除也需要耗费极大时间。手动删除备份有如下两种方式\n通过 Time Machine 内建右键删除备份 此方式可以删除「特定备份文件（夹）」或「Time Machine 的老旧备份」\n 删除「特定备份文件（夹）」 第一步：将你的 Time Machine 磁盘连接到 Mac 电脑。 第二步：从 Time Machine 菜单栏图标处进入 Time Machine。 第三步：找到需要删除的特定文件（夹）所在的路径位置。 第四步：点击齿轮图标呼出下拉菜单，然后选择「删除XXX的所有备份」项并确认即可。  简而言之就是 进入 Time Machine 找到要删除的特定备份文件（夹） 然后右键选择**「删除XXX的所有备份」**\n 删除「Time Machine 的老旧备份」 第一步：进入 Time Machine。 第二步：在 Time Machine 右下角选择大概的时间，然后可以使用窗口右侧的滚轮来精细调节直至找到需要删除的那一个备份。  简而言之与上操作大致相同，就是右键选择**「删除所有备份」**\n进入 Time Machine 备份文件夹删除文件 此操作仅针对 删除磁盘上的所有备份数据「需要用到 terminal 命令行」\n 进入 Time Machine 的备份磁盘  cd /Volumes/Seagate\\ Backup\\ Plus\\ Drive/  找到备份文件 「Backups.backupdb」 删除「Backups.backupdb」文件夹  sudo rm -rf Backups.backupdb # 此命令会耗费较长时间  注意如果手动删除了 Backups.backupdb，那么 Backups.backupdb 会进入 回收站，那么\n 清空回收站会提示文件正在使用 选择 跳过 删不掉的文件 需要通过 terminal 命令行删除  cd /Volumes/Seagate\\ Backup\\ Plus\\ Drive/ sudo cd .Trashes sudo cd 501 sudo rm -rf Backups.backupdb  关于验证备份 验证备份用于验证备份是否可用。此操作会对比 电脑和备份 的文件校验值，若不一致则会发出通知「验证备份只有网络磁盘作为备份介质才可用」\n验证网络磁盘备份 可以用使用系统自带的 验证备份 功能来校验备份\n验证移动硬盘备份 可进入终端使用如下命令进行对比\ntmutil compare -s ! 之前的文件意味着给定的文件已更改。 + 之前的文件意味着给定的文件是新的。 - 在文件之前意味着给定的文件被删除。  参考资料 http://www.howtoip.com/how-to-verify-that-your-macs-time-machine-backups-are-working-properly/ https://zhcn.eyewated.com/%E9%AA%8C%E8%AF%81%E6%97%B6%E9%97%B4%E6%9C%BA%E5%99%A8%E5%92%8C%E6%97%B6%E9%97%B4%E8%83%B6%E5%9B%8A%E5%A4%87%E4%BB%BD/ https://www.jianshu.com/p/0f5a309cac92\n","id":11,"section":"posts","summary":"👌 2021-02-25 Mac with Time Machine FileInfo Filename - Mac with Time Machine Version - v1.1.2102（2021/02/25 ~ 2021/02/26） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - Mac Time Machine 版本修订记录： v1.0","tags":["macOS","Time Machine"],"title":"Mac With Time Machine 时间机器备份","uri":"https://blog.standuke.top/2021/02/2021-02-25-mac-with-time-machine-%E6%97%B6%E9%97%B4%E6%9C%BA%E5%99%A8%E5%A4%87%E4%BB%BD/","year":"2021"},{"content":"👌 2020-12-20 kvm 虚拟机通过 bridge 桥实现主机互通 状况 在RedHat7上搭了一台KVM服务器，创建好虚拟机之后发现，外部电脑与KVM服务器、外部机器与VM虚拟机、两台VM虚拟机之间都可以通讯，但是KVM服务器与VM虚拟机却无法通讯。此时外部电脑、KVM服务器、VM虚拟机都关闭了防火墙。\n简单一句话就是：虚拟机与宿主机之间无法互访\n解决 原理 创建一个网桥，把 虚拟机的虚拟网卡 和 物理机实体网卡 同时放置到这个网桥中\n⚠️ 注意：此操作需要在实体机配置，中间会出现网络中断，故不适合远程配置\n检察环境  ifconfig\n 物理网卡eno1、eno2 / 网桥virbr0 / 虚拟网卡macvtap0、macvtap1\n brctl show\n 网桥virbr0，相当于VMware的 VMNET8，提供NAT的网卡，当有虚拟机网卡使用桥接模式并且启动时，使用#brctl show 查看，在virbr0会有的interfaces下会出现网卡vnetX。\n创建新网桥 virsh iface-bridge eno1 br0\n创建网桥，并把eno1，虚拟机的网卡接入网桥「此时物理网卡已经是此网桥的一个成员了」\n修改虚拟机的网卡配置  关闭虚拟机 删除已有网卡 创建新的网卡连接，使用 桥接模式 桥接到方才创建的网卡「修改完成后启动虚拟机，发现虚拟机的网卡也加入了br0，此时虚拟机的网卡名由macvtapX变成了vnetX。」  参考资料 https://blog.51cto.com/cubix/1736750\n","id":12,"section":"posts","summary":"👌 2020-12-20 kvm 虚拟机通过 bridge 桥实现主机互通 状况 在RedHat7上搭了一台KVM服务器，创建好虚拟机之后发现，外部电脑与KVM服务器、外部机器与VM虚拟","tags":["KVM","Virtualization","Linux Bridge"],"title":"KVM 虚拟机通过 Bridge 桥实现主机互通","uri":"https://blog.standuke.top/2020/12/2020-12-20-kvm-%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%80%9A%E8%BF%87-bridge-%E6%A1%A5%E5%AE%9E%E7%8E%B0%E4%B8%BB%E6%9C%BA%E4%BA%92%E9%80%9A/","year":"2020"},{"content":"👌 2020-10-29 vSphere ESXi vCenter 部署安装与关系区别.md 关系与区别  vSphere  vSphere 是数据中心产品附带的软件套件。vSphere 就像 Microsoft Office 套件，其中包含许多软件，例如 MS Office，MS Excel，MS Access 等。与 Microsoft Office 一样，vSphere 也是一个软件套件，其中包含许多软件组件，例如 vCenter，ESXi，vSphere Client 等。因此，所有这些软件组件的组合就是 vSphere。vSphere 不是可以安装和使用的特定软件，\u0026ldquo;它只是具有其他子组件的软件包名称\u0026rdquo;。\n ESXi  ESXi，vSphere 客户端和 vCenter是 VMware vSphere 的组件。 ESXi 服务器是 vSphere 最重要的部分。ESXi 是虚拟化服务器。这是 1 类管理程序。所有虚拟机或来宾操作系统均安装在 ESXi 服务器上。要安装，管理和访问位于 ESXi 服务器上方的那些虚拟服务器，您将需要 vSphere 套件中称为 vSphere Client 的其他部分。现在，vSphere Client 允许管理员连接到 ESXi 服务器并访问或管理虚拟机。 vSphere Client 是基于 HTML5 / Web 的管理门户。管理员登录 Web 浏览器以访问 vSphere Client，以管理 ESXi 服务器。适用于 Windows 或 C＃ 的 vSphere Client 不再可用，在 vSphere 6.7 中已被基于 HTML5 的 vSphere Client 取代，从而无需安装 vSphere Client 软件来访问 ESXi 主机。\n vCenter Server  vCenter Server 是另一套 vSphere 套件。 vCenter Server 有两种。 vCenter Server 可以安装在 Windows Server 上，也可以是基于 Linux 的虚拟设备。VMware将停止使用基于 Winodws 的 vCenter Server，并在将来仅发布基于 Linux 的 vCenter 设备。 VMware vCenter Server 是一个集中式管理应用程序，可让您集中管理虚拟机和 ESXi 主机。 vSphere Client 再次用于访问 vCenter Server 并最终管理 ESXi 服务器。对于需要 vMotion，VMware High Availability，VMware Update Manager，VMware Distributed Resource Scheduler（DRS）等企业功能的企业，vCenter Server 是强制性的。例如，您可以轻松地在 vCenter 中克隆现有虚拟机服务器。因此，vCenter 是vSphere 套件的另一个重要部分。您必须单独购买 vCenter Server 许可证。\n安装建议 新装环境默认全部安装 6.7 版本「安装包为 VMvisor-Installer-6.7.0.U3」，安装之后使用 VCSA 管理「安装包为 VCSA-all-6.7.0」。\n安装步骤 安装包概览 vcsa 是 Linux 版的 vcenter（自带数据库），vim 是Windows 版的 vcenter（要 SQL server）\nESXi 安装 略\nVCSA「vCenter Server Appliance」安装 有 DNS 解析环境 https://blog.51cto.com/4690837/2419974 无 DNS 解析环境 https://blog.51cto.com/3701740/2484158 https://www.mr-mao.cn/archives/deployment-vcenter6-7-without-dns.html\n注意事项 最近几天把旧的vCenter升级到6.7，发现无法连接到节点，提示无权。\n查找相关资料发现是锁定模式的严格模式开启了，只能从原来的vcenter连接到节点，不能通过其他方式连接。\n从 DCUI 启用或禁用锁定模式（最简单）：\n直接登录到 ESXi 主机。 从主机上打开 DCUI。 按 F2 进行初始设置。 按 Enter 切换配置锁定模式(lockdown)设置。 从 vSphere Web Client 启用或禁用锁定模式（需要已经连接的vcenter）：\n在 vSphere Web Client 清单中浏览到主机。 单击管理选项卡，然后单击设置。 在\u0026quot;系统\u0026quot;下，选择安全配置文件。 在\u0026quot;锁定模式\u0026quot;面板中，单击编辑。 单击锁定模式并选择其中一个锁定模式选项。 关闭之后，在新的Vcenter输入ESXI节点密码，即可管理。\n许可证 激活码 ESXi vSphere 6.0 已淘汰\nESXi vSphere 6.7 ESXi SN:\nHV4WC-01087-1ZJ48-031XP-9A843 👈 NF0F3-402E3-MZR80-083QP-3CKM2 4F6FX-2W197-8ZKZ9-Y31ZM-1C3LZ JZ2E9-6D2DK-XZQD0-632E4-33E7Z MZ48M-DNK56-ZZJD0-RTCE2-9321X 0Y0AJ-4P29H-LZV81-59AQ2-C291V\n👆https://www.cnblogs.com/walkersss/p/12458218.html\nvCenter Server 6 Standard SN:\nHG612-FH19H-08DL1-V19X2-1VKND 👈 NU4JA-4V2DQ-48428-T32GK-8VRN4 0Y4H2-8P217-H8900-M8AE4-2LH44 NA658-2308J-08809-93AQ6-278J0\n👆http://www.linuxmysql.com/16/2019/1012.htm\nESXi vSphere 7.0 这个暂时不用于生产环境\n","id":13,"section":"posts","summary":"👌 2020-10-29 vSphere ESXi vCenter 部署安装与关系区别.md 关系与区别 vSphere vSphere 是数据中心产品附带的软件套件。vSphere 就像 Microsoft Office 套件，其中包含许多软件，例如 MS Offic","tags":["vSphere","ESXi","vCenter","Virtualization"],"title":"vSphere ESXi vCenter 部署安装与关系区别","uri":"https://blog.standuke.top/2020/10/2020-10-29-vsphere-esxi-vcenter-%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%B3%E7%B3%BB%E5%8C%BA%E5%88%AB/","year":"2020"},{"content":"👌 2020-10-13 ClickHouse 官方文档摘要与深入  FileInfo Filename - ClickHouse 官方文档摘要与深入 Version - v1.0.2010（2020/10/20 ~ 2020/10/22） Author - NUO standuke Email - shadowdoker@gmail.com DescriptionKey - ClickHouse Official Document step in\n 列式数据库与行式数据库 列式与行式数据库的主要区别在于数据的存储方式，对于数据库来说本质是一样的。以下为列式数据库与行式数据库的相关比较。也可以理解为优势劣势。\n查询方面\n 行式数据库基本上可以理解为需要扫描所有数据，列式则只扫描需要获取的相关字段的列即可 对于列存储，可以很方便的建立每一个列的索引信息「实则 每一列就是索引」 如果我们的需求就是查询所有字段，那个这个时候列式数据库的处理方式就是先把所有列查询出来，然后再拼接起来，速度方面是比不上行式数据库的。「这也就是为什么列式数据库大多用于大数据分析，因为大数据分析每一次查询不需要获取所有的字段信息」  数据压缩\n 行式数据库因为存贮数据是一行行的来存贮，而每一行数据的差异性太大，所以压缩比很小。 列式数据库则不同，因为是按照一列列来存贮，每一列的数据的相同性极高，这就为压缩埋下了很好的种子，压缩比可以达到很大，可以达到5～20倍以上。 压缩首先带来的硬盘上存储空间的降低，但是硬盘又不值钱。它的真正意义在于：数据占用的硬盘空间越小，查询引擎花在IO上的时间就越少(不管是从硬盘里面把数据读入内存，还是从内存里面把数据读入CPU)。同时要记住的是数据压缩之后，要进行处理很多时候要需要解压缩(不管是Column-Store还是Row-Store), 因此压缩比不是我们追求的唯一，因为后面解压也需要花时间，因此一般会在压缩比和解压速度之间做一个权衡。  块遍历 块迭代计算\n 块遍历(Block Iteration)是相对于单记录遍历(per-tuple iteration)而言的，其实说白了就是一种批量化的操作。 这种提高性能的方法在Row-Store里面是case-by-case实现的(不是一种共识), 而对于Column-Store来说已经形成共识，大家都是这么做的。而如果column的值是字节意义上等宽的，比如数字类型，Column-Store可以进一步提高性能，因为查询引擎要从一个Block里取出其中一个值进行处理的时候直接用数组下标就可以获取数据，进一步提升性能。  延迟物化\n 为了能够把底层存储格式(面向Column的), 跟用户查询表达的意思(Row)对应上，在一个查询的生命周期的某个时间点，一定要把数据转换成Row的形式，这在Column-Store里面被称为物化(Materization)。 我这里把物化理解为对象的实例化。 一般(Naive)的做法是从文件系统读出三列的数据，马上物化成一行行的person数据，然后应用两个过滤条件: id \u0026gt; 10 和 age \u0026gt; 20 , 过滤完了之后从数据里面抽出 name 字段，作为最后的结果 延迟物化的做法则会先不拼出行式数据，直接在Column数据上分别应用两个过滤条件，从而得到两个满足过滤条件的bitmap, 然后再把两个bitmap做位与(bitwise AND)的操作得到同时满足两个条件的所有的bitmap，因为最后用户需要的只是 name 字段而已，因此下一步我们拿着这些 position 对 name 字段的数据进行过滤就得到了最终的结果。  隐式连接 Invisible Join\n Invisible Join 针对的场景是数仓里面的星型模型(Star Schema), 如果用户查询符合下面的模式就可以应用Invisible Join「传统方案一: 按Selectivity依次JOIN、延迟物化」 以下为 Invisible Join 思维 把所有过滤条件应用到每个维度表上，得到符合条件的维度表的主键(同时也是事实表的外键)。 遍历事实表，并且查询第一步得到的所有外键的值，得到符合条件的bitmap(s), 这里会有多个bitmap，因为维度表可能有多个。 对第二步的多个bitmap做AND操作，得到最终事实表里面符合过滤条件的bitmap。 根据第三步的事实表的bitmap以及第一步的符合条件的维度表的主键值，组装出最终的返回值。  https://zhuanlan.zhihu.com/p/54433448 https://zhuanlan.zhihu.com/p/54484592\nOLTP 与 OLAP OLTP（On-Line Transaction Processing，联机事务处理） 多为对数据库的数据操作，例如「增删改查」，以及业务类系统主要供基层人员使用，进行一线业务操作\nOLAP（On-Line Analytical Processing，联机分析处理） 多为对数据的查询分析，数据分析的目标则是探索并挖掘数据价值，作为企业高层进行决策的参考，此时需要查询大量数据，分析其中的关联性\n从功能角度来看，OLTP 负责基本业务的正常运转，而业务数据积累时所产生的价值信息则被 OLAP 不断呈现，企业高层通过参考这些信息会不断调整经营方针，也会促进基础业务的不断优化，这是 OLTP 与 OLAP 最根本的区别。\nOLAP 场景的关键特征「官方」  大多数是读请求 数据总是以相当大的批(\u0026gt; 1000 rows)进行写入 不修改已添加的数据 每次查询都从数据库中读取大量的行，但是同时又仅需要少量的列 宽表，即每个表包含着大量的列 较少的查询(通常每台服务器每秒数百个查询或更少) 对于简单查询，允许延迟大约50毫秒 列中的数据相对较小： 数字和短字符串(例如，每个URL 60个字节) 处理单个查询时需要高吞吐量（每个服务器每秒高达数十亿行） 事务不是必须的 对数据一致性要求低 每一个查询除了一个大表外都很小 查询结果明显小于源数据，换句话说，数据被过滤或聚合后能够被盛放在单台服务器的内存中  存储 行式数据库系统：处于同一行中的数据总是被物理的存储在一起 列式数据库：对于存储而言，列式数据库总是将同一列的数据存储在一起，不同列的数据也总是分开存储。\n数据按列存储并且按列执行\n聚合与非聚合数据  「Aggregated and Non-aggregated Data」 此处的聚合与非聚合可以近似理解为 oracle 数据库中为了方便查询生成的视图\n 有一种流行的观点认为，想要有效的计算统计数据，必须要聚合数据，因为聚合将降低数据量。\n但是数据聚合是一个有诸多限制的解决方案，例如：\n 你必须提前知道用户定义的报表的字段列表 用户无法自定义报表 当聚合条件过多时，可能不会减少数据，聚合是无用的。 存在大量报表时，有太多的聚合变化（组合爆炸） 当聚合条件有非常大的基数时（如：url），数据量没有太大减少（少于两倍） 聚合的数据量可能会增长而不是收缩 用户不会查看我们为他生成的所有报告，大部分计算将是无用的 各种聚合可能违背了数据的逻辑完整性 如果我们直接使用非聚合数据而不进行任何聚合时，我们的计算量可能是减少的。  然而，相对于聚合中很大一部分工作被离线完成，在线计算需要尽快的完成计算，因为用户在等待结果。\nYandex.Metrica 有一个专门用于聚合数据的系统，称为Metrage，它可以用作大部分报表。 从2009年开始，Yandex.Metrica还为非聚合数据使用专门的OLAP数据库，称为OLAPServer，它以前用于报表构建系统。 OLAPServer可以很好的工作在非聚合数据上，但是它有诸多限制，导致无法根据需要将其用于所有报表中。如，缺少对数据类型的支持（只支持数据），无法实时增量的更新数据（只能通过每天重写数据完成）。OLAPServer不是一个数据库管理系统，它只是一个数据库。\n为了消除OLAPServer的这些局限性，解决所有报表使用非聚合数据的问题，我们开发了ClickHouse数据库管理系统。\nclickhouse 特性及限制   多服务器分布式处理 上面提到的列式数据库管理系统中，几乎没有一个支持分布式的查询处理。 在ClickHouse中，数据可以保存在不同的shard上，每一个shard都由一组用于容错的replica组成，查询可以并行地在所有shard上进行处理。这些对用户来说是透明的\n  向量引擎 为了高效的使用CPU，数据不仅仅按列存储，同时还按向量(列的一部分)进行处理，这样可以更加高效地使用CPU。\n  支持近似计算 ClickHouse提供各种各样在允许牺牲数据精度的情况下对查询进行加速的方法： 用于近似计算的各类聚合函数，如：distinct values, medians, quantiles 基于数据的部分样本进行近似查询。这时，仅会从磁盘检索少部分比例的数据。 不使用全部的聚合条件，通过随机选择有限个数据聚合条件进行聚合。这在数据聚合条件满足某些分布条件下，在提供相当准确的聚合结果的同时降低了计算资源的使用。\n  限制 没有完整的事务支持。 缺少高频率，低延迟的修改或删除已存在数据的能力。仅能用于批量删除或修改数据，但这符合 GDPR。 稀疏索引使得ClickHouse不适合通过其键检索单行的点查询。\n  性能 单个大查询的吞吐量 吞吐量可以使用每秒处理的行数或每秒处理的字节数来衡量。如果数据被放置在page cache中，则一个不太复杂的查询在单个服务器上大约能够以2-10GB／s（未压缩）的速度进行处理（对于简单的查询，速度可以达到30GB／s）。如果数据没有在page cache中的话，那么速度将取决于你的磁盘系统和数据的压缩率。例如，如果一个磁盘允许以400MB／s的速度读取数据，并且数据压缩率是3，则数据的处理速度为1.2GB/s。这意味着，如果你是在提取一个10字节的列，那么它的处理速度大约是1-2亿行每秒。 对于分布式处理，处理速度几乎是线性扩展的，但这受限于聚合或排序的结果不是那么大的情况下。\n处理短查询的延迟时间 如果一个查询使用主键并且没有太多行(几十万)进行处理，并且没有查询太多的列，那么在数据被page cache缓存的情况下，它的延迟应该小于50毫秒(在最佳的情况下应该小于10毫秒)。 否则，延迟取决于数据的查找次数。如果你当前使用的是HDD，在数据没有加载的情况下，查询所需要的延迟可以通过以下公式计算得知： 查找时间（10 ms） * 查询的列的数量 * 查询的数据块的数量。\n处理大量短查询的吞吐量 在相同的情况下，ClickHouse可以在单个服务器上每秒处理数百个查询（在最佳的情况下最多可以处理数千个）。但是由于这不适用于分析型场景。==因此我们建议每秒最多查询100次。==\n数据的写入性能 我们建议每次写入不少于1000行的批量写入，或每秒不超过一个写入请求。当使用tab-separated格式将一份数据写入到MergeTree表中时，写入速度大约为50到200MB/s。如果您写入的数据每行为1Kb，那么写入的速度为50，000到200，000行每秒。如果您的行更小，那么写入速度将更高。==为了提高写入性能，您可以使用多个INSERT进行并行写入，这将带来线性的性能提升。==\n引擎 使用的所有表都是由数据库引擎所提供的 默认情况下，ClickHouse使用自己的数据库引擎，该引擎提供可配置的表引擎和所有支持的SQL语法.\n数据库引擎 所有表都是由数据库引擎所提供，默认情况下，ClickHouse 使用自己的数据库引擎，该引擎提供可配置的表引擎和所有支持的SQL语法。 此外，还可以使用如下数据库引擎：MySQL、Lazy\nMySQL MySQL 引擎用于将远程的 MySQL 服务器中的表映射到 ClickHouse 中，并允许您对表进行 INSERT 和SELECT 查询，以方便您在 ClickHouse 与 MySQL 之间进行数据交换。 MySQL 数据库引擎会将对其的查询转换为 MySQL 语法并发送到 MySQL 服务器中，因此您可以执行诸如SHOW TABLES 或 SHOW CREATE TABLE 之类的操作。 但无法对其执行以下操作：RENAME、CREATE TABLE、ALTER\nLazy 在最后一次访问之后，仅在 expiration_time_in_seconds 秒内将表保留在RAM中。 只能与 * Log 表一起使用。 它经过优化，可以存储许多小的 * Log 表，两次访问之间的时间间隔很长。\n表引擎 表引擎（即表的类型）决定了：\n 数据的存储方式和位置，写到哪里以及从哪里读取数据 支持哪些查询以及如何支持 并发数据访问 是否使用索引（如果存在） 是否可以执行多线程请求 数据复制参数  使用要求 \u0026amp; 安装建议 CPU CPU ==必须支持SSE4.2指令集==。要使用不支持SSE4.2或具有AArch64或PowerPC64LE体系结构的处理器运行ClickHouse，您应该从源代码构建ClickHouse。 ClickHouse实现并行数据处理并使用所有可用的硬件资源。 在选择处理器时，考虑到ClickHouse在==具有大量内核但时钟速率较低的配置中的工作效率要高于具有较少内核和较高时钟速率的配置==。 例如，具有2600MHz的16核心优于具有3600MHz的8核心。 ==建议使用 睿频加速 和 超线程 技术==。 它显着提高了典型工作负载的性能。\nCPU Scaling Governor「CPU 缩放调控器」 建议始终开启使用性能缩放调节器。按需缩放比例调速器在持续高需求的情况下效果更差。\necho 'performance' | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor  CPU Limitations「CPU限制」 处理器可能会过热。 使用 dmesg 看看CPU的时钟速率是否由于过热而受到限制。 此限制也可以在数据中心级别的外部设置。 您可以使用 turbostat 在负载下监视它。\nSwap File 禁用生产环境的交换文件\nRAM 对于少量数据（高达-200GB压缩），最好使用与数据量一样多的内存。 对于大量数据和处理交互式（在线）查询时，应使用合理数量的RAM（128GB或更多），以便热数据子集适合页面缓存。 即使对于每台服务器约50TB的数据量，使用128GB的RAM与64GB相比显着提高了查询性能。\n不要禁用过量使用。cat /proc/sys/vm/overcommit_memory 的值应为 0 或 1。\n$ echo 0 | sudo tee /proc/sys/vm/overcommit_memory  Huge Pages 始终禁用透明的大页面。 它会干扰内存分配器，从而导致性能显着下降。\n$ echo 'madvise' | sudo tee /sys/kernel/mm/transparent_hugepage/enabled  使用perf top观察内核在内存管理上花费的时间。永久大页面也不需要分配。\nStorage Subsystem 如果您的预算允许您使用SSD，请使用SSD。如果没有，请使用 HDD 使用 SATA HDD 7200 RPM 即可。\n优先选择带有大量本地硬盘驱动器的服务器，而不是带有附加磁盘架的小量服务器。 但是对于要存储很少查询的档案，附加存储可以使用。\nRAID 当使用硬盘，你可以结合他们的RAID-10，RAID-5，RAID-6或RAID-50。 对于Linux，软件RAID更好（与 mdadm). 我们不建议使用LVM。 当创建RAID-10，选择 far 布局。 如果您的预算允许，请选择RAID-10。\n如果您有==超过4个磁盘，请使用RAID-6（首选）或RAID-50，而不是RAID-5==。 当使用RAID-5、RAID-6或RAID-50时，始终增加stripe_cache_size，因为默认值通常不是最佳选择。\n$ echo 4096 | sudo tee /sys/block/md2/md/stripe_cache_size  使用以下公式，从设备数量和块大小计算确切数量: 2 * num_devices * chunk_size_in_bytes / 4096.\n1025KB的块大小足以满足所有RAID配置。切勿将块大小设置得太小或太大。\n您可以在SSD上使用RAID-0。无论使用何种RAID，始终使用复制来保证数据安全。\n使用长队列启用NCQ。 对于HDD，选择CFQ调度程序，对于SSD，选择noop。 不要减少 \u0026lsquo;readahead\u0026rsquo; 设置。对于HDD，启用写入缓存。\nFile System ==Ext4是最可靠的选择==。设置挂载选项 noatime、nobarrier XFS也是合适的，但它还没有经过 ClickHouse 的彻底测试。 大多数其他文件系统也应该正常工作。在具有延迟分配的文件系统工作得更好。\nLinux Kernel 不要使用过时的Linux内核\nNetwork 如果您使用的是IPv6，请增加路由缓存的大小。 3.2之前的Linux内核在IPv6实现方面遇到了许多问题。\n如果可能的话，至少使用一个10GB的网络。 1Gb也可以工作，但对于使用数十tb的数据修补副本或处理具有大量中间数据的分布式查询，情况会更糟。\nZooKeeper 环境中可能已有 ZooKeeper 并且此 Zookeeper 已用于其他目的。只要此 Zookeeper 没有超负荷，可以使用相同的 zookeeper 安装。 建议==全新安装 Zookeeper – 3.4.9 或更新版本==，Linux 默认发行版提供的版本可能已经过时。\n请勿使用手动编写的脚本在不同的 ZooKeeper 群集之间传输数据，因为对于序列节点来说传输结果将是不正确的。出于相同的原因，切勿使用 zkcopy 实用程序： https://github.com/ksprojects/zkcopy/issues/15\n如果要将现有ZooKeeper集群分为两个，正确的方法是增加其副本的数量，然后将其重新配置为两个独立的集群。\n不要在与ClickHouse相同的服务器上运行ZooKeeper。 由于ZooKeeper对延迟非常敏感，ClickHouse可能会利用所有可用的系统资源。\n==使用默认设置，ZooKeeper是一个定时炸弹==: 使用默认配置时，ZooKeeper服务器不会从旧快照和日志中删除文件（请参阅 autopurge），这是操作员的责任。 必须拆除炸弹 下面的ZooKeeper（3.5.1）配置在Yandex中使用。梅地卡生产环境截至2017年5月20日:\ncfg # http://hadoop.apache.org/zookeeper/docs/current/zookeeperAdmin.html # The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take # This value is not quite motivated initLimit=300 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=10 maxClientCnxns=2000 # It is the maximum value that client may request and the server will accept. # It is Ok to have high maxSessionTimeout on server to allow clients to work with high session timeout if they want. # But we request session timeout of 30 seconds by default (you can change it with session_timeout_ms in ClickHouse config). maxSessionTimeout=60000000 # the directory where the snapshot is stored. dataDir=/opt/zookeeper/{{ cluster['name'] }}/data # Place the dataLogDir to a separate physical disc for better performance dataLogDir=/opt/zookeeper/{{ cluster['name'] }}/logs autopurge.snapRetainCount=10 autopurge.purgeInterval=1 # To avoid seeks ZooKeeper allocates space in the transaction log file in # blocks of preAllocSize kilobytes. The default block size is 64M. One reason # for changing the size of the blocks is to reduce the block size if snapshots # are taken more often. (Also, see snapCount). preAllocSize=131072 # Clients can submit requests faster than ZooKeeper can process them, # especially if there are a lot of clients. To prevent ZooKeeper from running # out of memory due to queued requests, ZooKeeper will throttle clients so that # there is no more than globalOutstandingLimit outstanding requests in the # system. The default limit is 1,000.ZooKeeper logs transactions to a # transaction log. After snapCount transactions are written to a log file a # snapshot is started and a new transaction log file is started. The default # snapCount is 10,000. snapCount=3000000 # If this option is defined, requests will be will logged to a trace file named # traceFile.year.month.day. #traceFile= # Leader accepts client connections. Default value is \u0026quot;yes\u0026quot;. The leader machine # coordinates updates. For higher update throughput at thes slight expense of # read throughput the leader can be configured to not accept clients and focus # on coordination. leaderServes=yes standaloneEnabled=false dynamicConfigFile=/etc/zookeeper-{{ cluster['name'] }}/conf/zoo.cfg.dynamic  Java version Java(TM) SE Runtime Environment (build 1.8.0_25-b17) Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)  JVM parameters NAME=zookeeper-{{ cluster['name'] }} ZOOCFGDIR=/etc/$NAME/conf # TODO this is really ugly # How to find out, which jars are needed? # seems, that log4j requires the log4j.properties file to be in the classpath CLASSPATH=\u0026quot;$ZOOCFGDIR:/usr/build/classes:/usr/build/lib/*.jar:/usr/share/zookeeper/zookeeper-3.5.1-metrika.jar:/usr/share/zookeeper/slf4j-log4j12-1.7.5.jar:/usr/share/zookeeper/slf4j-api-1.7.5.jar:/usr/share/zookeeper/servlet-api-2.5-20081211.jar:/usr/share/zookeeper/netty-3.7.0.Final.jar:/usr/share/zookeeper/log4j-1.2.16.jar:/usr/share/zookeeper/jline-2.11.jar:/usr/share/zookeeper/jetty-util-6.1.26.jar:/usr/share/zookeeper/jetty-6.1.26.jar:/usr/share/zookeeper/javacc.jar:/usr/share/zookeeper/jackson-mapper-asl-1.9.11.jar:/usr/share/zookeeper/jackson-core-asl-1.9.11.jar:/usr/share/zookeeper/commons-cli-1.2.jar:/usr/src/java/lib/*.jar:/usr/etc/zookeeper\u0026quot; ZOOCFG=\u0026quot;$ZOOCFGDIR/zoo.cfg\u0026quot; ZOO_LOG_DIR=/var/log/$NAME USER=zookeeper GROUP=zookeeper PIDDIR=/var/run/$NAME PIDFILE=$PIDDIR/$NAME.pid SCRIPTNAME=/etc/init.d/$NAME JAVA=/usr/bin/java ZOOMAIN=\u0026quot;org.apache.zookeeper.server.quorum.QuorumPeerMain\u0026quot; ZOO_LOG4J_PROP=\u0026quot;INFO,ROLLINGFILE\u0026quot; JMXLOCALONLY=false JAVA_OPTS=\u0026quot;-Xms{{ cluster.get('xms','128M') }} \\ -Xmx{{ cluster.get('xmx','1G') }} \\ -Xloggc:/var/log/$NAME/zookeeper-gc.log \\ -XX:+UseGCLogFileRotation \\ -XX:NumberOfGCLogFiles=16 \\ -XX:GCLogFileSize=16M \\ -verbose:gc \\ -XX:+PrintGCTimeStamps \\ -XX:+PrintGCDateStamps \\ -XX:+PrintGCDetails -XX:+PrintTenuringDistribution \\ -XX:+PrintGCApplicationStoppedTime \\ -XX:+PrintGCApplicationConcurrentTime \\ -XX:+PrintSafepointStatistics \\ -XX:+UseParNewGC \\ -XX:+UseConcMarkSweepGC \\ -XX:+CMSParallelRemarkEnabled\u0026quot;  Salt init description \u0026quot;zookeeper-{{ cluster['name'] }} centralized coordination service\u0026quot; start on runlevel [2345] stop on runlevel [!2345] respawn limit nofile 8192 8192 pre-start script [ -r \u0026quot;/etc/zookeeper-{{ cluster['name'] }}/conf/environment\u0026quot; ] || exit 0 . /etc/zookeeper-{{ cluster['name'] }}/conf/environment [ -d $ZOO_LOG_DIR ] || mkdir -p $ZOO_LOG_DIR chown $USER:$GROUP $ZOO_LOG_DIR end script script . /etc/zookeeper-{{ cluster['name'] }}/conf/environment [ -r /etc/default/zookeeper ] \u0026amp;\u0026amp; . /etc/default/zookeeper if [ -z \u0026quot;$JMXDISABLE\u0026quot; ]; then JAVA_OPTS=\u0026quot;$JAVA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=$JMXLOCALONLY\u0026quot; fi exec start-stop-daemon --start -c $USER --exec $JAVA --name zookeeper-{{ cluster['name'] }} \\ -- -cp $CLASSPATH $JAVA_OPTS -Dzookeeper.log.dir=${ZOO_LOG_DIR} \\ -Dzookeeper.root.logger=${ZOO_LOG4J_PROP} $ZOOMAIN $ZOOCFG end script  同构集群 异构集群 区别在于：组成集群系统的计算机之间的体系结构是否相同。\n一句话概括：异构集群\u0026ndash;计算归计算，存储归存储；同构集群（瑶池方案）\u0026ndash;计算存储一体化。\n分片 \u0026amp; 副本备份 \u0026amp; 节点    分片/副本 分片1 分片2 分片3     副本1 Node1 Node2 Node3   副本2 Node4 Node5 Node6   副本3 Node7 Node8 Node9    分片（shard）：一个分片代表一组机器，分片内部各机器存储相同的数据（分布式文件系统），所有分片中的任一个想加起来等于完整的数据。集群的性能取决于分片的数量。各个分片可以具有不同的权重（比如说有的机器性能好存储空间大，那么可以权重设置高一点）。如上图，共3个分片，其中147属于一个分片，258属于一个分片，369属于一个分片。实际运行中，各分片各取一台机器共3台机器来计算，其它的机器只作为备份之用，并不参与实际计算。\n备份（replica）：同一个分片内，各个节点互为备份，记住是互为备份，没有主次之分，因为他们是完全一模一样的，相互补位。任何时候，只要不发生故障，他们都是一模一样的，这叫同一性。上图中147互为备份。\n节点（node）：一个节点就是一台机器，如上就是一个3x3的有9个节点的分布式集群。\n公司现有环境规划 无副本，多分片，RAID5\n参数配置文件详解 ClickHouse 核心的配置文件：\n config.xml 端口配置、本地机器名配置、内存设置等 metrika.xml 集群配置、ZK 配置、分片配置等 users.xml 权限、配额设置  ","id":14,"section":"posts","summary":"👌 2020-10-13 ClickHouse 官方文档摘要与深入 FileInfo Filename - ClickHouse 官方文档摘要与深入 Version - v1.0.2010（2020/10/20 ~ 2020/10/22） Author - NUO standuke Email - shadowdoker@gmail.com DescriptionKey - ClickHouse Official","tags":null,"title":"ClickHouse 官方文档摘要与深入","uri":"https://blog.standuke.top/2020/10/2020-10-13-clickhouse-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E6%91%98%E8%A6%81%E4%B8%8E%E6%B7%B1%E5%85%A5/","year":"2020"},{"content":"👌 2020-07-01 dmidecode 使用脚本 简介 dmidecode命令可以让你在Linux系统下获取有关硬件方面的信息。dmidecode的作用是将DMI数据库中的信息解码，以可读的文本方式显示。由于DMI信息可以人为修改，因此里面的信息不一定是系统准确的信息。dmidecode遵循SMBIOS/DMI标准，其输出的信息包括BIOS、系统、主板、处理器、内存、缓存等等。\nDMI（Desktop Management Interface,DMI）就是帮助收集电脑系统信息的管理系统，DMI信息的收集必须在严格遵照SMBIOS规范的前提下进行。SMBIOS（System Management BIOS）是主板或系统制造者以标准格式显示产品管理信息所需遵循的统一规范。SMBIOS和DMI是由行业指导机构Desktop Management Task Force(DMTF)起草的开放性的技术标准，其中DMI设计适用于任何的平台和操作系统。\nDMI充当了管理工具和系统层之间接口的角色。它建立了标准的可管理系统更加方便了电脑厂商和用户对系统的了解。DMI的主要组成部分是Management Information Format(MIF)数据库。这个数据库包括了所有有关电脑系统和配件的信息。通过DMI，用户可以获取序列号、电脑厂商、串口信息以及其它系统配件信息。\ndmidecode 参数 string 列表  bios-vendor bios-version bios-release-date system-manufacturer system-product-name system-version system-serial-number system-uuid system-family baseboard-manufacturer baseboard-product-name baseboard-version baseboard-serial-number baseboard-asset-tag chassis-manufacturer chassis-type chassis-version chassis-serial-number chassis-asset-tag processor-family processor-manufacturer processor-version processor-frequency  常用命令「用于生产」  查看服务器型号：dmidecode -s system-product-name 查看系统序列号 sn：dmidecode -s system-serial-number  查看主板的序列号：dmidecode -s baseboard-serial-number 查看内存信息：dmidecode -t memory 查看OEM信息：dmidecode -t 11\nman 手册 -s, --string KEYWORD Only display the value of the DMI string identified by KEYWORD. KEYWORD must be a keyword from the following list: bios-vendor, bios-version, bios-release-date, system-manufacturer, system- product-name, system-version, system-serial-number, system-uuid, system-family, baseboard-manufacturer, baseboard-product-name, baseboard-version, baseboard-serial-number, baseboard-asset-tag, chassis-manufacturer, chassis-type, chassis-version, chassis- serial-number, chassis-asset-tag, processor-family, processor- manufacturer, processor-version, processor-frequency. Each key‐ word corresponds to a given DMI type and a given offset within this entry type. Not all strings may be meaningful or even defined on all systems. Some keywords may return more than one result on some systems (e.g. processor-version on a multi-pro‐ cessor system). If KEYWORD is not provided or not valid, a list of all valid keywords is printed and dmidecode exits with an error. This option cannot be used more than once.  -t, --type TYPE Only display the entries of type TYPE. TYPE can be either a DMI type number, or a comma-separated list of type numbers, or a keyword from the following list: bios, system, baseboard, chas‐ sis, processor, memory, cache, connector, slot. Refer to the DMI TYPES section below for details. If this option is used more than once, the set of displayed entries will be the union of all the given types. If TYPE is not provided or not valid, a list of all valid keywords is printed and dmidecode exits with an error.  DMI TYPES The SMBIOS specification defines the following DMI types: Type Information ──────────────────────────────────────────── 0 BIOS 1 System 2 Baseboard 3 Chassis 4 Processor 5 Memory Controller 6 Memory Module 7 Cache 8 Port Connector 9 System Slots 10 On Board Devices 11 OEM Strings 12 System Configuration Options 13 BIOS Language 14 Group Associations 15 System Event Log 16 Physical Memory Array 17 Memory Device 18 32-bit Memory Error 19 Memory Array Mapped Address 20 Memory Device Mapped Address 21 Built-in Pointing Device 22 Portable Battery 23 System Reset 24 Hardware Security 25 System Power Controls 26 Voltage Probe 27 Cooling Device 28 Temperature Probe 29 Electrical Current Probe 30 Out-of-band Remote Access 31 Boot Integrity Services 32 System Boot 33 64-bit Memory Error 34 Management Device 35 Management Device Component 36 Management Device Threshold Data 37 Memory Channel 38 IPMI Device 39 Power Supply 41 Onboard Devices Extended Information 42 Management Controller Host Interface Additionally, type 126 is used for disabled entries and type 127 is an end-of-table marker. Types 128 to 255 are for OEM-specific data. dmidecode will display these entries by default, but it can only decode them when the vendors have contributed documentation or code for them. Keywords can be used instead of type numbers with --type. Each keyword is equivalent to a list of type numbers: Keyword Types ────────────────────────────── bios 0, 13 system 1, 12, 15, 23, 32 baseboard 2, 10, 41 chassis 3 processor 4 memory 5, 6, 16, 17 cache 7 connector 8 slot 9 Keywords are matched case-insensitively. The following command lines are equivalent: · dmidecode --type 0 --type 13 · dmidecode --type 0,13 · dmidecode --type bios · dmidecode --type BIOS  参考资料\nLinux命令大全\n","id":15,"section":"posts","summary":"👌 2020-07-01 dmidecode 使用脚本 简介 dmidecode命令可以让你在Linux系统下获取有关硬件方面的信息。dmidecode的作用是将DMI数据库中的信息解","tags":["CentOS","Linux"],"title":"dmidecode 使用脚本","uri":"https://blog.standuke.top/2020/07/2020-07-01-dmidecode-%E4%BD%BF%E7%94%A8%E8%84%9A%E6%9C%AC/","year":"2020"},{"content":"👌 2020-03-31 创建 Windows Server 2012 R2 qcow2 格式虚拟机模板  FileInfo Filename - 创建 Windows Server 2012 R2 qcow2 格式虚拟机模板 Version - v1.1.2003（2020/03/31 ~ 2020/03/31） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Windows Server 2012 R2 qcow2 cloudbase init openstack\n 需求 Openstack 虚拟化需要\n工具准备 操作系统环境 以下为 gui 环境必须软件\n Linux 系统「CentOS 7.7」GNOME 桌面环境「也可以使用 cli 方式，但是会麻烦些」 Linux 虚拟化环境 yum groupinstall -y 'Virtualization Host' Linux 虚拟化 gui 管理器 yum install -y virt-manager Linux 虚拟化 cli 管理器  以下为 cli 方式必须要安装的软件\n 虚拟机安装器 yum install -y virt-install 虚拟机 vnc 连接器 yum install -y virt-viewer  Windows 安装镜像及其驱动文件  ISO cn_windows_server_2012_r2_with_update_x64_dvd_6052725.iso Driver 「https://docs.fedoraproject.org/en-US/quick-docs/creating-windows-virtual-machines-using-virtio-drivers/index.html」 virtio-win-0.1.171.iso「所有驱动都在里面」 virtio-win_amd64.vfd「64bit 系统驱动，本次安装只用这一个就行」 virtio-win-0.1.171_x86.vfd「32bit 系统驱动」  cloudera-init 文件  CloudbaseInitSetup_Stable_x64.msi  https://cloudbase.it/downloads/CloudbaseInitSetup_Stable_x64.msi https://github.com/cloudbase/cloudbase-init/blob/master/README.rst https://github.com/cloudbase/cloudbase-init\n开始安装  前往系统 /opt 目录创建 qemu 目录，并给予权限，里面放入所有需要用到的文件  qemu ├── cn_windows_server_2012_r2_with_update_x64_dvd_6052725.iso ├── virt │ ├── virtio-win-0.1.171.iso │ ├── virtio-win-0.1.171_x86.vfd │ └── virtio-win_amd64.vfd └── ws2012.qcow2 chown -R qemu:qemu /opt/qemu  创建 .qcow2 格式文件，用于最后安装系统  qemu-img create -f qcow2 ws2012.qcow2 15G  打开 Virtual Machine Manager 创建一台虚拟机  img 略  修改默认配置  选择磁盘 -\u0026gt; 修改 Disk Bus 为「VirtIO」 选择网卡 -\u0026gt; 修改 Device mode 为「virtio」，建议使用桥接模式  添加驱动软盘  添加 \u0026quot;Hardware\u0026quot; Storage 并且 Device type 为「Floppy device」 选择 virtio-win_amd64.vfd 作为对象  开启虚拟机  运行 Windows Server 2012 R2 安装时加载 VirtIO 驱动即可顺利安装，网卡驱动可以在安装完操作系统后安装  一些设置  1. 关闭防火墙 2. 开启远程连接 3. 记得安装网卡驱动  安装 cloudbase-init  https://cloudbase.it/downloads/CloudbaseInitSetup_Stable_x64.msi  最后两个 勾勾 ==不要== 打上\nTips  驱动选择  让 Windows 自己去选择哪个驱动，勾选隐藏那些不兼容的驱动\n 驱动下载  可以只下载 virtio-win_amd64.vfd 里面有 win7 win8 win8.1 win10 的驱动，Windows Server 2012 R2 驱动选择 win8 文件夹即可\n Windows qcow2 转换工具  https://cloudbase.it/qemu-img-windows/\n参考文档 https://docs.openstack.org/image-guide/windows-image.html https://blog.51cto.com/11555417/2341874 https://www.cnblogs.com/nulige/p/8319838.html\n https://blog.csdn.net/qq_33317586/article/details/85613254 https://blog.51cto.com/royals/1956152 https://forum.huawei.com/enterprise/zh/thread-507243.html https://support.huaweicloud.com/usermanual-ims/zh-cn_topic_0030730602.html  C:\\Set-ExecutionPolicy Unrestricted netbios_host_name_compatibility=false first_logon_behavior=no\n","id":16,"section":"posts","summary":"👌 2020-03-31 创建 Windows Server 2012 R2 qcow2 格式虚拟机模板 FileInfo Filename - 创建 Windows Server 2012 R2 qcow2 格式虚拟机模板 Version - v1.1.2003（2020/03/31 ~ 2020/03/31） Author - standuke","tags":["Windows","qcow2","Virtualization"],"title":"创建 Windows Server 2012 R2 Qcow2 格式虚拟机模板","uri":"https://blog.standuke.top/2020/03/2020-03-31-%E5%88%9B%E5%BB%BA-windows-server-2012-r2-qcow2-%E6%A0%BC%E5%BC%8F%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A8%A1%E6%9D%BF/","year":"2020"},{"content":"👌 2020-03-28 docker image 导入导出 保存 Tag 标记 两者区别 VS  docker save 保存的是镜像（image），docker export 保存的是容器（container） 对于 Docker Save 方法，会保存该镜像的所有历史记录，包含 commit 历史 对于 Docker Export 方法，不会保留历史记录，即没有 commit 历史 docker load 用来载入镜像包，docker import 用来载入容器包，但两者都会恢复为镜像 docker load 不能对载入的镜像重命名，而 docker import 可以为镜像指定新名称  docker save - load  save\n 示例 docker save -o nginx.tar nginx:latest 或 docker save \u0026gt; nginx.tar nginx:latest\n其中-o和\u0026gt;表示输出到文件，nginx.tar为目标文件，nginx:latest是源镜像名（name:tag）\n load\n 示例 docker load -i nginx.tar 或 docker load \u0026lt; nginx.tar 其中-i和\u0026lt;表示从文件输入。会成功导入镜像及相关元数据，包括tag信息\ndocker export - import  export\n 示例 docker export -o nginx-test.tar nginx-test\n导出为tar\ndocker export #ID or #Name \u0026gt; /home/export.tar\n其中-o表示输出到文件，nginx-test.tar为目标文件，nginx-test是源容器名（name）\n import\n 示例 docker import nginx-test.tar nginx:imp 或 cat nginx-test.tar | docker import - nginx:imp\ndocker 命令混用情况 save -\u0026gt; import\nexport -\u0026gt; load\n注意事项 「docker save 镜像 ID」保存的镜像会丢失 Tag 信息，可以使用「docker save XXX:Tag」方式保存镜像\n","id":17,"section":"posts","summary":"👌 2020-03-28 docker image 导入导出 保存 Tag 标记 两者区别 VS docker save 保存的是镜像（image），docker export 保存的是容器（container） 对于 Docker Save 方法，会保存该镜","tags":["docker"],"title":"docker image 导入导出 保存 Tag 标记","uri":"https://blog.standuke.top/2020/03/2020-03-28-docker-image-%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA-%E4%BF%9D%E5%AD%98-tag-%E6%A0%87%E8%AE%B0/","year":"2020"},{"content":"👌 2020-03-17 OpenStack Train 快速离线部署「在线类似」  本文档为 openstack 快速部署文档，只适用于已经熟悉 openstack 各个组件及其部署方式和对应安装节点的维护人员 文档适用于构建 openstack 学习环境，文档默认三台节点，一台为 controller 若采用离线安装，则相关离线 repo 请预先设置，不再赘述\n   FileInfo Filename - 2020-03-05 Openstack Train Version EZ Install Guide Version - v1.1.2003（2020/03/15 ~ 2020/03/18） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - Openstack Train Version Offline Install\n 离线安装环境要求  操作系统要求 软件以及依赖 环境介绍     节点名称 IP地址 配置 泛角色     train-1 192.168.10.10 32C64T 8T controller   train-2 192.168.10.20 32C64T 8T node   train-3 192.168.10.30 32C64T 8T node    各节点初始化  安全设置  systemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld sed -i 's/^SELINUX=.*/SELINUX=disabled/` /etc/selinux/config setenforce 0  hosts 文件修改  vi /etc/hosts  配置 NTP 服务  yum install -y chrony # controller - server * + server 127.127.1.0 iburst + allow 192.168.10.0/24 # node - server * + server train-1 iburst systemctl start chronyd \u0026amp;\u0026amp; systemctl enable chronyd  安装基础 openstack 软件包  yum install -y centos-release-openstack-train python-openstackclient openstack-selinux \u0026amp;\u0026amp; yum upgrade -y  Mariadb  安装软件  yum install -y mariadb mariadb-server python2-PyMySQL  修改配置  vi /etc/my.cnf.d/openstack.cnf [mysqld] bind-address = 192.168.10.10 default-storage-engine = innodb innodb_file_per_table = on max_connections = 4096 collation-server = utf8_general_ci character-set-server = utf8  设置启动  systemctl start mariadb.service \u0026amp;\u0026amp; systemctl enable mariadb.service  初始化数据库  mysql_secure_installation  创建 库 / 赋予权限  CREATE DATABASE keystone; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'keystone'; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'keystone'; CREATE DATABASE glance; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'glance'; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'glance'; CREATE DATABASE placement; GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost' IDENTIFIED BY 'placement'; GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' IDENTIFIED BY 'placement'; CREATE DATABASE nova; CREATE DATABASE nova_api; CREATE DATABASE nova_cell0; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'nova'; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'nova'; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' IDENTIFIED BY 'nova'; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY 'nova'; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' IDENTIFIED BY 'nova'; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY 'nova'; CREATE DATABASE neutron; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY 'neutron'; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'*' IDENTIFIED BY 'neutron'; flush privileges;  RabbitMQ  安装软件  yum install -y rabbitmq-server  设置启动  systemctl start rabbitmq-server.service \u0026amp;\u0026amp; systemctl enable rabbitmq-server.service  创建用户  rabbitmqctl add_user openstack openstack # Creating user \u0026quot;openstack\u0026quot; ...  赋予权限  rabbitmqctl set_permissions openstack \u0026quot;.*\u0026quot; \u0026quot;.*\u0026quot; \u0026quot;.*\u0026quot; # Setting permissions for user \u0026quot;openstack\u0026quot; in vhost \u0026quot;/\u0026quot; ...  Memcached  安装软件  yum install -y memcached python-memcached  修改配置  vi /etc/sysconfig/memcached OPTIONS=\u0026quot;-l 127.0.0.1,::1,train-1\u0026quot;  设置启动  systemctl start memcached.service \u0026amp;\u0026amp; systemctl enable memcached.service  etcd  安装软件  yum install -y etcd  修改配置  vi /etc/etcd/etcd.conf #[Member] ETCD_DATA_DIR=\u0026quot;/var/lib/etcd/default.etcd\u0026quot; ETCD_LISTEN_PEER_URLS=\u0026quot;http://192.168.10.10:2380\u0026quot; ETCD_LISTEN_CLIENT_URLS=\u0026quot;http://192.168.10.10:2379\u0026quot; ETCD_NAME=\u0026quot;train-1\u0026quot; #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=\u0026quot;http://192.168.10.10:2380\u0026quot; ETCD_ADVERTISE_CLIENT_URLS=\u0026quot;http://192.168.10.10:2379\u0026quot; ETCD_INITIAL_CLUSTER=\u0026quot;train-1=http://192.168.10.10:2380\u0026quot; ETCD_INITIAL_CLUSTER_TOKEN=\u0026quot;etcd-cluster-01\u0026quot; ETCD_INITIAL_CLUSTER_STATE=\u0026quot;new\u0026quot;  设置启动  systemctl start etcd \u0026amp;\u0026amp; systemctl enable etcd   keystone  安装软件  yum install -y openstack-keystone httpd mod_wsgi  修改配置  [database] connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@train-1/keystone [token] provider = fernet  导入数据库  su -s /bin/sh -c \u0026quot;keystone-manage db_sync\u0026quot; keystone  初始化  keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone keystone-manage credential_setup --keystone-user keystone --keystone-group keystone  创建结点  keystone-manage bootstrap --bootstrap-password ADMIN_PASS \\ --bootstrap-admin-url http://train-1:5000/v3/ \\ --bootstrap-internal-url http://train-1:5000/v3/ \\ --bootstrap-public-url http://train-1:5000/v3/ \\ --bootstrap-region-id RegionOne  配置 Apache HTTP 服务 \\ 修改 /etc/httpd/conf/httpd.conf 中 ServerName 参数  ServerName train-1  创建 wsgi-keystone.conf 的软连接，生产环境建议使用 https 方式  ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/  启动 keystone \\ 设置开机自启  systemctl enable httpd.service \u0026amp;\u0026amp; systemctl start httpd.service  预设  openstack user create --domain default --password-prompt glance openstack role add --project service --user glance admin openstack service create --name glance --description \u0026quot;OpenStack Image\u0026quot; image openstack endpoint create --region RegionOne image public http://train-1:9292 openstack endpoint create --region RegionOne image internal http://train-1:9292 openstack endpoint create --region RegionOne image admin http://train-1:9292 openstack user create --domain default --password PLACEMENT_PASS placement openstack service create --name placement --description \u0026quot;Placement API\u0026quot; placement openstack endpoint create --region RegionOne placement public http://train-1:8778 openstack endpoint create --region RegionOne placement internal http://train-1:8778 openstack endpoint create --region RegionOne placement admin http://train-1:8778 openstack user create --domain default --password-prompt nova openstack role add --project service --user nova admin openstack service create --name nova --description \u0026quot;OpenStack Compute\u0026quot; compute openstack endpoint create --region RegionOne compute public http://train-1:8774/v2.1 openstack endpoint create --region RegionOne compute internal http://train-1:8774/v2.1 openstack endpoint create --region RegionOne compute admin http://train-1:8774/v2.1 openstack user create --domain default --password-prompt neutron openstack role add --project service --user neutron admin openstack service create --name neutron --description \u0026quot;OpenStack Networking\u0026quot; network openstack endpoint create --region RegionOne network public http://train-1:9696 openstack endpoint create --region RegionOne network internal http://train-1:9696 openstack endpoint create --region RegionOne network admin http://train-1:9696  glance ⚠️ 使用 admin 环境，来使用管理员权限  source admin-openrc.sh  安装 glance 软件包  yum install -y openstack-glance 此处会缺少软件包 tk*  修改 /etc/glance/glance-api.conf 配置文件  vi /etc/glance/glance-api.conf # 配置数据库访问 [database] connection = mysql+pymysql://glance:GLANCE_DBPASS@train-1/glance # 这部分删除多余的 [keystone_authtoken] www_authenticate_uri = http://train-1:5000 auth_url = http://train-1:5000 memcached_servers = train-1:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = glance password = GLANCE_PASS # 配置认证方式 [paste_deploy] flavor = keystone # 配置本地文件系统存储和镜像文件存储位置 [glance_store] stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/  初始化 glance 数据库  su -s /bin/sh -c \u0026quot;glance-manage db_sync\u0026quot; glance # 可忽略输出，直到提示 Database is synced successfully.  启动 glance 服务 / 设置开机自启  systemctl start openstack-glance-api.service \u0026amp;\u0026amp; systemctl enable openstack-glance-api.service  上传测试镜像  http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img\nopenstack image create --file /root/cirros-0.4.0-x86_64-disk.img --disk-format qcow2 --container-format bare --public cirros openstack image list \u0026gt;root ~ [train-1]# openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | deeb4604-620b-4a3c-85ce-9173c4325f26 | cirros | active | +--------------------------------------+--------+--------+ ls -lah /var/lib/glance/images/  placement 安装 placement 软件包  yum install -y openstack-placement-api  修改 /etc/placement/placement.conf 配置文件  vi /etc/placement/placement.conf [placement_database] connection = mysql+pymysql://placement:PLACEMENT_DBPASS@train-1/placement [api] auth_strategy = keystone [keystone_authtoken] auth_url = http://train-1:5000/v3 memcached_servers = train-1:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = PLACEMENT_PASS  初始化 placement 数据库 \\ 此操作无输出  su -s /bin/sh -c \u0026quot;placement-manage db sync\u0026quot; placement  重启 httpd 服务  systemctl restart httpd  坑  \u0026lt;Directory /usr/bin\u0026gt; \u0026lt;IfVersion \u0026gt;= 2.4\u0026gt; Require all granted \u0026lt;/IfVersion\u0026gt; \u0026lt;IfVersion \u0026lt; 2.4\u0026gt; Order allow,deny Allow from all \u0026lt;/IfVersion\u0026gt; \u0026lt;/Directory\u0026gt;  nova 安装 nova 组件  yum install -y openstack-nova-api openstack-nova-conductor openstack-nova-novncproxy openstack-nova-scheduler  修改 /etc/nova/nova.conf 配置文件  [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:openstack@train-1:5672/ my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver [api_database] connection = mysql+pymysql://nova:NOVA_DBPASS@train-1/nova_api [database] connection = mysql+pymysql://nova:NOVA_DBPASS@train-1/nova [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://train-1:5000/ auth_url = http://train-1:5000/ memcached_servers = train-1:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = NOVA_PASS [vnc] enabled = true server_listen = $my_ip server_proxyclient_address = $my_ip [glance] api_servers = http://train-1:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://train-1:5000/v3 username = placement password = PLACEMENT_PASS  初始化数据库  # 同步 su -s /bin/sh -c \u0026quot;nova-manage api_db sync\u0026quot; nova su -s /bin/sh -c \u0026quot;nova-manage cell_v2 map_cell0\u0026quot; nova su -s /bin/sh -c \u0026quot;nova-manage cell_v2 create_cell --name=cell1 --verbose\u0026quot; nova su -s /bin/sh -c \u0026quot;nova-manage db sync\u0026quot; nova 这个会有两个警告，忽视即可 /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `block_device_mapping_instance_uuid_virtual_name_device_name_idx`. This is deprecated and will be disallowed in a future release') result = self._query(query) /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `uniq_instances0uuid`. This is deprecated and will be disallowed in a future release') result = self._query(query) su -s /bin/sh -c \u0026quot;nova-manage cell_v2 list_cells\u0026quot; nova +-------+--------------------------------------+-----------------------------------------------+------------------------------------------------------+----------+ | 名称 | UUID | Transport URL | 数据库连接 | Disabled | +-------+--------------------------------------+-----------------------------------------------+------------------------------------------------------+----------+ | cell0 | 00000000-0000-0000-0000-000000000000 | none:/ | mysql+pymysql://nova:****@train-1/nova_cell0 | False | | cell1 | 5360e154-62a1-4232-8bb7-8f4abcf5ad2b | rabbit://openstack:****@train-1:5672/ | mysql+pymysql://nova:****@train-1/nova | False | +-------+--------------------------------------+-----------------------------------------------+------------------------------------------------------+----------+  启动 nova 相关服务 \\ 设置开机自启  systemctl start \\ openstack-nova-api.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service systemctl enable \\ openstack-nova-api.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service    安装 nova 组件  yum install -y openstack-nova-compute  修改 /etc/nova/nova.conf 配置文件  [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:openstack@train-1 my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://train-1:5000/ auth_url = http://train-1:5000/ memcached_servers = train-1:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = NOVA_PASS [vnc] enabled = true server_listen = 0.0.0.0 server_proxyclient_address = $my_ip novncproxy_base_url = http://train-1:6080/vnc_auto.html [glance] api_servers = http://train-1:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://train-1:5000/v3 username = placement password = PLACEMENT_PASS  虚拟化方案筛选  egrep -c '(vmx|svm)' /proc/cpuinfo # 如果此命令返回值是 0，则计算节点不支持硬件加速，并且必须配置 libvirt 为 QEMU 而不是 KVM，需要编辑 /etc/nova/nova.conf 文件中的 [libvirt] 部分 [libvirt] virt_type = qemu  启动 nova 服务 \\ 设置开机自启  systemctl start libvirtd.service openstack-nova-compute.service systemctl enable libvirtd.service openstack-nova-compute.service  neutron 安装 neutron 软件  yum install -y openstack-neutron openstack-neutron-ml2 openstack-neutron-linuxbridge ebtables  修改 /etc/neutron/neutron.conf neutron 配置文件  [database] connection = mysql+pymysql://neutron:NEUTRON_DBPASS@train-1/neutron [DEFAULT] core_plugin = ml2 service_plugins = transport_url = rabbit://openstack:openstack@train-1 auth_strategy = keystone notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [keystone_authtoken] www_authenticate_uri = http://train-1:5000 auth_url = http://train-1:5000 memcached_servers = train-1:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS [nova] auth_url = http://train-1:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = NOVA_PASS [oslo_concurrency] lock_path = /var/lib/neutron/tmp  修改 /etc/neutron/plugins/ml2/ml2_conf.ini ML2 plugin 配置文件  [ml2] type_drivers = flat,vlan tenant_network_types = mechanism_drivers = linuxbridge extension_drivers = port_security [ml2_type_flat] flat_networks = provider [securitygroup] enable_ipset = true  修改 /etc/neutron/plugins/ml2/linuxbridge_agent.ini 配置文件  [linux_bridge] physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME [vxlan] enable_vxlan = false [securitygroup] enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver  修改内核参数 /etc/sysctl.conf  vim /etc/sysctl.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 modprobe br_netfilter sysctl -p  修改 /etc/neutron/dhcp_agent.ini DHCP 配置文件  [DEFAULT] interface_driver = linuxbridge dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true  配置 /etc/neutron/metadata_agent.ini metadata agent 配置文件  [DEFAULT] nova_metadata_host = train-1 metadata_proxy_shared_secret = METADATA_SECRET  配置计算服务使用刚才配置的网络服务，修改 /etc/nova/nova.conf nova 配置文件  [neutron] auth_url = http://train-1:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS service_metadata_proxy = true metadata_proxy_shared_secret = METADATA_SECRET  最后几步，建立 ml2 软链  ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini  填充 neutron 数据库  su -s /bin/sh -c \u0026quot;neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\u0026quot; neutron  重启 计算服务 API  systemctl restart openstack-nova-api.service  as  systemctl start \\ neutron-server.service neutron-linuxbridge-agent.service \\ neutron-dhcp-agent.service neutron-metadata-agent.service systemctl enable \\ neutron-server.service neutron-linuxbridge-agent.service \\ neutron-dhcp-agent.service neutron-metadata-agent.service    安装相关 neutron 服务  yum install -y openstack-neutron-linuxbridge ebtables ipset  配置通用组件，修改 /etc/neutron/neutron.conf 配置文件  [DEFAULT] transport_url = rabbit://openstack:openstack@train-1 auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://train-1:5000 auth_url = http://train-1:5000 memcached_servers = train-1:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS [oslo_concurrency] lock_path = /var/lib/neutron/tmp   配置 /etc/neutron/plugins/ml2/linuxbridge_agent.ini Linux bridge agent 代理  [linux_bridge] physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME [vxlan] enable_vxlan = false [securitygroup] enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver  修改内核参数 /etc/sysctl.conf  vim /etc/sysctl.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 modprobe br_netfilter sysctl -p   配置计算服务使用刚才配置的网络服务，修改 /etc/nova/nova.conf 配置文件  [neutron] auth_url = http://train-1:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS  重启 nova 计算服务  systemctl restart openstack-nova-compute.service  启动 neutron 相关服务  systemctl start neutron-linuxbridge-agent.service \u0026amp;\u0026amp; systemctl enable neutron-linuxbridge-agent.service  horizon  安装软件包  yum install openstack-dashboard  修改 /etc/openstack-dashboard/local_settings 配置文件  OPENSTACK_HOST = \u0026quot;train-1\u0026quot; ALLOWED_HOSTS = ['one.example.com', 'two.example.com'] ALLOWED_HOSTS = ['horizon.example.com', 'localhost','*'] SESSION_ENGINE = 'django.contrib.sessions.backends.cache' CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'train-1:11211', } } OPENSTACK_KEYSTONE_URL = \u0026quot;http://%s:5000/v3\u0026quot; % OPENSTACK_HOST OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True OPENSTACK_API_VERSIONS = { \u0026quot;identity\u0026quot;: 3, \u0026quot;image\u0026quot;: 2, \u0026quot;volume\u0026quot;: 3, } OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \u0026quot;Default\u0026quot; OPENSTACK_KEYSTONE_DEFAULT_ROLE = \u0026quot;user\u0026quot; OPENSTACK_NEUTRON_NETWORK = { ... 'enable_router': False, 'enable_quotas': False, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_lb': False, 'enable_firewall': False, 'enable_vpn': False, 'enable_fip_topology_check': False, } TIME_ZONE = \u0026quot;TIME_ZONE\u0026quot;  Add the following line to /etc/httpd/conf.d/openstack-dashboard.conf if not included.  WSGIApplicationGroup %{GLOBAL}  启动  systemctl restart httpd.service memcached.service  生产配置文件**「！！不要做这步」**  cd /usr/share/openstack-dashboard python manage.py make_web_conf --apache \u0026gt; /etc/httpd/conf.d/openstack-dashboard.conf  创建链接  ln -s /etc/openstack-dashboard /usr/share/openstack-dashboard/openstack_dashboard/conf  坑  vim /usr/share/openstack-dashboard/openstack_dashboard/defaults.py vim /usr/share/openstack-dashboard/openstack_dashboard/test/settings.py vim /usr/share/openstack-dashboard/static/dashboard/js/9937cc9f2cae.js WEBROOT = '/' WEBROOT = '/dashboard'  附录 略\n","id":18,"section":"posts","summary":"👌 2020-03-17 OpenStack Train 快速离线部署「在线类似」 本文档为 openstack 快速部署文档，只适用于已经熟悉 openstack 各个组件及其部署方式和对应安装节点的维护人员 文档适用于构建 openstack 学习环","tags":["OpenStack","Virtualization"],"title":"OpenStack Train 快速离线部署「在线类似」","uri":"https://blog.standuke.top/2020/03/2020-03-17-openstack-train-%E5%BF%AB%E9%80%9F%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2%E5%9C%A8%E7%BA%BF%E7%B1%BB%E4%BC%BC/","year":"2020"},{"content":"👌 2020-03-02 CentOS 7 CDH 6.3.1 Cloudera Manager 6.3.1 企业级离线安装简易版  FileInfo Filename - 2020-03-02 CentOS 7 CDH 6.3.1 Cloudera Manager 6.3.1 企业级离线安装简易版 Version - v1.1.2003（2020/03/02 ~ 2020/03/02） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - CDH install quick version\n 本文约定 在文中将有以下提示符对重点进行标注说明，请注意文中提示。\n⚠️ - 文中出现此标记，代表重要提示，指需要格外注意的地方 🔘 - 文中出现此标记，代表可选配置，建议配置，但不必要 ✅ - 文中出现此标记，代表检查项目，需要检查对应的配置文件 ❗️ - 文中出现此标记，代表该操作不可随意修改，如更改此步操作，请预先测试\nCDH 简单介绍 Cloudera Distribution including Apache Hadoop - CDH 为 Cloudera 的开源 Apache Hadoop 发行版，面向 Hadoop 企业级部署。 Cloudera版本（Cloudera\u0026rsquo;s Distribution Including Apache Hadoop，简称\u0026quot;CDH\u0026quot;），基于 Web 的用户界面，支持大多数 Hadoop 组件，包括 HDFS、MapReduce、Hive、Pig、Hbase、Zookeeper、Sqoop，简化了大数据平台的安装和使用难度。 除此 Apache Hadoop 发行版本之外，还有如下发行版：\n Cloudera\u0026rsquo;s Distribution Including Apache Hadoop（CDH）「本文采用」 Hortonworks Data Platform (HDP) MapR EMR  组件介绍 Cloudera Manager 是用于管理 CDH 集群的端到端应用程序，统一管理和安装。CDH 除了可以通过 CM 安装也可以通过 YUM、TAR、RPM 安装。主要由如下几部分组成：\n Server：Cloudera Manager 的核心。主要用于管理 web server 和应用逻辑。它用于安装软件，配置，开始和停止服务，以及管理服务运行的集群。 agent：安装在每台主机上。它负责启动和停止进程，部署配置，触发安装和监控主机。 Database：存储配置和监控信息。通常可以在一个或多个数据库服务器上运行的多个逻辑数据库。例如，所述的 Cloudera 管理器服务和监视，后台程序使用不同的逻辑数据库。 Parcel（Cloudera Repository）：由 Cloudera 提供的软件分发库。 Clients：提供了一个与 Server 交互的接口。  节点介绍    NAME NUMBER 描述     Server 1 CM 中 Manager 节点   Agent 1+N CM 中 其余 Node 节点    ALL 所有节点  ❗️关闭并禁止开机自启如下服务：系统防火墙（Firewalld、iptables）、NetworkManager  systemctl stop firewalld systemctl stop iptables systemctl stop NetworkManager systemctl disable firewalld systemctl disable iptables systemctl disable NetworkManager   ❗️关闭并禁用 SELinux  sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config   ❗️永久修改各节点的 Hostname 必须防止变回默认  hostnamectl set-hostname $HOSTNAME   ❗️添加服务器之间本地域名解析 /etc/hosts  vi /etc/hosts # incloud itself # 192.168.10.1 localhost localhost.localhost   ❗️配置仅使用物理内存，所有主机都需要  echo \u0026quot;vm.swappiness=0\u0026quot; \u0026gt;\u0026gt;/etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p   ❗️禁用透明页压缩，所有主机都需要  echo \u0026quot;never\u0026quot; \u0026gt; /sys/kernel/mm/transparent_hugepage/defrag echo \u0026quot;never\u0026quot; \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled chmod +x /etc/rc.local echo \u0026quot;echo 'never' \u0026gt; /sys/kernel/mm/transparent_hugepage/defrag\u0026quot; \u0026gt;\u0026gt; /etc/rc.local echo \u0026quot;echo 'never' \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026quot; \u0026gt;\u0026gt; /etc/rc.local tail ‐2f /sys/kernel/mm/transparent_hugepage/defrag tail ‐2f /sys/kernel/mm/transparent_hugepage/enabled tail ‐2f /etc/rc.local  echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/defrag echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\n ❗️⚠️ 配置个节点时间同步，确保各个节点时间误差最大不得高于 2s  yum -y install ntp  server\n# 管理节点使用本地时钟源,执行以下语句即可 cat \u0026lt;\u0026lt;EOF\u0026gt;/etc/ntp.conf driftfile /var/lib/ntp/drift restrict default kod nomodify notrap nopeer noquery restrict -6 default kod nomodify notrap nopeer noquery restrict 127.0.0.1 restrict -6 ::1 server 127.127.1.0 iburst includefile /etc/ntp/crypto/pw keys /etc/ntp/keys EOF  agent\n# 其他节点的时钟源为管理节点，执行以下语句即可 cat \u0026lt;\u0026lt;EOF\u0026gt;/etc/ntp.conf driftfile /var/lib/ntp/drift restrict default kod nomodify notrap nopeer noquery restrict -6 default kod nomodify notrap nopeer noquery restrict 127.0.0.1 restrict -6 ::1 server node1 iburst includefile /etc/ntp/crypto/pw keys /etc/ntp/keys EOF  强制设置时间，写入硬件时钟\n# 修改各节点时间,时间为当前时间 date -s \u0026quot;2020-04-16 23:11:07\u0026quot; # 写入硬件时钟 hwclock -w  启动服务，并设置开机自启动\n# 各节点启动服务 systemctl start ntpd \u0026amp;\u0026amp; systemctl enable ntpd   🔘配置 Java 运行环境，建议安装 JDK 1.8.0_161（亦可选择安装 CDH 时，选择安装 CDH 自带的 Oracle JDK）  # JDK 安装路径 mkdir -p /usr/local/java  若操作系统安装有 OpenJDK 则移除系统原有的 JDK\n# 各节点都需要进行 # 查找JDK rpm -aq|grep java rpm -aq|grep jdk # 卸载JDK yum -y remove [上述查找结果的包名]  安装 Oracle JDK 1.8\n# 在各节点上进行安装 # 创建java目录 mkdir /usr/java/ # 上传jdk目录下jdk-8u161-linux-x64.tar.gz到/usr/java目录 并解压 cd /usr/java/ tar -zxvf jdk-8u161-linux-x64.tar.gz # ⚠️ 修改 jdk 所属用户用户组 chown root:root jdk-8u161-linux-x64 # 配置环境变量 vi /etc/profile # 在后面追加下面三行 export JAVA_HOME=/usr/java/jdk1.8.0_161 export CLASSPATH=.:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar export PATH=${JAVA_HOME}/bin:${PATH} # 最后刷新环境变量 source /etc/profile # 查看 Java 是否安装成功 java -version  Server 节点 🔘 若操作系统安装有 mariadb 则手工移除mariadb数据库 ⚠️ 亦可不移除，在安装 mysql 是会自动处理\n rpm -qa | grep mariadb # 结果应为 mariadb-libs-5.5.56-2.el7.x86_64 # 卸载 rpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64  安装 MySql 服务\n# 在 server 上安装 mysql 服务 # 上传repo目录下mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar安装包到 /home/cdh/ 目录 并解压 tar -xvf mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar # 进入解压目录 安装 mysql yum install net-tools rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm mysql-community-client-5.7.25-1.el7.x86_64.rpm mysql-community-common-5.7.25-1.el7.x86_64.rpm mysql-community-libs-5.7.25-1.el7.x86_64.rpm mysql-community-libs-compat-5.7.25-1.el7.x86_64.rpm  启动 mysql 服务，设置自启动\n# 在 server上启动 mysql 服务,并设置自启动 systemctl start mysqld systemctl enable mysqld  初始化 mysql 数据库\n# 在node1 上初始化mysql # 获得初始密码 grep 'temporary password' /var/log/mysqld.log # 使用初始密码登录 mysql -u root -p # 修改初始密码 # show variables like 'validate_password%';# 查看密码验证策略 set global validate_password_policy=0;# 设置密码验证策略为低 set global validate_password_mixed_case_count=0;# 设置密码至少要包含的大小写字母个数 set global validate_password_number_count=0;# 设置密码至少要包含的数字个数 set global validate_password_special_char_count=0;# 设置密码至少要包含的特殊字符个数 set global validate_password_length=2; # 设置密码最小长度为2 ALTER USER 'root'@'localhost' IDENTIFIED BY '123456'; grant all privileges on *.* to 'root'@'localhost' identified by '123456' with grant option; grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option; flush privileges; quit;   配置 mysql jdbc 驱动  # 在各节点上执行 # 上传 repo 目录下 mysql 连接 mysql-connector-java-5.1.47.jar 到 /usr/share/java ⚠️ mkdir -p /usr/share/java # 重命名 ⚠️ mv mysql-connector-java-5.1.47.jar mysql-connector-java.jar # 授权 ⚠️ chmod 777 mysql-connector-java.jar   安装 daemons agent server   yum -y install cloudera-manager-agent cloudera-manager-daemons cloudera-manager-server   初始化 CM 相关数据库  ##执行数据库脚本 cd /opt/cloudera/cm/schema ./scm_prepare_database.sh mysql -uroot -p scm scm scm   修改 agent 配置文件  vi /etc/cloudera-scm-agent/config.ini server=$SERVERHOSTNAME  Agent 节点  安装 daemons agent  yum -y install cloudera-manager-agent cloudera-manager-daemo   修改 agent 配置文件  vi /etc/cloudera-scm-agent/config.ini server=$SERVERHOSTNAME  开始启动服务 server\nsystemctl start cloudera-scm-server systemctl enable cloudera-scm-server systemctl start cloudera-scm-agent systemctl enable cloudera-scm-agent  agent\nsystemctl start cloudera-scm-agent systemctl enable cloudera-scm-agent  网页操作 http://server:7180 默认用户名为 admin 默认密码为 admin\n附录 组件建表语句\nmysql -uroot -p123456 ##给scm授权 grant all privileges on *.* to 'scm'@'localhost' identified by 'scm' with grant option; grant all privileges on *.* to 'scm'@'%' identified by 'scm' with grant option; ##创建hive数据库 create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci; ##给hive授权 grant all privileges on *.* to 'hive'@'localhost' identified by 'hive' with grant option; grant all privileges on *.* to 'hive'@'%' identified by 'hive' with grant option; ##创建oozie数据库 create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci; ##给oozie授权 grant all privileges on *.* to 'oozie'@'localhost' identified by 'oozie' with grant option; grant all privileges on *.* to 'oozie'@'%' identified by 'oozie' with grant option; ##创建hue数据库 create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci; ##给hub授权 grant all privileges on *.* to 'hue'@'localhost' identified by 'hue' with grant option; grant all privileges on *.* to 'hue'@'%' identified by 'hue' with grant option; ##创建AM数据库 create database am DEFAULT CHARSET utf8 COLLATE utf8_general_ci; ##给AM授权 grant all privileges on *.* to 'am'@'localhost' identified by 'am' with grant option; grant all privileges on *.* to 'am'@'%' identified by 'am' with grant option; ##刷新权限 flush privileges; ##退出 quit;   附录结束\n版本修订记录    版本号 修订日期 修订人 备注     v1.1.2003 2020-03-02 nuo 创建文档    ","id":19,"section":"posts","summary":"👌 2020-03-02 CentOS 7 CDH 6.3.1 Cloudera Manager 6.3.1 企业级离线安装简易版 FileInfo Filename - 2020-03-02 CentOS 7 CDH 6.3.1 Cloudera Manager 6.3.1 企业级离线安装简易版 Version - v1.1.2003（2020/03/02 ~ 2020/03","tags":["CDH","Cloudera","Bigdata"],"title":"CentOS 7 CDH 6.3.1 Cloudera Manager 6.3.1 企业级离线安装简易版","uri":"https://blog.standuke.top/2020/03/2020-03-02-centos-7-cdh-6.3.1-cloudera-manager-6.3.1-%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85-ez-%E7%89%88/","year":"2020"},{"content":"👌 2020-02-17 Linux 系统 systemd 服务简介及编写  FileInfo Filename - Linux 编写系统 systemd 服务.md Version - v1.1.2002（2020/02/18 ~ 2020/02/19） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Linux Systemd Configure Set\n 本文约定 在文中将有以下提示符对重点进行标注说明，请注意文中提示。\n⚠️ - 文中出现此标记，代表重要提示，指需要格外注意的地方 🔘 - 文中出现此标记，代表可选配置，建议配置，但不必要 ✅ - 文中出现此标记，代表检查项目，需要检查对应的配置文件 ❗️ - 文中出现此标记，代表该操作不可随意修改，如更改此步操作，请预先测试\n[TOC]\nsystemd 概述 Red Hat Enterprise Linux 7（RHEL7）已经将服务管理工具从 SysVinit 和 Upstart（ubuntu） 迁移到了 systemd 上。 之前版本的所有启动脚本都是放在 /etc/rc.d/init.d/ 目录下。这些脚本都是 bash 脚本，可以让系统管理员控制这些服务的状态。通常，这些脚本中包含了 start \\ stop \\ restart 这些方法，以提供系统自动调用这些方法。但是在 RHEL7 中已经完全摒弃了这种方法，而采用了一种叫 systemd 的 unit 的配置文件来管理服务。 unit 文件可用来描述：系统服务（.service）、挂载点（.mount）、sockets（.sockets）、系统设备（.device）、交换分区（.swap）、文件路径（.path）、启动目标（.target）、由 systemd 管理的计时器（.timer）\nsystemd 命令集  systemctl 是 Systemd 的主命令，用于管理系统。 systemd-analyze 用于查看启动耗时。 hostnamectl 用于查看当前主机的信息。 localectl 用于查看本地化设置。 timedatectl 用于查看当前时区设置。 loginctl 用于查看当前登录的用户。  RHEL7 服务启动相关文件 init 在 RHEL7 种与启动相关的 SysVinit（init） 文件以及文件夹如下所示，大部分使用的文件都是软链接\nll /etc/ lrwxrwxrwx. 1 root root 11 1月 16 08:59 init.d -\u0026gt; rc.d/init.d // inittab 已弃用 -rw-r--r--. 1 root root 511 8月 9 2019 inittab lrwxrwxrwx. 1 root root 10 1月 16 08:59 rc0.d -\u0026gt; rc.d/rc0.d lrwxrwxrwx. 1 root root 10 1月 16 08:59 rc1.d -\u0026gt; rc.d/rc1.d lrwxrwxrwx. 1 root root 10 1月 16 08:59 rc2.d -\u0026gt; rc.d/rc2.d lrwxrwxrwx. 1 root root 10 1月 16 08:59 rc3.d -\u0026gt; rc.d/rc3.d lrwxrwxrwx. 1 root root 10 1月 16 08:59 rc4.d -\u0026gt; rc.d/rc4.d lrwxrwxrwx. 1 root root 10 1月 16 08:59 rc5.d -\u0026gt; rc.d/rc5.d lrwxrwxrwx. 1 root root 10 1月 16 08:59 rc6.d -\u0026gt; rc.d/rc6.d drwxr-xr-x. 10 root root 127 1月 16 08:59 rc.d lrwxrwxrwx. 1 root root 13 1月 16 08:59 rc.local -\u0026gt; rc.d/rc.local ll /etc/rc.d/ drwxr-xr-x. 2 root root 70 1月 16 08:59 init.d drwxr-xr-x. 2 root root 45 1月 16 08:59 rc0.d drwxr-xr-x. 2 root root 45 1月 16 08:59 rc1.d drwxr-xr-x. 2 root root 45 1月 16 08:59 rc2.d drwxr-xr-x. 2 root root 45 1月 16 08:59 rc3.d drwxr-xr-x. 2 root root 45 1月 16 08:59 rc4.d drwxr-xr-x. 2 root root 45 1月 16 08:59 rc5.d drwxr-xr-x. 2 root root 45 1月 16 08:59 rc6.d -rw-r--r--. 1 root root 473 8月 8 2019 rc.local  systemd 在 RHEL7 种与启动相关的 systemd 文件以及文件夹如下所示\n/etc/systemd/system/* # 供系统管理员和用户使用 ⚠️ 自定义服务需要放置在该目录 /run/systemd/system/* # 运行时配置文件 /usr/lib/systemd/system/* # 安装程序时默认的 unit 文件存放位置（如 RPM 包安装）  编写一个 服务  编写 unit 文件 demo.service  [Unit] Description=My-demo Service [Service] Type=oneshot ExecStart=/bin/bash /root/test.sh StandardOutput=syslog StandardError=inherit [Install] WantedBy=multi-user.target  将上述的文件拷贝到 RHEL7 系统中 /usr/lib/systemd/system/* 目录下  cp demo.service /usr/lib/systemd/system/demo.service  编写 unit 文件中 ExecStart=/bin/bash /root/test.sh 所定义的 test.sh 文件，将其放在定义的目录当中，此文件是服务的执行主体。  #!/bin/bash date \u0026gt;\u0026gt; /tmp/date  将 demo.service 设置为开机自启  systemctl enable demo.service  关键词详解  [Unit]：记录unit文件的通用信息 [Service]：记录Service的信息 [Install]：安装信息\n Unit ● Description：对本service的描述。 ● Before, After：定义启动顺序，Before=xxx.service，代表本服务在xxx.service启动之前启动。After=xxx.service,代表本服务在xxx之后启动。 ● Requires: 这个单元启动了，那么它\u0026quot;需要\u0026quot;的单元也会被启动; 它\u0026quot;需要\u0026quot;的单元被停止了，它自己也活不了。但是请注意，这个设定并不能控制某单元与它\u0026quot;需要\u0026quot;的单元的启动顺序（启动顺序是另外控制的），即 Systemd 不是先启动 Requires 再启动本单元，而是在本单元被激活时，并行启动两者。于是会产生争分夺秒的问题，如果 Requires 先启动成功，那么皆大欢喜; 如果 Requires 启动得慢，那本单元就会失败（Systemd 没有自动重试）。所以为了系统的健壮性，不建议使用这个标记，而建议使用 Wants 标记。可以使用多个 Requires。 ● RequiresOverridable：跟 Requires 很像。但是如果这条服务是由用户手动启动的，那么 RequiresOverridable 后面的服务即使启动不成功也不报错。跟 Requires 比增加了一定容错性，但是你要确定你的服务是有等待功能的。另外，如果不由用户手动启动而是随系统开机启动，那么依然会有 Requires 面临的问题。 ● Requisite：强势版本的 Requires。要是这里需要的服务启动不成功，那本单元文件不管能不能检测等不能等待都立刻就会失败。 ● Wants：推荐使用。本单元启动了，它\u0026quot;想要\u0026quot;的单元也会被启动。但是启动不成功，对本单元没有影响。 ● Conflicts：一个单元的启动会停止与它\u0026quot;冲突\u0026quot;的单元，反之亦然。\nService ● Type：service的种类，包含下列几种类型： \u0026mdash;-simple 默认，这是最简单的服务类型。意思就是说启动的程序就是主体程序，这个程序要是退出那么一切都退出。 \u0026mdash;\u0026ndash;forking 标准 Unix Daemon 使用的启动方式。启动程序后会调用 fork() 函数，把必要的通信频道都设置好之后父进程退出，留下守护精灵的子进程 \u0026mdash;\u0026ndash;oneshot种服务类型就是启动，完成，没进程了。 notify,idle类型比较少见，不介绍。 ● ExecStart：服务启动时执行的命令，通常此命令就是服务的主体。 \u0026mdash;\u0026mdash;如果你服务的类型不是 oneshot，那么它只可以接受一个命令，参数不限。 \u0026mdash;\u0026mdash;多个命令用分号隔开，多行用 \\ 跨行。 ● ExecStartPre, ExecStartPost：ExecStart执行前后所调用的命令。 ● ExecStop：定义停止服务时所执行的命令，定义服务退出前所做的处理。如果没有指定，使用systemctl stop xxx命令时，服务将立即被终结而不做处理。 ● Restart：定义服务何种情况下重启（启动失败，启动超时，进程被终结）。可选选项：no, on-success, on-failure,on-watchdog, on-abort ● SuccessExitStatus：参考ExecStart中返回值，定义何种情况算是启动成功。 eg：SuccessExitStatus=1 2 8 SIGKILL Install ● WantedBy：何种情况下，服务被启用。 eg：WantedBy=multi-user.target（多用户环境下启用） ● Alias：别名\n自启脚本接入 init 方式接入 ⚠️ 默认 rc.local 弃用，但是仍然可以通过赋予执行权限 chmod +x /etc/rc.d/rc.local 来启用 rc.local 文件，此种方法即为 init 方式设置开机启动。\nlinux 启动时，先加载内核，然后加载 inittab 文件，inittab 文件中有个条目 si::sysinit:/etc/rc.d/rc.sysinit 指定了下一个要加载的文件 rc.sysinit，这个文件加载完之后，加载 /etc/rc.d/rc.RUNLEVEL.d 目录中的启动脚本，最后加载 /etc/rc.d/rc.local 文件。\ninittab 和 rc.sysinit 文件就不说了，在 rc.RUNLEVEL.d 文件夹里，所存的都是软链接，链接到 /etc/rc.d/init.d 中的脚本文件，而 /etc/rc.d/init.d 文件夹和 /etc/init.d 文件夹是一样的，/etc/init.d 其实是软链接到 /etc/rc.d/init.d 文件夹中。\n若脚本需要开机启动，则方法如下\n 把脚本注册为系统服务，把它放到 /etc/init.d 目录下，并且在脚本中，加一行 # chkconfig: 345 85 35，然后就可以用 chkconfig 命令让其开机启动。因为在 /etc/init.d 目录下，所以也可以用 service 命令控制该脚本。 建议 在 /etc/rc.d/rc.local 文件中，直接把该脚本的路径写进去，在开机加载 rc.local 文件时，自然会启动这个脚本。这个脚本就不能用 chkconfig 和 service 命令控制。  systemd 方式接入  创建服务 unit 描述文件 设置开启自启  systemctl enable ***.service  重启检验  systemctl status ***.service  老版本兼容性  RHEL7 默认已经不再使用 SysVinit 和 Upstart，但是仍然可以兼容 SysVinit 和 Upstart\n    老版本 新版本 描述     service name start systemctl start name.service   Starts a service   service name stop systemctl stop name.service Stops a service   service name restart systemctl restartname.service Restarts a service   service name reload systemctl reloadname.service Reloads configuration   service name status systemctl status name.service Checks if a service status   chkconfig name on systemctl enablename.service Enables a service   chkconfig name off systemctl disablename.service Disables a service     默认的 RunLevel（在 /etc/inittab 文件设置）现在被默认的 Target 取代，位置是 /etc/systemd/system/default.target，通常符号链接到 graphical.target（图形界面）或者 multi-user.target（多用户命令行）。 启动脚本的位置，以前是 /etc/init.d 目录，符号链接到不同的 RunLevel 目录 （比如 /etc/rc3.d、/etc/rc5.d 等），现在则存放在 /lib/systemd/system 和 /etc/systemd/system 目录。 配置文件的位置，以前init进程的配置文件是 /etc/inittab，各种服务的配置文件存放在 /etc/sysconfig 目录。现在的配置文件主要存放在 /lib/systemd 目录，在 /etc/systemd 目录里面的修改可以覆盖原始设置。  相关参考 systemd - Arch Linux https://wiki.archlinux.org/index.php/Systemd_(简体中文)#systemd_基本工具 阮一峰的网络日志 http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html IBM 浅析 Linux 初始化 init 系统，第 3 部分 https://www.ibm.com/developerworks/cn/linux/1407_liuming_init3/index.html 编写systemd下服务脚本 https://blog.csdn.net/fu_wayne/article/details/38018825\n","id":20,"section":"posts","summary":"👌 2020-02-17 Linux 系统 systemd 服务简介及编写 FileInfo Filename - Linux 编写系统 systemd 服务.md Version - v1.1.2002（2020/02/18 ~ 2020/02/19） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Linux","tags":["CentOS","Linux"],"title":"Linux 系统 Systemd 服务简介及编写","uri":"https://blog.standuke.top/2020/02/2020-02-17-linux-%E7%B3%BB%E7%BB%9F-systemd-%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B%E5%8F%8A%E7%BC%96%E5%86%99/","year":"2020"},{"content":"👌 2020-01-15 PXE 预启动环境安装 - Legacy 传统引导环境  FileInfo Filename - PXE Legacy Boot Configure Guide.md Version - v1.3.2001（2020/01/13 ~ 2020/01/28） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - PXE Boot with multi-system Configure Guide\n 本文约定 在文中将有以下提示符对重点进行标注说明，请注意文中提示。\n⚠️ - 文中出现此标记，代表重要提示，指需要格外注意的地方 🔘 - 文中出现此标记，代表可选配置，建议配置，但不必要 ✅ - 文中出现此标记，代表检查项目，需要检查对应的配置文件 ❗️ - 文中出现此标记，代表该操作不可随意修改，如更改此步操作，请预先测试\nPXE 简介 PXE ( Preboot Excution Environment ) 预启动执行环境，由 Intel 公司研发基于 Client/Server 的网络模式，远程主机可通过网络从远端服务器下载系统映像，并由此支持通过网络启动操作系统。PXE 可以引导和安装 Windows，Linux 等多种操作系统。 ⚠️ PXE 网络自动化安装需要搭建如下三类系统服务。\n DHCP 服务器: 提供 IP 地址，tftp 位置 网络系统镜像 YUM 源（ HTTP、FTP、NFS 三选一 ）: 提供系统安装文件 tftp 服务器: 提供 bootloader 以及内核作为启动引导  ⚠️ PXE 所使用的核心文件有以下几个。\n vmlinuz: 核心文件（kernel file） initrd.img: 开启过程中核心组件的参数 isolinux.cfg \u0026ndash;\u0026gt; demo: 开机 PXE 选择参考   原理： 由 DHCP 服务器，使服务器启动时，获取到自分配 IP，在 DHCP 配置中指定了参数 next-Server，该 next-Server 指向 tftp 服务器的 IP。如此机器获取到 IP 后，会从指定的 tftp 服务器的默认路径 /var/lib/tftpboot 下去下载相关的文件. 首先是加载 PXELinux.cfg 目录下的 default 文件，该 default 文件就是安装机器的菜单选项，在这菜单里，指定 Kickstart 文件路径和 /var/lib/tftpboot 下的 initrd.img 和 vmlinuz 的路径，使得需要安装的对应系统能够启动并加载 kickstart 文件进行安装。安装包的路径在 kickstart 文件中指定。\n ⚠️ 注意：全程使用为 UDP 封装，图中部分箭头指向方位有误\n Client 向 PXE Server 上的 DHCP 发送 IP 地址请求消息，DHCP 检测 Client 是否合法，同时将 PXE 环境下的 boot loader 文件 PXElinux.0 的位置信息发给 Client Client 向 PXE Server 上的 tftp 请求 PXELinux.0，tftp 收到消息向 Client发送 PXELinux.0大小信息，试探 Client 是否满意，当 tftp 收到 Client 发回的统一大小信息后，发送 PXELinux.0. Client 执行接收到的 PXELinux.0 Client 向 tftp 请求 PXELinux.cfg 文件（其实是目录，里面放了启动菜单，即 grub 的配置文件），tftp 将配置文件发回 Client，继而 Client 根据配置文件执行后续的操作 Client 向 tftp 发送 Linux 内核请求信息，tftp 发送内核 Client 向 tftp 发送根文件请求信息， tftp 接受到消息之后返回 Linux 根文件系统 Client 加载 Linux 内核（启动参数已经在4中的配置文件中设置好了）。 Client 通过 nfs/ftp/http 下载系统安装文件进行安装，如果4中的配置文件指定了 Kickstart 路径，则回根据此文件自动应答安装系统  基础环境准备 PXE 基础操作系统环境\n 操作系统 CentOS 7.7 （Minimal Install 最小化安装） 本地 YUM 源 建议网络速率千兆以上 ❗️关闭并禁止开机自启如下服务：系统防火墙（Firewalld、iptables） ❗️关闭并禁用 SELinux ❗️PXE环境下 DHCP 服务仅能当前 PXE 服务器提供，⚠️ 注意检查环境内是否有另外的 DHCP 服务干扰  开始安装 大致部署顺序为：DHCP、部署 HTTP、tftp、提供 bootloader 及配置文件、挂载光盘，把内核文件 cp 到 tftp 目录，并放置文件、设置菜单及提供系统安装文件。\n1. DHCP 服务器 DHCP 服务器向待安装服务器分配 IP 地址，同时指定 tftp 服务器的地址，以让服务器在获得 IP 地址后可前往 tftp 获取 bootloader 文件。\n安装 DHCP 服务\nyum install -y dhcp  修改 DHCP 服务配置（vi /etc/dhcp/dhcp.conf）默认 DHCP 配置文件为空\n# 设置子网 subnet 192.168.16.0 netmask 255.255.255.0 { range 192.168.16.2 192.168.16.249; option subnet-mask 255.255.255.0; option routers 192.168.16.254; # tftp 地址以及 pxelinux.0 的 bootloader 文件 next-server 192.168.16.1; filename \u0026quot;pxelinux.0\u0026quot;; # 以下是子网可选配置 option domain-name-servers 192.168.16.250; default-lease-time 600; max-lease-time 7200; } # 以下全局配置可选：可用 MAC 绑定某台主机 IP 地址 host clientA{ hardware ethernet 00:00:00:00:00:AB;　fixed-address 192.168.16.249; } ddns-update-style interim;  ⚠️ 若出现 No subnet declaration for eth 则需要排查如下事项\n DHCP 报错提示的 eth 网卡若已有 IP 地址则其网段必须与 DHCP 配置文件在同一网段（即 eth 网段与 DHCP 网段相同）。 若 eth 网卡未分配有 IP 地址或未开启，请务必先开启并手动分配，同时确保为 static 的方式启动，才能启动 dhcpd 服务。 使用 Vmware 虚拟机时，需要注意 DHCP 配置的 subnet 在 eth0 网卡 IP 所在网段，并且 eth0 不能是 hostonly，可以是桥接模式或 NAT 模式。和「1」相同，也是网段问题。  启动 DHCP 服务\n# 如有需要可设置开机自启 systemctl start dhcpd \u0026amp;\u0026amp; systemctl enable dhcpd  验证\n可使用 dhclient 工具测试 DHCP 服务，亦可查看 IP 租约信息 cat /var/lib/dhcpd/dhcpd.leases  2. 网络系统镜像 YUM 源（ HTTP、FTP、NFS 三选一 ） 在本文中建议使用 HTTP 作为系统 YUM 的提供方式，一个是作为 PXE 安装使用，另一个可作为系统安装完成后的系统本地 YUM 源使用，同时也可以在该台 HTTP 服务器上提供多个系统版本的 YUM 源。\nHTTP 安装 HTTP 服务\nyum install -y httpd  添加系统光盘镜像，⚠️ 可添加多个安装光盘，HTTP 服务默认把 /var/www/html 作为文件网站根目录\n# 默认将系统 OS 安装光盘上传至文件夹 /opt/mirror 可安装 lrzsz 用于上传文件 mkdir -p /opt/mirror \u0026amp;\u0026amp; cd /opt/mirror \u0026amp;\u0026amp; rz $OS_VERSION # 设置开机自动挂载至文件夹 /var/www/html/$OS_VERSION mkdir -p /var/www/html/centos77 \u0026amp;\u0026amp; vi /etc/fstab # 文件末尾添加自动挂载配置 /opt/mirror/centos77.iso /var/www/html/centos77 iso9660 defaults 0 0 # 挂载镜像文件，并检查 mount -a \u0026amp;\u0026amp; ls /var/www/html/centos77  🔘 配置 HTTP 服务，设置 ～/var/www/html/$OS_VERSION 文件夹浏览器可目录展示\n# 若如上配置完毕，此处无需修改 # 开启 autoindex 模块，默认为开启状态，注意检查 # 若配置为其他文件夹作为 HTTP YUM 提供目录，则需要配置对应目录，默认是不需要配置的，配置时注意文件夹访问权限  启动 HTTP 服务同时设置开机自启\nsystemctl start httpd \u0026amp;\u0026amp; systemctl enable httpd  验证 浏览器访问: http://localhost/centos77\n3. tftp 服务器 安装 tftp 访问\n# tftp 是由 xinetd 这个 super daemon 所管理的 # 因此要安装 xinetd，同时设定好 tftp 之后，要启动的是 xinetd; yum install tftp-server xinetd  启用 tftp\nvi /etc/xinetd.d/tftp # 修改其中参数，yes 改为 no，以启用 tftp disable = no # ⚠️ 以下是 tftp 的根目录 server_args = -s /var/lib/tftpboot  启动 tftp\nsystemctl start tftp \u0026amp;\u0026amp; systemctl enable tftp  检验\n# 安装 tftp 客户端 yum install -y tftp # 在 tftp 的根目录创建文件 cd /var/lib/tftpboot \u0026amp;\u0026amp; touch test # 本地测试连接是否可访问且可下载文件 cd ~ \u0026amp;\u0026amp; tftp localhost # 以下命令在 tftp 客户端输入 tftp\u0026gt;get test tftp\u0026gt;quit # 查看当前目录是否有刚才下载的 `test` 文件  4. 制作 bootloader 及配置文件  创建 pxelinux.cfg 启动配置文件夹  mkdir /var/lib/tftpboot/pxelinux.cfg  ⚠️ pxelinux.cfg 是个目录，可以放置默认的开机选项，也可以针对不同的客户端主机提供不同的开机选项。可以在 pxelinux.cfg 目录内建立一个名为 default 的文件来提供默认选项。\n 准备启动菜单，复制 系统安装光盘 下的 isolinux.cfg 文件，作为默认菜单文件  cp /$SYSTEM_ISO_MIRROR/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default  ⚠️ isolinux.cfg 文件为系统启动菜单\n 准备 bootloader 及配置文件  # bootloader 所需文件由 syslinux 软件包提供，这里不建议从系统镜像中获得 bootloader yum install -y syslinux # 从 syslinux 复制几个启动文件至 tftp 根目录 cp -a /usr/share/syslinux/{menu.c32,vesamenu.c32,pxelinux.0} /var/lib/tftpboot  ⚠️ pxelinux.0 为启动操作系统的文件；menu.c32 这个是菜单风格；vesamenu.c32 这个是图像风格\n 准备计算机启动所需的内核文件和虚拟根文件  cp/misc/cd/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/   ❗️ 最后文件结构为  tree /var/lib/tftpboot |__initrd.img # 虚拟根文件 |__menu.32c # 菜单风格 |__pexlinux.0 # 启动操作系统的文件 |__pxelinux.cfg # 放置默认的开机选项 | |__default # 即 isolinux.cfg 系统启动菜单 |__vesamenu.32c # 图像风格 |__vmlinuz # 内核文件   ❗️ default 文件配置修改，需添加或修改成如下内容  label linux menu label^Install CentOS 7 menu default kernel vmlinuz append initrd=initrd.img inst.repo=http://192.168.16.1/centos77 inst.ks=http://192.168.16.1/ks.cfg quiet   ❗️ ks 文件配置修改  cdrom # 改为 url --url=\u0026quot;http://192.168.16.1/centos77\u0026quot;  5. 光盘部分文件介绍 isolinux/boot.cat：这个文件作用是类型MBR（Main Boot Record），负责磁盘操作系统(DOS)对磁盘进行读写时分区合法性的判别、分区引导信息的定位，启动的stage1.\nisolinux/isolinux.bin,负责光盘的stage2,也是二进制文件，作用类似grub的第二阶段\nisolinuz/vmlinuz：是linux的内核，相当于是一个小的linux系统\nisolinuz/initrd.img，一般被用来临时的引导硬件到实际内核vmlinuz能够接管并继续引导的状态\nisolinux/isolinux.cfg：这个是光盘启动时的菜单文件，菜单的风格是文件vesamenu.c32.在isolinux.cfg里有调用，该文件里还指定了内核isolinuz/vmlinuz和isolinuz/initrd.img的路径，向内核传递参数：append initrd=initrd.img，这段参数可以自己定制，如在后面加text,就会实现字符界面安装，这个用于自动化安装，不适合于手动安装，鼠标点不了的。字符界面一般用于自动化安装。\n在isolinux.cfg文件中指明kickstart文件的位置，有以下几个路径进行调用该文件，写法如下\nDVD drive:ks=cdrom:/PATH/TO/KICKSTART_FILE Hard drive:ks=hd:device:/directory/KICKSTART_FILE HTTP server:ks=http://host:port/path/to/KICKSTART_FILE FTP server:ks=ftp://host:port/path/to/KICKSTART_FILE HTTPS server:ks=https://host:port/path/to/KICKSTART_FILE NFSserver:ks=nfs:host:/path/to/KICKSTART_FILE  详细可见: https://blog.51cto.com/ghbsunny/1969593\n6. ks（Kickstart）文件 如下为系统默认 最小化安装 时的 ks 文件（anaconda-ks.cfg）\n#version=DEVEL # System authorization information auth --enableshadow --passalgo=sha512 # Use CDROM installation media cdrom # Use graphical install graphical # Run the Setup Agent on first boot firstboot --enable # Keyboard layouts keyboard --vckeymap=us --xlayouts='us' # System language lang en_US.UTF-8 # Network information network --bootproto=dhcp --device=enp0s3 --onboot=off --ipv6=auto --no-activate network --hostname=localhost.localdomain # Root password rootpw --plaintext 123456 # System services services --disabled=\u0026quot;chronyd\u0026quot; # System timezone timezone Asia/Shanghai --isUtc --nontp # System bootloader configuration bootloader --location=mbr --boot-drive=sda autopart --type=lvm # Partition clearing information clearpart --none --initlabel %packages @^minimal @core %end %addon com_redhat_kdump --disable --reserve-mb='auto' %end %anaconda pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty %end  如下为建议使用的 ks 文件（请自行创建）\n#platform=x86, AMD64, or Intel EM64T #version=DEVEL # Install OS instead of upgrade install # Keyboard layouts keyboard 'us' # Root password rootpw --plaintext 123456 # System language lang en_US # System authorization information auth --useshadow --passalgo=sha512 # Use text mode install text # SELinux configuration selinux --disabled # Do not configure the X Window System skipx # Firewall configuration firewall --disabled # Reboot after installation reboot # System timezone timezone Asia/Shanghai # Use network installation url --url=\u0026quot;http://192.168.16.1/centos77\u0026quot; # System bootloader configuration bootloader --location=mbr # Clear the Master Boot Record zerombr # Partition clearing information clearpart --all --initlabel # Disk partitioning information part /boot --fstype=\u0026quot;xfs\u0026quot; --ondisk=sda --size=1024 %packages @^minimal @core %end %addon com_redhat_kdump --disable --reserve-mb='auto' %post PS1=' \\[\\033[0;33m\\]\u0026gt;\\u \\[\\033[0;37m\\]\\w\\n\\[\\033[1;32m\\][\\h]\\[\\033[01;31m\\]\\$ \\[\\033[00m\\]' yum install -y wget unzip ethtool git bind-utils sysstat iptraf lsof tmux tree lrzsz vim man-pages bash-completion dos2unix %end  一键 PXE #!/bin/bash restart_DHCPd() { service DHCPd restart \u0026amp;\u0026gt;/dev/null; chkconfig DHCPd on \u0026amp;\u0026gt;/dev/null; } restart_tftp () { sed -i 's/disable.*/disble = no/g' /etc/xinetd.d/tftp \u0026amp;\u0026gt;/dev/null; chkconfig tftp on \u0026amp;\u0026gt;/dev/null; service xinetd restart \u0026amp;\u0026gt;/dev/null; } restart_httpd(){ service httpd restart \u0026amp;\u0026gt;/dev/null; chkconfig httpd on \u0026amp;\u0026gt;/dev/null; } min_time () { time=`date +%Y%m%d%H%M` } ip=$(ifconfig | awk '/inet /{print $2}'| awk -F : '{print $NF}'| head -1) min_time; #install Server echo \u0026quot;Now install DHCP,http,tftp Server and tftp Client,it might take few minites\u0026quot; rpm -q httpd \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; restart_httpd || { yum -y install httpd \u0026amp;\u0026gt;/dev/null;restart_httpd; } rpm -q DHCP \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; restart_DHCPd || { yum -y install DHCP\u0026amp;\u0026gt;/dev/null;restart_DHCPd; } rpm -q tftp-Server \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; restart_tftp || { yum -y install tftp-Server \u0026amp;\u0026gt;/dev/null;restart_tftp; } rpm -q tftp \u0026amp;\u0026gt;/dev/null || yum -y install tftp \u0026amp;\u0026gt;/dev/null; #For centos 6.9,file PXELinux.0 comes from packges sysLinux-nonLinux,other version is from sysLinux,but if you install packge sysLinux,it will also install sysLinux-nonLinux packge,so just install sysLinux packge is OK to get file sysLinux-nonLinux. rpm -q sysLinux \u0026amp;\u0026gt;/dev/null || yum -y install sysLinux \u0026amp;\u0026gt;/dev/null; #set http for yum Server #mount yum source echo \u0026quot;Now you need to config yum Server in http Server\u0026quot; echo \u0026quot;Since I do not know which different disc your disc will be displayed,such as,centos7 display as /dev/sr0,or display as/dev/sr1 or other device \u0026quot; echo \u0026quot;This time,I have three disks,6i386 means 386 arch for ceentos6.5,6x86_64 means 64bit for centos6.9,7 means centos7.3\u0026quot; echo \u0026quot;the relation of my disk dislay in the centos as below\u0026quot; echo -e \u0026quot;/dev/sr0 ---\u0026gt; 6x86_64 \\n/dev/sr1 ---\u0026gt; 6i386 \\n/dev/sr2 ---\u0026gt; 7\u0026quot; mkdir -p /var/www/html/os/{6i386,6x86_64,7} read -p \u0026quot;Would you want to mount disk auto:(eg:y/n): \u0026quot; automount case $automount in y) echo -e \u0026quot;/dev/sr0 ---\u0026gt; 6x86_64 \\n/dev/sr1 ---\u0026gt; 6i386 \\n/dev/sr2 ---\u0026gt; 7\u0026quot; mount /dev/sr0 /var/www/html/os/6x86_64 mount /dev/sr1 /var/www/html/os/6i386 mount /dev/sr2 /var/www/html/os/7 ;; *) echo \u0026quot;Since your answer is no or other,please mount disk after the script end\u0026quot; echo \u0026quot;eg: run mount /dev/sr0 /var/www/html/os/6x86_64 \u0026quot; echo \u0026quot;eg: if your want to mount the disk fixed,please write to /etc/fstab,eg: /dev/sr0 /var/www/html/os/6x86_64 iso9660 defaults 0 0 \u0026quot; ;; esac #prepare ks file in /var/www/html/ksdir echo \u0026quot;If your have put ks file in other hosts,your should input remote ,and input the remote file full path,and it will use scp ⌘ to copy the ks file directory to /var/www/html/ksdir\u0026quot; echo \u0026quot;If you put dir in local host,input local,it will will cp ⌘ to copy the ks file directory to /var/www/html/ksdir\u0026quot; echo \u0026quot;if you input any other,you should cp ksdir to /var/www/html/ksdir\u0026quot; read -p \u0026quot;Do you want to copy remote ks dir( r (remote) or l (local) or any other input ): \u0026quot; ifcopy mkdir -p /var/www/html/ksdir/ case $ifcopy in r|remote) read -p \u0026quot;input the remote ksdir directory(defaults:root@172.18.50.75:/var/www/html/ksdir/*): \u0026quot; ksdir if [ -z ${ksdir:-} ];then ksdir=\u0026quot;root@172.18.50.75:/var/www/html/ksdir/*\u0026quot; fi read -p \u0026quot;input host user's password you have put: \u0026quot; passwd expect -c \u0026quot; spawn scp $ksdir /var/www/html/ksdir/ expect { \\\u0026quot;*assword\\\u0026quot; {set timeout 300; send \\\u0026quot;$passwd\\r\\\u0026quot;; } \\\u0026quot;yes/no\\\u0026quot; { send \\\u0026quot;yes\\r\\\u0026quot;; exp_continue; } } expect eof\u0026quot; ls /var/www/html/ksdir | while read ksfile; do sed -i \u0026quot;s@url --url=\\\u0026quot;http://.*/os/@url --url=\\\u0026quot;http://$ip/os/@g\u0026quot; /var/www/html/ksdir/$ksfile done ;; l|local ) read -p \u0026quot;Please input your local ks directory(eg:/root/ksdir/*): \u0026quot; ksdir cp $ksdir /var/www/html/ksdir/ ;; *) echo \u0026quot;your input is wrong,please manual copy ksdir to /var/www/html/ksdir/\u0026quot; ;; esac #config DHCP echo \u0026quot;Now config DHCP Server...\u0026quot; read -p \u0026quot;Input your next-Server ip(default is your host ip): \u0026quot; nextip if [ -z ${nextip:-} ];then nextip=\u0026quot;$ip\u0026quot; fi echo nextip is \u0026quot;$nextip\u0026quot; mv /etc/DHCP/DHCPd.conf /etc/DHCP/DHCPd.conf.\u0026quot;$time\u0026quot;.bak cat \u0026gt;/etc/DHCP/DHCPd.conf\u0026lt; option domain-name \u0026quot;sunny.com\u0026quot;; option domain-name-Servers 192.168.32.61; default-lease-time 86400; max-lease-time 86400; subnet 192.168.32.0 netmask 255.255.255.0 { range 192.168.32.100 192.168.32.200; option routers 192.168.32.1; next-Server $nextip; filename \u0026quot;PXELinux.0\u0026quot;; } log-facility local7; eof echo \u0026quot;As default,the DHCP Server will alocate ip 192.168.32.100--192.168.32.200,dns Server is 192.168.32.61,router is 192.168.32.1,if you want to change these config ,please run 'vim /etc/DHCP/DHCPd.conf' to change /etc/DHCP/DHCPd.conf\u0026quot; echo \u0026quot;DHCP is complete config now\u0026quot; #config tltp echo \u0026quot;If you want to copy Linux kernel file to /var/lib/tftpboot/{6i386,6x86_64,7}\u0026quot; read -p \u0026quot;Please input m(means manual) or a (means auto): \u0026quot; copyfile case $copyfile in a) mkdir -p /var/lib/tftpboot/{6i386,6x86_64,7} cp /var/www/html/os/6i386/isoLinux/{initrd.img,vmlinuz} /var/lib/tftpboot/6i386 cp /var/www/html/os/6x86_64/isoLinux/{initrd.img,vmlinuz} /var/lib/tftpboot/6x86_64 cp /var/www/html/os/7/isoLinux/{initrd.img,vmlinuz} /var/lib/tftpboot/7 ;; *) echo \u0026quot;Your input is m or other things\u0026quot; echo \u0026quot;you should do two things after the scripts\u0026quot; echo \u0026quot;create directory under /var/lib/tftpboot/,such as mkdir /var/lib/tftpboot/6i386\u0026quot; echo \u0026quot;copy the kernel file to the relative dir,such as cp /var/www/html/os/6i386/isoLinux/{initrd.img,vmlinuz} /var/lib/tftpboot/6i386\u0026quot; echo \u0026quot;If you hve many other yum source,please create relative dir under /var/lib/tftpboot/6i386\u0026quot; ;; esac cp /usr/share/sysLinux/{PXELinux.0,menu.c32} /var/lib/tftpboot/ echo \u0026quot;Now config defaults file ,you can copy the host relative disk file ,/media/isoLinux/isoLinux.cfg to /var/lib/tftpboot/PXELinux.cfg,and rename it to defaults,and the modify the config,run ⌘ 'cp /media/isoLinux/isoLinux.cfg /var/lib/tftpboot/ PXELinux.cfg/default' \u0026quot; echo \u0026quot;Now I will config /var/lib/tftpboot/PXELinux.cfg/default\u0026quot; mkdir /var/lib/tftpboot/PXELinux.cfg cat \u0026gt; /var/lib/tftpboot/PXELinux.cfg/default\u0026lt; default menu.c32 #prompt 1 timeout 80 display boot.msg menu background splash.jpg menu title Welcome to Sunny diy install Linux! menu color border 0 #ffffffff #00000000 menu color sel 7 #ffffffff #ff000000 menu color title 0 #ffffffff #00000000 menu color tabmsg 0 #ffffffff #00000000 menu color unsel 0 #ffffffff #00000000 menu color hotsel 0 #ff000000 #ffffffff menu color hotkey 7 #ffffffff #ff000000 menu color scrollbar 0 #ffffffff #00000000 label desktop73 menu label Install diy ^desktop centos 7 menu default kernel 7/vmlinuz append initrd=7/initrd.img ks=http://$ip/ksdir/ks73desk.cfg label mini73 menu label Install diy ^mini centos 7 menu default kernel 7/vmlinuz append initrd=7/initrd.img ks=http://$ip/ksdir/ks73min.cfg label desktop6.5 menu label Installed d^esktop centos 6.5 i386 kernel 6i386/vmlinuz append initrd=6i386/initrd.img ks=http://$ip/ksdir/ks65desk.cfg label mini6.5 menu label Install m^ini centos 6.5 i386 kernel 6i386/vmlinuz append initrd=6i386/initrd.img ks=http://$ip/ksdir/ks65min.cfg label desktop6.9 menu label Installed de^sktop centos 6.9 kernel 6x86_64/vmlinuz append initrd=6x86_64/initrd.img ks=http://$ip/ksdir/ks69desk.cfg label mini6.9 menu label Install mi^ni centos 6.9 kernel 6x86_64/vmlinuz append initrd=6x86_64/initrd.img ks=http://$ip/ksdir/ks69min.cfg eof echo \u0026quot;tftp is config OK\u0026quot; #restart Server echo \u0026quot;now restart Server\u0026quot; restart_httpd; restart_tftp; restart_DHCPd; netstat -ntulp | grep DHCPd | grep :67 \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026quot;DHCP is running...\u0026quot; || echo \u0026quot;DHCP is not run,please check\u0026quot; netstat -ntulp | grep httpd | grep :80 \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026quot;http is running...\u0026quot; || echo \u0026quot;http is not run,please check\u0026quot; netstat -ntulp | grep xinetd | grep 69 \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026quot;tftp is running...\u0026quot; || echo \u0026quot;tftp is not run,please check\u0026quot;  安装校验及注意事项  PXE 服务开机自启 ⚠️ 当需要安装的服务器自动安装完毕后记得关闭 PXE 服务，因为万一出现业务系统服务器开机找不到系统，自动从 PXE 引导，会被重新安装操作系统（从 PXE 到跑路……） 因安装时关闭了系统防火墙，如有需要，请重新开启 因安装需要配置的 DHCP 服务，很大程度上在之后的业务中并不会使用 PXE 的 DHCP 服务，注意检查或关闭此 DHCP 服务 使用 PXE 自动化安装系统，最小内存要求为 2GB，使用虚拟机部署请注意  修订信息    版本号 修订日期 修订人 备注     v1.1.2001 2020-01-13 NUO 建立文档   v1.2.2001 2020-01-16 NUO 更新 ks 文件   v1.3.2001 2020-01-28 NUO 更新光盘文件说明    ","id":21,"section":"posts","summary":"👌 2020-01-15 PXE 预启动环境安装 - Legacy 传统引导环境 FileInfo Filename - PXE Legacy Boot Configure Guide.md Version - v1.3.2001（2020/01/13 ~ 2020/01/28） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - PXE Boot","tags":["CentOS","PXE"],"title":"PXE 预启动环境安装 - Legacy 传统引导环境","uri":"https://blog.standuke.top/2020/01/2020-01-15-pxe-%E9%A2%84%E5%90%AF%E5%8A%A8%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85-legacy-%E4%BC%A0%E7%BB%9F%E5%BC%95%E5%AF%BC%E7%8E%AF%E5%A2%83/","year":"2020"},{"content":"👌 2020-01-14 Markdown 文档编写语法指北  FileInfo Filename - Markdown Syntax And Writing Specifications Guide.md Version - v1.2.2001（2020/01/14 ~ 2020/01/15） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Markdown Syntax And Writing Specifications \u0026amp; Chinese and Western typography \u0026amp; Punctuation Specification\n 文件编写约定 在文件开头将会标注文件的信息，文件信息包括文件名称，用于文件检索。同时会标注文件的版本信息，版本信息格式为v + 大版本号 + 修订版本号 + 修订年月，例如v1.2.1909所代表的含义为第一个大版本、第二个修订版、修订年月为 2019 年 9 月。之后为作者及联系方式。文档描述和关键字用于搜索软件检索文档。\n 欢迎效仿\n Markdown 的设计哲学 Markdown 是一种轻量级标记语言，创始人为约翰·格鲁伯（John Gruber）。它允许人们『使用易读易写的纯文本格式编写文档，然后转换成有效的 XHTML（或者 HTML）文档』。 故 Markdown 的目标是实现文档的「易读易写」。其中最需要强调的是它的易读性。一份使用 Markdown 格式的文件在纯文字发布的情况下，看起来都不会像是有许多符号所组成的文档。 由于Markdown的轻量化、易读易写特性，并且对于图片，图表、数学式都有支持，当前许多网站都广泛使用 Markdown 来撰写帮助文档或是用于论坛上发表消息。\n文章结构及阅读指北 在本篇文档中将会分为三大部分。第一部分是基础的 Markdown 语法以及使用范例；第二部分为书写排版及中西文混排范例（部分来自百度前端团队、知乎）；第三部分为标点符号使用范例（来自知乎）。相关可查看 Github 规范 以及 知乎修改规范 、中文文案排版指北\n[TOC]\n ⚠️ 以上为文档简介，正文及规范从下文开始，因为考虑到三大部分的独立性，故各个部分均相互独立，且均以 一级标题 开始\n Markdown 语法 1. 标题 Markdown 语法：\n# 第一级标题 `\u0026lt;h1\u0026gt;` ## 第二级标题 `\u0026lt;h2\u0026gt;` ###### 第六级标题 `\u0026lt;h6\u0026gt;`  效果如下：\n第一级标题 \u0026lt;h1\u0026gt; 第二级标题 \u0026lt;h2\u0026gt; 第六级标题 \u0026lt;h6\u0026gt; 2. 强调 Markdown 语法：\n*这些文字会生成`\u0026lt;em\u0026gt;`* _这些文字会生成`\u0026lt;u\u0026gt;`_ **这些文字会生成`\u0026lt;strong\u0026gt;`** __这些文字会生成`\u0026lt;strong\u0026gt;`__  效果如下：\n这些文字会生成\u0026lt;em\u0026gt; 这些文字会生成\u0026lt;u\u0026gt;\n这些文字会生成\u0026lt;strong\u0026gt; 这些文字会生成\u0026lt;strong\u0026gt;\n3. 换行 四个及以上空格加回车。\n4. 列表 无序列表 Markdown 语法：\n* 项目一 无序列表 `* + 空格键` * 项目二 * 项目二的子项目一 无序列表 `TAB + * + 空格键` * 项目二的子项目二  效果如下：\n 项目一 无序列表 * + 空格键 项目二  项目二的子项目一 无序列表 TAB + * + 空格键 项目二的子项目二    有序列表 Markdown 语法：\n1. 项目一 有序列表 `数字 + . + 空格键` 2. 项目二 3. 项目三 1. 项目三的子项目一 有序列表 `TAB + 数字 + . + 空格键` 2. 项目三的子项目二  效果如下：\n 项目一 有序列表 数字 + . + 空格键 项目二 项目三  项目三的子项目一 有序列表 TAB + 数字 + . + 空格键 项目三的子项目二    列表中嵌入代码块语法 1. 项目一 有序列表 `数字 + . + 空格键` 列表中嵌入代码块必须前后空一行，如这个写法 ```js function fancyAlert(arg) { if(arg) { $.facebox({div:'#foo'}) } } ``` 其他文本。 2. 项目二  任务列表（Task lists） Markdown 语法：\n- [ ] 任务一 未做任务 `- + 空格 + [ ]` - [x] 任务二 已做任务 `- + 空格 + [x]`  效果如下：\n 任务一 未做任务 - + 空格 + [ ] 任务二 已做任务 - + 空格 + [x]  5. 图片 Markdown 语法：\n![GitHub set up](http://URL/set-up-git.gif) 格式: ![Alt Text](url)  效果如下：\n6. 链接 Markdown 语法：\nemail \u0026lt;example@example.com\u0026gt; [GitHub](http://github.com) 自动生成连接 \u0026lt;http://www.github.com/\u0026gt;  效果如下：\nEmail 连接： example@example.com 连接标题Github网站 自动生成连接像： http://www.github.com/ 这样\n7. 区块引用 Markdown 语法：\n某某说: \u0026gt; 第一行引用 \u0026gt; 第二行费用文字  效果如下：\n某某说:\n 第一行引用 第二行费用文字\n 8. 行内代码 Markdown 语法：\n像这样即可：`\u0026lt;addr\u0026gt;` `code`  效果如下：\n像这样即可：\u0026lt;addr\u0026gt; code\n9. 多行或者一段代码 Markdown 语法：\n```js function fancyAlert(arg) { if(arg) { $.facebox({div:'#foo'}) } } ```  效果如下：\nfunction fancyAlert(arg) { if(arg) { $.facebox({div:'#foo'}) } }  10. 顺序图或流程图 Markdown 语法：\n```sequence 张三-\u0026gt;李四: 嘿，小四儿, 写博客了没? Note right of 李四: 李四愣了一下，说： 李四--\u0026gt;张三: 忙得吐血，哪有时间写。 ``` ```flow st=\u0026gt;start: 开始 e=\u0026gt;end: 结束 op=\u0026gt;operation: 我的操作 cond=\u0026gt;condition: 确认？ st-\u0026gt;op-\u0026gt;cond cond(yes)-\u0026gt;e cond(no)-\u0026gt;op ```  效果如下（「」）：\n张三-\u0026gt;李四: 嘿，小四儿, 写博客了没? Note right of 李四: 李四愣了一下，说： 李四--\u0026gt;张三: 忙得吐血，哪有时间写。  st=\u0026gt;start: 开始 e=\u0026gt;end: 结束 op=\u0026gt;operation: 我的操作 cond=\u0026gt;condition: 确认？ st-\u0026gt;op-\u0026gt;cond cond(yes)-\u0026gt;e cond(no)-\u0026gt;op  更多请参考：http://bramp.github.io/js-sequence-diagrams/, http://adrai.github.io/flowchart.js/\n11. 表格 Markdown 语法：\n第一格表头 | 第二格表头 --------- | ------------- 内容单元格 第一列第一格 | 内容单元格第二列第一格 内容单元格 第一列第二格 多加文字 | 内容单元格第二列第二格  效果如下：\n   第一格表头 第二格表头     内容单元格 第一列第一格 内容单元格第二列第一格   内容单元格 第一列第二格 多加文字 内容单元格第二列第二格    12. 删除线 Markdown 语法：\n加删除线像这样用： ~~删除这些~~  效果如下：\n加删除线像这样用： 删除这些\n13. 分隔线 以下三种方式都可以生成分隔线：\n*** ***** - - -  效果如下：\n   14. MathJax Markdown 语法：\n块级公式： $$\tx = \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ \\\\[ \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5}}-\\phi\\Bigr) e^{\\frac25 \\pi}} = 1+\\frac{e^{-2\\pi}} {1+\\frac{e^{-4\\pi}} {1+\\frac{e^{-6\\pi}} {1+\\frac{e^{-8\\pi}} {1+\\ldots} } } } \\\\] 行内公式： $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$  效果如下（「」）：\n块级公式： $$\tx = \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$\n\\[ \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5}}-\\phi\\Bigr) e^{\\frac25 \\pi}} = 1+\\frac{e^{-2\\pi}} {1+\\frac{e^{-4\\pi}} {1+\\frac{e^{-6\\pi}} {1+\\frac{e^{-8\\pi}} {1+\\ldots} } } } \\]\n行内公式： $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$\n15. 脚注（Footnote） Markdown 语法：\n这是一个脚注：[^sample_footnote]  效果如下：\n这是一个脚注：1\n16. 高亮（Highlight） Markdown 语法：\n==example==  效果如下： ==example==\n17. 注释和阅读更多 Markdown 语法：\n\u0026lt;!-- comment --\u0026gt; \u0026lt;!-- more --\u0026gt;  注 阅读更多的功能只用在生成网站或博客时，插入时注意要后空一行。\n18. 锚点链接 Markdown 语法：\n任意 1-6 个 # 标注的标题都会被添加上同名的锚点链接\n[标题1](#标题1) [标题2](#标题2) [标题3](#标题3) # 标题1 ## 标题2 ### 标题3  锚点跳转的标识名称，可使用任意字符，大写字母要转换成小写\n[Github标题1](#github标题1) ### Github标题1  多单词锚点的空格用 - 代替\n[Github 标题2 Test](#github-标题2-test) ### Github 标题2 Test  多级序号需要去除 .\n[2.3. Github 标题](#23-github-标题) ### 2.3. Github 标题  注 Github 并不支持 HTML 形式的锚点链接，它有自己的规则。由于很多渲染器不支持锚点，故尽量少使用锚点。非英文的锚点字符，在单击跳转时，在浏览器的 url 中会按照规则进行 encode 和 decode。 更多请参考：https://my.oschina.net/antsky/blog/1475173/\n19. TOC Markdown 语法：\n[TOC]  效果如文档开头的目录\n  书写排版及中西文混排范例 1. 书写排版范例 文档大标题必须以 # 开头 章节标题必须以 ## 开始，而不是 # 凡是标题，下方正文书写必须空一行\n例如：\n// bad ##章节1 // bad ## 章节1 ## // good ## 章节1 // bad ## 章节1 内容 ## 章节2 // good ## 章节1 内容 ## 章节2  代码段的必须「MUST」使用 Fenced code blocks 风格，如下所示：\nconsole.log(\u0026quot;\u0026quot;);  表格的写法应该参考 GFM，如下所示：\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell       Left-Aligned Center Aligned Right Aligned     col 3 is some wordy text $1600   col 2 is centered $12   zebra stripes are neat $1    2. 中西文混排范例 中西文混排应该采用如下规则：\n【基本规则】\n 英文和数字使用半角字符 中文文字之间不加空格 中文文字与英文、阿拉伯数字及 @ # $ % ^ \u0026amp; * . ( ) 等符号之间加空格 中文标点之间不加空格 中文标点与前后字符（无论全角或半角）之间不加空格 如果括号内有中文，则使用中文括号 如果括号中的内容全部都是英文，则使用半角英文括号 当半角符号 / 表示「或者」之意时，与前后的字符之间均不加空格 结尾不改写西文专有名词中的半角标点如 \u0026ldquo;McDonald\u0026rsquo;s\u0026rdquo; 中西文（和其他西文半角符号）间留一个半角空格 中文和阿拉伯数字之间同样需留一个半角空格包裹 中文内容的引号应使用直角引号「」或『』 包裹西文内容的引号可以使用 \u0026quot;\u0026quot; 或 '' 包裹西文内容的括号可以使用 () 或（）  以下示例的情况无需修改： 为什么 OS X 的市场份额不及 Windows？ 苹果公司 (Apple) 的招聘流程是怎样的？ 1970 年代的美国电影有哪些推荐？ 如何理解 \u0026lsquo;double irish with a dutch sandwich\u0026rsquo; 避税方法？\n【表达方式】\n 应当遵循《The Element of Style》 使段落成为文章的单元 一个段落只表达一个主题 通常在每一段落开始要点题，在段落结尾要扣题 使用主动语态 陈述句中使用肯定说法 删除不必要的词 避免连续使用松散的句子 使用相同的结构表达并列的意思 将相关的词放在一起 在总结中，要用同一种时态（这里指英文中的时态，中文不适用，所以可以不理会） 将强调的词放在句末 避免模糊 误：最近有哪些值得推荐的喜剧电影？ 正：2012 年 7 月 有哪些值得推荐的喜剧电影？ 与内容无关的冗余修辞，需要删除  需要修改的词语 网络用语例：「东东」 应为「东西」 ，「神马」应为「什么」 口头语例：「为啥」应为「为什么」 不文明用语例：「牛逼」应为「厉害」「强大」等 错别字：「斯德哥尔摩综合症」应为「斯德哥尔摩综合征」\n扩展阅读 Google 后来也出了 Markdown 规范，很多和这里是一样的，但也增加了一些约定，可以参考\n  标点符号使用 注意事项 避免重复混乱 英文问号（?）、重复（？？？）、混乱（？！） 逗号：英文逗号（,）、重复（，，，）、混乱（，，。）\n问号 选择问句中，问号只用在末尾 误：今后十年内，主流手机的系统谁主沉浮？Android？Windows Phone？MeeGo ？iOS？ 正：今后十年内，主流手机的系统谁主沉浮？Android、Windows Phone、MeeGo、iOS？\n连续提问时，每个-问句的后面都以问号结尾 误：当前移动互联网的第一大入口是什么，竞争力如何？ 正：当前移动互联网的第一大入口是什么？竞争力如何？\n省略号 使用规范的「……」，禁用各种错误变体「。。」「。。。」「。。。。。。」出于简洁考虑，尽量不在标题中使用省略号 省略号使用「……」，而「。。。」仅用于表示停顿\n顿号 同类、并列的单字、词语和短语用顿号分隔并列的书名号、引号之间，可用可不用，全文统一即可\n书名号 书名、篇名、报纸名、杂志名、歌曲名、影剧名和图表名，用书名号标识括号用作注明翻译或原文时应置于书名号外 误：《旺达与巨像（Shadow of the Colossus）》好玩吗？ 正：《旺达与巨像》（Shadow of the Colossus）好玩吗？\n引号 包裹对象为中文时使用直角引号「」或『』包裹对象为西文时可以使用 \u0026quot;\u0026quot; 或 '' 且左右留有半角空格间接引用中句末的句号、问号、感叹号等标点符号应去掉 用直角引号（「」）代替双引号（\u0026quot;\u0026quot;） 误：鸡蛋被嫌小时母鸡反驳「你下一个试试？」的逻辑或理由是什么？ 正：鸡蛋被嫌小时母鸡反驳「你下一个试试」的逻辑或理由是什么？\n括号 使用括号对内容进行补充说明（如增加信息、消除歧义等）括号的使用原则： 去掉括号的内容句子依然是正确通顺的需要使用外语来详细或准确表述的名词，应当放入括号中 误：为什么样本方差 sample variance 的分母是 n-1？ 正：为什么样本方差（sample variance）的分母是 n-1？ 或：正：为什么样本方差 (sample variance) 的分母是 n-1？\n纠错更新 「使用顿号连接的短语必须是名词性的」这个判断是错误的，是否有其他限制，暂未见可靠出处。（来自葛易） 「使用括号注明对名称的翻译（或原文）应置于书名号内」这个用法是错误的，Shadow of the Colossus 是对「《旺达与巨像》」进行注释，而非「旺达与巨像」。（来自 Raymond Wang、黄继新） 不建议在标题等公共区域将『』「」做书名号使用，以保持统一和规范、避免混乱。（来自梁海） 需要删除的词语「指称」加上「楼主」。个人建议「伟大」应改为「强大」，因为它最接近「牛逼」的本意。（来自郅帅杰）\n  修订信息    版本号 修订日期 修订人 备注     v1.1.2001 2020-01-14 NUO 建立文档   v1.2.2001 2020-01-15 NUO 添加相关出处链接；添加锚点      这里是脚注信息，在脚注后直接添加即可，渲染器会直接放置在文章末尾 \u0026#x21a9;\u0026#xfe0e;\n   ","id":22,"section":"posts","summary":"👌 2020-01-14 Markdown 文档编写语法指北 FileInfo Filename - Markdown Syntax And Writing Specifications Guide.md Version - v1.2.2001（2020/01/14 ~ 2020/01/15） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - Markdown Syntax And Writing Specifications \u0026amp; Chinese and","tags":["Markdown"],"title":"Markdown 文档编写语法指北","uri":"https://blog.standuke.top/2020/01/2020-01-14-markdown-%E6%96%87%E6%A1%A3%E7%BC%96%E5%86%99%E8%AF%AD%E6%B3%95%E6%8C%87%E5%8C%97/","year":"2020"},{"content":"👌 2019-12-23 CentOS 7 重置 root 用户密码 rd.break方法：推荐  启动的时候，在 GRUB2 启动界面，相应启动项，内核名称上按\u0026quot;e\u0026quot;修改启动参数； 进入后，找到 linux16 开头的行，把改行ro后面的字符全部删除「快捷键 Ctrl+K」再输入 rd.break 按 ctrl+x 进入； 重新挂的磁盘获得读写权限 mount -o remount,rw /sysroot; chroot /sysroot 改变根； passwd root修改 root 密码； touch /.autorelabel 使 selinux 生效 exit exit 退出 自动 reboot  init方法：未尝试  启动系统，并在GRUB2启动屏显时，按下e键进入编辑模式。 在linux16/linux/linuxefi所在参数行尾添加以下内容：init=/bin/sh 按Ctrl+x启动到shell。 挂载文件系统为可写模式：mount –o remount,rw/ 运行passwd,并按提示修改root密码。passwd 如果之前系统启用了selinux，必须运行以下命令，否则将无法正常启动系统：touch /.autorelabel 运行命令exec /sbin/init来正常启动，或者用命令exec /sbin/reboot重启exec /sbin/init  参考资料 https://www.cnblogs.com/bobkingblog/p/11049772.html\n","id":23,"section":"posts","summary":"👌 2019-12-23 CentOS 7 重置 root 用户密码 rd.break方法：推荐 启动的时候，在 GRUB2 启动界面，相应启动项，内核名称上按\u0026quot;e\u0026quot;修改启动参数； 进","tags":["CentOS"],"title":"CentOS 7 重置 Root 用户密码","uri":"https://blog.standuke.top/2019/12/2019-12-23-centos-7-%E9%87%8D%E7%BD%AE-root-%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81/","year":"2019"},{"content":"👌 2019-10-03 CentOS 登陆出现 module is unknown 不能登陆 由于 CentOS 更改了某些配置之后，导致系统无法登陆，出现 module is unknown 提示，一直循环在登陆系统界面。 由于在配置oracle的安装环境时，更改了 /etc/pam.d/login 下面的文件，在里面加入了如下配置：\nsession required /lib/security/pam_limits.so session required pam_limits.so  后来发现，这是配置 32 位系统的，如果是 64 位系统，则需要更改为如下：\nsession required /lib64/security/pam_limits.so session required pam_limits.so  ⚠️ 说明：如果更改了之后，启动系统登录时出现 module is unknown，可使用 ssh 终端连接工具，连接上之后更改配置，然后再次登录就可以。也就是说不影响 ssh 方式登录。\n","id":24,"section":"posts","summary":"👌 2019-10-03 CentOS 登陆出现 module is unknown 不能登陆 由于 CentOS 更改了某些配置之后，导致系统无法登陆，出现 module is unknown 提示，一直循环在登陆系统界面。 由于在配置oracle的安装","tags":["CentOS"],"title":"CentOS 登陆出现 Module Is Unknown 不能登陆","uri":"https://blog.standuke.top/2019/10/2019-10-03-centos-%E7%99%BB%E9%99%86%E5%87%BA%E7%8E%B0-module-is-unknown-%E4%B8%8D%E8%83%BD%E7%99%BB%E9%99%86/","year":"2019"},{"content":"👌 2019-09-12 Windows Server 2008 R2 已经激活但每隔一段时间自动关机 VMware 环境 原因： C:\\Windows\\system32\\wlms\\wlms.exe程序关闭的系统\n处理方案： 1.bat批处理文件\ntaskkill /f /im wlms.exe ping -n 4 127.0.0.1 shutdown -a  2.下载PSTools后修改注册表\n下载链接：https://docs.microsoft.com/en-us/sysinternals/downloads/pstools\nWin + R ⌘ 打开运行（文件放在C盘）即管理员权限打开 C:\\PSTools\\psexec.exe -d -i -s regedit.exe 注册表 找 WLMS [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WLMS] 启动类型由02（自动）改为04（禁用） 并修改加载的EXE位置  参考资料： https://www.cnblogs.com/CodingArt/articles/2264132.html https://my.oschina.net/yysue/blog/1796171\n","id":25,"section":"posts","summary":"👌 2019-09-12 Windows Server 2008 R2 已经激活但每隔一段时间自动关机 VMware 环境 原因： C:\\Windows\\system32\\wlms\\wlms.exe程序关闭的系统 处理方","tags":["Windows"],"title":"Windows Server 2008 R2 已经激活但每隔一段时间自动关机 VMware 环境","uri":"https://blog.standuke.top/2019/09/2019-09-12-windows-server-2008-r2-%E5%B7%B2%E7%BB%8F%E6%BF%80%E6%B4%BB%E4%BD%86%E6%AF%8F%E9%9A%94%E4%B8%80%E6%AE%B5%E6%97%B6%E9%97%B4%E8%87%AA%E5%8A%A8%E5%85%B3%E6%9C%BA-vmware-%E7%8E%AF%E5%A2%83/","year":"2019"},{"content":"👌 2019-08-07 macOS or Windows 压缩文件中文件夹中文编码原因导致无法解压  Unzip fail when zip contains chinese char on macOS\n 报错信息： unzip checkdir error cannot create illegal byte sequence  处理方案： 用 ditto 代替 unzip\nditto -V -x -k --sequesterRsrc --rsrc FILENAME.ZIP DESTINATIONDIRECTORY  参考资料： https://leadscloud.github.io/20190329/mac-unzip-Illegal-byte-sequence/ https://github.com/CocoaPods/CocoaPods/issues/7711\n","id":26,"section":"posts","summary":"👌 2019-08-07 macOS or Windows 压缩文件中文件夹中文编码原因导致无法解压 Unzip fail when zip contains chinese char on macOS 报错信息： unzip checkdir error cannot create illegal byte sequence 处理方案： 用 ditto 代替 unzip ditto -V -x -k --sequesterRsrc --rsrc FILENAME.ZIP DESTINATIONDIRECTORY 参考资料：","tags":["macOS","Windows"],"title":"macOS or Windows 压缩文件中文件夹中文编码原因导致无法解压","uri":"https://blog.standuke.top/2019/08/2019-08-07-macos-or-windows-%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6%E4%B8%AD%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E6%96%87%E7%BC%96%E7%A0%81%E5%8E%9F%E5%9B%A0%E5%AF%BC%E8%87%B4%E6%97%A0%E6%B3%95%E8%A7%A3%E5%8E%8B/","year":"2019"},{"content":"👌 2016-06-17 文件一致性 md5 校验  FileInfo Filename - 文件一致性 md5 校验 Version - v1.1.2105（2016/06/17 ~ 2021/05/14） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - File consistency md5 check\n 版本修订记录：\nv1.0.1606：2016-06-17：新建文档，修订人：standuke v1.1.2105：2021-05-14：测试新版系统下命令是否适用，修订人：standuke\n用途用法 用于校验文件是否一致，一般用于下载文件，文件下载后，本地运行 md5 校验得到的校验码与原始下载站上提供问文件校验码一致即代表两个文件一致。\nCentOS 环境 一般用 md5 值\nmd5sum 「file 文件拖进来」  🌰 示例用法与输出\n[Node1]# md5sum VMware-VCSA-all-6.7.0-14367737.iso dff12f195347a61a45d3aee3278ebfca VMware-VCSA-all-6.7.0-14367737.iso  Windows 环境 支持如下算法\nMD2 MD4 MD5 SHA1 SHA256 SHA384 SHA512\n用的算法自己替换即可 CentOS 下的 md5sum 对应 Windows 下的 MD5 certutil -hashfile 「file 文件拖进来」 MD5 certutil -hashfile 「file 文件拖进来」 SHA1 certutil -hashfile 「file 文件拖进来」 SHA256  🌰 示例用法与输出\nMicrosoft Windows [版本 10.0.18363.592] (c) 2019 Microsoft Corporation。保留所有权利。 C:\\Users\\Administrator\u0026gt;certutil -hashfile E:\\iso\\VMware-VCSA-all-6.7.0-14367737.iso md5 MD5 的 E:\\iso\\VMware-VCSA-all-6.7.0-14367737.iso 哈希: dff12f195347a61a45d3aee3278ebfca CertUtil: -hashfile 命令成功完成。  ","id":27,"section":"posts","summary":"👌 2016-06-17 文件一致性 md5 校验 FileInfo Filename - 文件一致性 md5 校验 Version - v1.1.2105（2016/06/17 ~ 2021/05/14） Author - standuke Email - shadowdoker@gmail.com DescriptionKey - File consistency md5 check 版本修","tags":["tools"],"title":"文件一致性 MD5 校验","uri":"https://blog.standuke.top/2016/06/2016-06-17-%E6%96%87%E4%BB%B6%E4%B8%80%E8%87%B4%E6%80%A7-md5-%E6%A0%A1%E9%AA%8C/","year":"2016"},{"content":"👌 2022-03-23 LDAP 企业部署实战 - LDAP 基础服务安装  FileInfo Filename - LDAP 企业部署实战 - LDAP 基础服务安装 Version - v1.0.2203（2022/03/25 ~ 2022/04/06） Author - nuo standuke Email - shadowdoker@gmail.com DescriptionKey - LDAP Enterprise Deployment Practice\n ⚠️ 注意：现有版本 openldap-servers-2.4.44-25.el7_9.x86_64 按照需要全程使用 CLI 操作配置，请勿直接修改 slapd.d 文件夹内的配置。目前网络上安装文档均为老版本，使用 ‘slapd.conf’ 进行配置，与新版本安装操作方式不一致「详见本文档 版本变化 部分」\n[TOC]\n简介 目前网络资源较少「真的很少、很老、很差」，建议大部分问题从官方文档寻找说明与解决方案。\n Wikipedia\n OpenLDAP 是轻型目录访问协议「Lightweight Directory Access Protocol，LDAP」的自由和开源的实现，在其 OpenLDAP 许可证下发行，并已经被包含在众多流行的 Linux 发行版中。 它主要包括下述 4 个部分：\n slapd - 独立 LDAP 守护服务 slurpd - 独立的 LDAP 更新复制守护服务 实现 LDAP 协议的库 工具软件和示例客户端  版本说明  CentOS 7.9-2009 系统源版本  openldap-2.4.44-25.el7_9.x86_64 openldap-servers-2.4.44-25.el7_9.x86_64 openldap-clients-2.4.44-25.el7_9.x86_64   最新官方版本「截止本文档发布日期」  OpenLDAP 2.6 (Released October 2021) Functional enhancements: slapd and lloadd File-based logging, including log file management capabilities (ITS#9492) Load Balancer enhancements Read affinity (ITS#9598) Additional balancing algorithms (ITS#9599)   下一次大版本更新「官方都没想过，老老实实用 2.* 版本吧」  OpenLDAP 3.0 (TBD) We're not thinking that far ahead right now.  ⚠️ 版本变化 这是本文章比较重要的一点，由官网可得目前 openldap 配置以及改为动态配置文件，由命令方式去修改配置文件，并且直接生效。同时，官方在每个配置文件内开头都注明了不要修改配置文件，以及配置文件的 CRC 校验。「OpenLDAP 2.3 及其以后版本，使用 cn=config 作为后端配置文件」\n⚠️ 不要手动修改配置，否则启动时 CRC 校验失败，导致 slapd.service 服务无法启动\n官方说明 https://www.openldap.org/doc/admin24/guide.html#Configuring%20slapd\n 官方说明文档  OpenLDAP 2.3 and later have transitioned to using a dynamic runtime configuration engine, slapd-config(5). slapd-config(5)   现有配置文件的开头说明「自带 CRC 校验，所以不要去改文件」  # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 7ee1beb6  官方说明地址  官方 release 版本路线说明  https://www.openldap.org/software/roadmap.html\n 官方源码下载地址  https://www.openldap.org/software/download/ https://www.openldap.org/software/download/OpenLDAP/openldap-release/\n基础概念 OpenLDAP 1.0「released August 1998」发布近 25 年，部分配置概念还是有些跟不上时代，但是理解后也能满足当下的业务需求。「主要还是 LDAP 能对接的系统太多了，不然折腾到现在我也不想弄」\nhttps://blog.csdn.net/liukuan73/article/details/78684710\n  数据库组织架构\n  DIT = Directory Information Tree 目录信息树，整一个 LDAP 数据库就是一个目录信息树\n  Enrty = 条目，可以理解为一条数据一个用户或组织，是 LDAP 中一个基本的存储单元；也可以被看作是一个 DN 和一组属性的集合。一条 entry 可以包含多个 objectClass，例如 zhang3 可以存在于 “电话薄” 中，也可以同时存在于 “同学录” 中。\n  DN = Distinguished Name 全局唯一的标识名，每一个条目 Entry 都可通过 DN 来唯一确定\n  RDN = Relative Distinguished Name 区分名或者相对区别名\n  Base DN = 一条 Base DN 可以是 “dc=expwd,dc=com”，也可以是“dc=People,dc=expwd,dc=com”。执行 LDAP Search 时一般要指定 basedn，由于 LDAP 是树状数据结构，指定 BaseDN 后，搜索将从 BaseDN 开始\n  🌰 例\nDN = uid=stan,ou=People,dc=expwd,dc=com RDN = uid=stan BaseDN = dc=expwd,dc=com Enrty = 条目「下方详解」\ndn: uid=stan,ou=People,dc=expwd,dc=com cn:: stan gidnumber: 5001 homedirectory: /home/users/stan loginshell: /bin/bash mail: stan@expwd.com objectclass: inetOrgPerson objectclass: posixAccount objectclass: shadowAccount sn: stan uid: stan uidnumber: 2000 userpassword: {SSHA}tIUzvYvE7YWxRRKCE0jC53vxdIwAt96k   Schema = LDAP 元数据模型「Schema」，也就是上面 Entry 的模板，模板定义了需要哪些数据，必填项等，Schema 会定义 Enrty 有哪些 objectClass 组成。 objectClass = 对象类「objectClass」是 LDAP 内置的数据模型，比如我们有一种叫“电话薄”的objectClass，肯定会内置很多属性(attributes)，如姓名(uid)，身份证号(uidNumber)，单位名称(gid)，家庭地址(homeDirectory)等，同时，还有一种叫“同学录”的objectClass，具备“电话薄”里的一些attributes(如uid、homeDirectory)，还会具有“电话薄”没有的attributes(如description等)。一个条目(Entry)必须包含一个对象类(objectClass)属性，且需要赋予至少一个值。每一个值将用作一条 LDAP 条目进行数据存储的模板；模板中包含了一个条目必须被赋值的属性和可选的属性。 inetOrgPerson = 对象类 inetOrgPerson（Internet Organizational Person）   一个条目的属性通过 LDAP 元数据模型（Schema）中的对象类（objectClass）所定义，下面的表格列举了对象类 inetOrgPerson（Internet Organizational Person）中的一些必填属性和可选属性。\n objectClass https://www.cnblogs.com/lfdblog/p/9803276.html\nLDAP中，一个条目必须包含一个 objectClass 属性，且需要赋予至少一个值。每一个值将用作一条 LDAP 条目进行数据存储的模板；模板中包含了一个条目必须被赋值的属性和可选的属性。objectClass 有着严格的等级之分，最顶层是 top 和 alias。例如，organizationalPerson 这个 objectClass 就隶属于person，而 person 又隶属于 top。\n文件 *.ldif = LDAP Data Interchange Format / LDAP 数据交换格式 「https://en.wikipedia.org/wiki/LDAP_Data_Interchange_Format 」 *.schema = LDAP 用户模板 「https://www.openldap.org/doc/admin23/schema.html 」\n节点「组织架构」  CN = Common Name OU = Organizational Unit DC = Domain Component  其他 OpenLDAP监听的端口：\n默认监听端口：389（明文数据传输，适用于启用了 StartTLS 的 LDAP）= OpenLDAP 不加密 / OpenLDAP over TLS 加密监听端口：636（密文数据传输，适用于启用了 SSL/TLS 的 LDAP）= OpenLDAP + SSL\n安装 OpenLDAP Server 初始化安装环境 卸载已有的 LDAP 环境 若前期已安装 LDAP 相关服务，建议首先备份导出 LDAP 数据后卸载 LDAP 程序\n# 关闭系统服务 systemctl stop slapd # 卸载软件包 ⚠️ 注意，不要卸载 系统的 openldap 包 yum remove compat-openldap openldap-clients openldap-servers # 移除配置文件 rm -rf /var/lib/ldap/* rm -rf /etc/openldap/slapd.d/*  置备操作系统环境 最小化安装的操作系统即可 建议配置完 DNS 以及主机和域名，方便接入域名系统  开始安装 使用 rpm 包安装 yum install openldap openldap-clients openldap-servers   openldap: 操作系统默认会安装此包，注意只能升级不能卸载。 openldap-clients: LDAP 的客户端，客户端必须要安装，内置 LDAP 操作的一些命令。 openldap-servers: LDAP 的服务端，服务端必须要安装，为 LDAP 的主程序，同时建议安装 openldap-clients 用于对服务端配置。  使用最新官方源码包安装  略，rpm 就已经够折腾的了\n 目录及配置文件介绍 涉及文件简介  /var/lib/ldap/ ldap 用户数据，所属用户所属组均为 ldap，故只有 ldap 用户才有读写权限。刚安装完时目录是空的 /etc/openldap openldap 的配置文件目录「所有 openldap 相关的配置都在此目录下，包括client 和 server 两者配置都这里」 /usr/sbin/slapd ldap 程序 /usr/share/openldap-servers/DB_CONFIG.example 模板 数据库配置文件 /usr/share/openldap-servers/slapd.ldif 模板 配置文件  每个 rpm 包涉及的配置文件如下\n[root@ldap-client ~]# rpm -qc openldap-clients 【空】 [root@ldap-server ~]# rpm -qc openldap # 系统默认会安装此包 /etc/openldap/ldap.conf # 此文件为 openldap rpm 包的配置文件 /usr/lib/tmpfiles.d/openldap.conf [root@ldap-server ~]# rpm -qc openldap-servers /etc/openldap/check_password.conf /etc/sysconfig/slapd /usr/lib/tmpfiles.d/slapd.conf # 部分文件详见下方「/etc/openldap 配置文件详解」部分  /etc/openldap 配置文件详解 [root@ldap-server openldap]# tree . ├── certs # TLS 密钥文件夹 cat /etc/openldap/slapd.d/cn\\=config.ldif 可见配置 │ ├── cert8.db │ ├── key3.db │ ├── password │ └── secmod.db ├── check_password.conf # 创建用户密码时的密码规则，OpenLDAP pwdChecker「check_password.so」库配置 ├── ldap.conf # 此文件为 openldap-client rpm 包的配置文件，里面会配置 /etc/openldap/certs 密钥文件夹地址 ├── schema # OpenLDAP 的 schema 存放的地方，可以理解为模板 │ ├── collective.ldif │ ├── collective.schema │ ├── corba.ldif │ ├── corba.schema │ ├── core.ldif │ ├── core.schema │ ├── cosine.ldif │ ├── cosine.schema │ ├── duaconf.ldif │ ├── duaconf.schema │ ├── dyngroup.ldif │ ├── dyngroup.schema │ ├── inetorgperson.ldif │ ├── inetorgperson.schema │ ├── java.ldif │ ├── java.schema │ ├── misc.ldif │ ├── misc.schema │ ├── nis.ldif │ ├── nis.schema │ ├── openldap.ldif │ ├── openldap.schema │ ├── pmi.ldif │ ├── pmi.schema │ ├── ppolicy.ldif │ └── ppolicy.schema └── slapd.d # 安装完 server 端后默认的 server 配置文件，后续新增的模块会增加在这个目录下 ├── cn=config # 核心配置文件，可以配置域名(olcSuffix)，管理员账号(olcRootDN)等 │ ├── cn=schema # LDAP 导入的模板文件夹，导入模板后才会出现在这里 │ │ └── cn={0}core.ldif # LDAP 安装后默认会有 core 模块 │ ├── cn=schema.ldif │ ├── olcDatabase={0}config.ldif # 文件名和字段名都有前缀\u0026quot;olc\u0026quot;(OpenLDAP Configuration) │ ├── olcDatabase={-1}frontend.ldif │ ├── olcDatabase={1}monitor.ldif │ └── olcDatabase={2}hdb.ldif # 后端数据库配置文件 └── cn=config.ldif 5 directories, 39 files  开始配置 第一步 直接启动 slapd 服务，是的，启动后再进行配置，也不要按照网上去拷贝数据库什么的，直接启动即可\n# 启动 ldap systemctl start slapd # 开机使能 ldap systemctl enable slapd # 查看 ldap 服务状态 systemctl status slapd  开始进行配置 默认安装完 LDAP Server 后启动的是默认配置，依照官方说法，我们需要使用 ldapmodify 来修改默认配置来满足我们生产环境需求\n 建议首先修改 rootDN，rootDN 是 DN 的根，是后续一切的基础。  vim stan.ldif dn: olcDatabase={2}hdb,cn=config # 数据库类型文件要按照自己的数据库版本修改 changetype: modify # 操作类型是修改 replace: olcRootDN # 操作目标为重置 RootDN olcRootDN: cn=admin,dc=expwd,dc=com # 替换为自己的根域 - replace: olcSuffix # 操作目标为重置 Suffix olcSuffix: dc=expwd,dc=com # 替换为自己的根域  这边 olcDatabase={2}hdb 文件是 LDAP 数据库配置文件，不同发型版本用的数据库可能不同，这里需要修改 olcDatabase={2}hdb 为实际的文件，文件路径为 /etc/openldap/slapd.d/cn=config/olcDatabase={2}hdb.ldif ，这里实际文件可能是 bdb，也可能是 mdb，详细可见附录「关于 mdb hdb bdb 后端数据库」部分解释。\n使用 ldapmodify 来配置文件生效  ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f stan.ldif  同理给 RootDN 的 admin 用户重设密码  设置完密码后就可以通过 LDAP 管理软件使用 admin 的 dn 和密码登陆。 参考链接，文章内讲的比较详细，包括如何找到 RootDN 信息等。 https://www.digitalocean.com/community/tutorials/how-to-change-account-passwords-on-an-openldap-server#changing-the-rootdn-password\nvim stan-pwd.ldif dn: olcDatabase={2}hdb,cn=config #olcRootDN: cn=admin,dc=expwd,dc=com changetype: modify replace: olcRootPW olcRootPW: {SSHA}AOvsPeLZYEpxBA8sdY2r9DSeZkuxlxxg  ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f stan-pwd.ldif  注：其实只要把修改 RootDN 那一步的配置文件改成如下即可，一次性就能改完\nvim stan.ldif dn: olcDatabase={2}hdb,cn=config # 数据库类型文件要按照自己的数据库版本修改 changetype: modify # 操作类型是修改 replace: olcRootDN # 操作目标为重置 RootDN olcRootDN: cn=admin,dc=expwd,dc=com # 替换为自己的根域 - replace: olcSuffix # 操作目标为重置 Suffix olcSuffix: dc=expwd,dc=com # 替换为自己的根域 - replace: olcRootPW olcRootPW: {SSHA}AOvsPeLZYEpxBA8sdY2r9DSeZkuxlxxg   到这一步建议安装先一下 phpldapadmin，也可以跳过后去再装，因为后期的命令行操作可以直观地在网页上看到目前 LDAP 的状态  导入自带 Schema ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif   为什么要先导入这几个模块呢？因为下面的 memberOf 模块要用 🤪\n 初始化基础目录结构 vim stan-user.ldif dn: dc=expwd,dc=com objectClass: dcObject objectClass: organization o: expwd.com dc: expwd dn: ou=users,dc=expwd,dc=com objectClass: organizationalUnit objectClass: top ou: users dn: ou=groups,dc=expwd,dc=com objectClass: organizationalUnit objectClass: top ou: groups  ldapadd -x -W -D \u0026quot;cn=admin,dc=expwd,dc=com\u0026quot; -f stan-user.ldif   导入完成后目录结构是这样的  安装完毕 🎉 至此，基础的 LDAP 服务已全部安装完毕，建议继续添加一些模块并且设计好整一个 LDAP 的目录结构，避免后期因为设计不合理的大规模迁移调整。\n添加 memberOf 模块 目前有很多第三方应用、云平台的 LDAP 配置需要检查这个属性，memberOf 模块的作用是，当你建一个组的时候，把一些用户添加到这个组里去，它会自动给这些用户添加一个 memberOf 属性。\n add-memberof.ldif  [root@ldap-server memberof]# cat add-memberof.ldif # 开启 memberof 支持 dn: cn=module{0},cn=config cn: modulle{0} objectClass: olcModuleList objectclass: top olcModuleload: memberof.la olcModulePath: /usr/lib64/openldap # 新增用户支持 memberof 配置 dn: olcOverlay={0}memberof,olcDatabase={2}hdb,cn=config objectClass: olcConfig objectClass: olcMemberOf objectClass: olcOverlayConfig objectClass: top olcOverlay: memberof olcMemberOfDangling: ignore olcMemberOfRefInt: TRUE olcMemberOfGroupOC: groupOfUniqueNames olcMemberOfMemberAD: uniqueMember olcMemberOfMemberOfAD: memberOf   refint1.ldif  [root@ldap-server memberof]# cat refint1.ldif dn: cn=module{0},cn=config add: olcmoduleload olcmoduleload: refint   refint2.ldif  [root@ldap-server memberof]# cat refint2.ldif dn: olcOverlay=refint,olcDatabase={2}hdb,cn=config objectClass: olcConfig objectClass: olcOverlayConfig objectClass: olcRefintConfig objectClass: top olcOverlay: refint olcRefintAttribute: memberof uniqueMember manager owner   使用命令将模块导入 LDAP  ldapadd -Q -Y EXTERNAL -H ldapi:/// -f add-memberof.ldif ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f refint1.ldif ldapadd -Q -Y EXTERNAL -H ldapi:/// -f refint2.ldif   检查模块是否生效  ldapsearch -Q -LLL -Y EXTERNAL -H ldapi:/// -b cn=config dn  一些管理工具 安装 phpldapadmin 简介 phpldapadmin 是使用 php 语言开发的 web 端管理 ldap 的应用。 不同操作系统建议先看下官方安装方式后进行安装。 http://phpldapadmin.sourceforge.net/wiki/index.php/Download https://sourceforge.net/projects/phpldapadmin/files/\n安装「CentOS 7 环境」 这里采用 httpd + php + phpldapadmin 的安装方案，当然也可以使用 nginx 作为 Web 容器。\nyum install -y httpd yum install -y epel-release # CentOS 7 yum install -y phpldapadmin # yum install -y php php-ldap php-gd php-mbstring php-pear php-bcmath php-xml # 不需要装 php，在安装 phpldapadmin 的时候会自行解决依赖 =============================================================================================== Package 架构 版本 源 大小 =============================================================================================== 正在安装: phpldapadmin noarch 1.2.5-1.el7 epel 797 k 为依赖而安装: libzip x86_64 0.10.1-8.el7 base 48 k php x86_64 5.4.16-48.el7 base 1.4 M php-cli x86_64 5.4.16-48.el7 base 2.7 M php-common x86_64 5.4.16-48.el7 base 565 k php-ldap x86_64 5.4.16-48.el7 base 53 k 事务概要 =============================================================================================== 安装 1 软件包 (+5 依赖软件包)  需要修改的配置文件\n[root@ldap-client ~]# rpm -qc phpldapadmin-1.2.5-1.el7.noarch /etc/httpd/conf.d/phpldapadmin.conf /etc/phpldapadmin/config.php   /etc/httpd/conf.d/phpldapadmin.conf  # cat /etc/httpd/conf.d/phpldapadmin.conf # # Web-based tool for managing LDAP servers # Alias /phpldapadmin /usr/share/phpldapadmin/htdocs Alias /ldapadmin /usr/share/phpldapadmin/htdocs \u0026lt;Directory /usr/share/phpldapadmin/htdocs\u0026gt; \u0026lt;IfModule mod_authz_core.c\u0026gt; # Apache 2.4 Require local Require all granted # 加这一行 \u0026lt;/IfModule\u0026gt; \u0026lt;IfModule !mod_authz_core.c\u0026gt; # Apache 2.2 Order Deny,Allow Deny from all Allow from 127.0.0.1 Allow from ::1 \u0026lt;/IfModule\u0026gt; \u0026lt;/Directory\u0026gt;   /etc/phpldapadmin/config.php  # 其实不需要这么配置，只就是能使用 # 下方参数只是把登陆的用户名从 uid 改为使用 dn 方式登陆了 $servers-\u0026gt;setValue('login','attr','dn'); //$servers-\u0026gt;setValue('login','attr','uid'); 把$servers-\u0026gt;setValue('login','anon_bind',false);改成false，因为我们不想让人匿名访问； 把$servers-\u0026gt;setValue('login','allowed_dns',array('cn=admin,dc=qiban,dc=com'));，我们只允许管理员访问，其他任何人不得访问。  启动 systemctl restart httpd  安装 Self Service Password 简介 Self Service Password 是一个 Web 应用，可以让用户自行更新、修改和重置 LDAP 中的用户密码。支持标准的 LDAPv3 目录服务，包括：OpenLDAP,Active Directory,OpenDS,ApacheDS等。 https://github.com/ltb-project/self-service-password https://self-service-password.readthedocs.io/en/latest/installation.html\n安装「CentOS 7 环境」  配置 yum 源  vi /etc/yum.repos.d/ltb-project.repo [ltb-project-noarch] name=LTB project packages (noarch) baseurl=https://ltb-project.org/rpm/$releasever/noarch enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-LTB-project   使用 yum 进行安装  # yum update # 可省略 rpm --import https://ltb-project.org/wiki/lib/RPM-GPG-KEY-LTB-project yum install self-service-password ======================================================================= Package 架构 版本 源 大小 ======================================================================= 正在安装: self-service-password noarch 1.4.3-1.el7 ltb-project-noarch 2.3 M 为依赖而安装: libX11 x86_64 1.6.7-4.el7_9 updates 607 k libX11-common noarch 1.6.7-4.el7_9 updates 164 k libXau x86_64 1.0.8-2.1.el7 base 29 k libXpm x86_64 3.5.12-1.el7 base 55 k libjpeg-turbo x86_64 1.2.90-8.el7 base 135 k libxcb x86_64 1.13-1.el7 base 214 k php-Smarty noarch 3.1.33-1.el7 epel 238 k php-gd x86_64 5.4.16-48.el7 base 128 k php-mbstring x86_64 5.4.16-48.el7 base 506 k t1lib x86_64 5.1.2-14.el7 base 166 k 事务概要 ======================================================================= 安装 1 软件包 (+10 依赖软件包)  修改需要的配置文件\nrpm -qc self-service-password.noarch 0:1.4.3-1.el7 /etc/httpd/conf.d/self-service-password.conf /usr/share/self-service-password/conf/config.inc.php   /usr/share/self-service-password/conf/config.inc.php  # LDAP $ldap_url = \u0026quot;ldaps://localhost:636\u0026quot;; $ldap_starttls = false; $ldap_binddn = \u0026quot;cn=admin,dc=expwd,dc=com\u0026quot;; $ldap_bindpw = \u0026quot;12345678900\u0026quot;; $ldap_base = \u0026quot;dc=expwd,dc=com\u0026quot;; $ldap_login_attribute = \u0026quot;uid\u0026quot;; $ldap_fullname_attribute = \u0026quot;cn\u0026quot;; # 此处配置要和上面 LDAP 登陆配置一致，我这边上面是 dn $ldap_filter = \u0026quot;(\u0026amp;(objectClass=person)($ldap_login_attribute={login}))\u0026quot;; ## Mail # 必须要配置成功 Mail 才能访问到网页 ## Mail # LDAP mail attribute $mail_attribute = \u0026quot;mail\u0026quot;; # Get mail address directly from LDAP (only first mail entry) # and hide mail input field # default = false $mail_address_use_ldap = false; # Who the email should come from $mail_from = \u0026quot;admin@expwd.com\u0026quot;; $mail_from_name = \u0026quot;Self Service Password\u0026quot;; $mail_signature = \u0026quot;\u0026quot;; # Notify users anytime their password is changed $notify_on_change = false; # PHPMailer configuration (see https://github.com/PHPMailer/PHPMailer) $mail_sendmailpath = '/usr/sbin/sendmail'; $mail_protocol = 'smtp'; $mail_smtp_debug = 0; $mail_debug_format = 'error_log'; $mail_smtp_host = 'localhost'; $mail_smtp_auth = false; $mail_smtp_user = 'admin@expwd.com'; $mail_smtp_pass = '12121212'; $mail_smtp_port = 25; $mail_smtp_timeout = 30; $mail_smtp_keepalive = false; $mail_smtp_secure = 'tls'; $mail_smtp_autotls = true; $mail_smtp_options = array(); $mail_contenttype = 'text/plain'; $mail_wordwrap = 0; $mail_charset = 'utf-8'; $mail_priority = 3;  /etc/httpd/conf.d/self-service-password.conf  无需修改  启动 必须要配置成功 Mail 才能访问到网页\nsystemctl start httpd  macOS 安装 ApacheDirectoryStudio 简介 Apache Directory Studio 是一个 LDAP 的工具平台，用来连接到任何 LDAP 服务器并进行管理和开发工作。 主要功能：LDAP浏览器、LDIF编辑器、嵌入式 ApacheDS、ACI编辑器。\n macOS version 10.10 (Yosemite) or later. Java 11 or later, we recommend AdoptOpenJDK.\n https://directory.apache.org/studio/ https://directory.apache.org/studio/downloads.html\n安装 建议使用 brew 安装 temurin「jdk17」，如果已经在使用 Eclipse 的用户，直接加载 Eclipse 插件就可以了\nbrew install --cask temurin brew install apache-directory-studio  之后就是图形化的一些操作了\nldapscripts 辅助脚本 https://github.com/martymac/ldapscripts\n用于脚本快速创建 Unix 用户，看一眼就会用\nLDAP TOOL BOX https://ltb-project.org/download.html#self_service_password\n附录 导入基本 scheme ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/collective.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/corba.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/duaconf.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/dyngroup.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/java.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/misc.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/openldap.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/pmi.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/ppolicy.ldif  关于 mdb hdb bdb 后端数据库 hdb 后端已取代 bdb 后端，同时两者很快也会弃用，取而代之的是新的 mdb 后端，原因是 Oracle 更改了许可，删除了 BDB 6 及更高版本与 OpenLDAP 软件的兼容性。\n升级到 mdb - Upgrade-from-BDB-HDB-to-MDB\nhttps://www.openldap.org/faq/data/cache/756.html\nback-mdb is the \u0026quot;primary\u0026quot; storage database backend. This backend manages directory objects in an embedded database and is more fully featured than other backends. back-mdb is superior to the deprecated back-hdb and back-bdb backends. back-bdb and back-hdb are deprecated backends based on BerkeleyDB.  https://www.openldap.org/doc/admin24/backends.html\nThe hdb backend has superseded the bdb backend, and both will soon be deprecated in favor of the new mdb backend. See below.  关于 scheme 与操作系统用户之间的映射 可搜索「RFC4519 rfc2307bis.ldif」相关标准解释，相关标准已在操作系统中默认做好用户与组的映射关系匹配。\n相关常用操作  由于此篇文章已经很长了，操作及使用相关的命令后期再写文章细说\n slapd ldapmodify ldapadd ldapsearch 参考资料 「Openldap 安装使用」 https://www.cnblogs.com/fan-yi/p/14915041.html 「我花了一个五一终于搞懂了OpenLDAP」 https://segmentfault.com/a/1190000014683418 「内部ldap实践」这篇文章里面手动修改配置文件了，不可取，只做参考 https://1661691223.github.io/2019/11/15/ldap-train/ 「OpenLDAP安装与配置」这篇文章里面手动修改配置文件了，不可取，只做参考 https://www.cnblogs.com/js1314/p/12887893.html 「How To Change Account Passwords on an OpenLDAP Server」 https://www.digitalocean.com/community/tutorials/how-to-change-account-passwords-on-an-openldap-server#changing-the-rootdn-password 「LDAP(一)之概念原理介绍」 https://www.jianshu.com/p/27ab7a5d56a4 「Centos7 搭建openldap完整详细教程(真实可用)」 https://www.cnblogs.com/jiligalaer/p/13300371.html https://blog.csdn.net/weixin_41004350/article/details/89521170 https://blog.csdn.net/weixin_41004350?type=blog 「如何在OpenLDAP启用MemberOf」 https://blog.csdn.net/qq_23191379/article/details/106867730 「LDAP添加 memberOf 模块」 https://blog.csdn.net/u011607971/article/details/119037796 https://cloud.tencent.com/developer/article/1349459 「Server:server:tls」 http://phpldapadmin.sourceforge.net/wiki/index.php/Server:server:tls 「Lightweight Directory Access Protocol (LDAP):Schema for User Applications」里面详细描述了一个 rfc4519 标准 RDN 各个字段的含义 https://www.ietf.org/rfc/rfc4519.txt 「LDAP学习笔记总结」 https://www.cnblogs.com/kevingrace/p/5773974.html 「# Chapter 6. LDAP Configuration」 https://www.zytrax.com/books/ldap/ch6/#list 「# Chapter 6.1.1: OpenLDAP using OLC (cn=config)」 https://www.zytrax.com/books/ldap/ch6/slapd-config.html#use\n","id":28,"section":"posts","summary":"👌 2022-03-23 LDAP 企业部署实战 - LDAP 基础服务安装 FileInfo Filename - LDAP 企业部署实战 - LDAP 基础服务安装 Version - v1.0.2203（2022/03/25 ~ 2022/04/06） Author","tags":null,"title":"","uri":"https://blog.standuke.top/1/01/2022-03-23-ldap-%E4%BC%81%E4%B8%9A%E9%83%A8%E7%BD%B2%E5%AE%9E%E6%88%98/","year":"0001"}],"tags":[{"title":"Aliyun","uri":"https://blog.standuke.top/tags/aliyun/"},{"title":"Bigdata","uri":"https://blog.standuke.top/tags/bigdata/"},{"title":"CDH","uri":"https://blog.standuke.top/tags/cdh/"},{"title":"CentOS","uri":"https://blog.standuke.top/tags/centos/"},{"title":"Cloudera","uri":"https://blog.standuke.top/tags/cloudera/"},{"title":"docker","uri":"https://blog.standuke.top/tags/docker/"},{"title":"EIP","uri":"https://blog.standuke.top/tags/eip/"},{"title":"ESXi","uri":"https://blog.standuke.top/tags/esxi/"},{"title":"frp","uri":"https://blog.standuke.top/tags/frp/"},{"title":"KVM","uri":"https://blog.standuke.top/tags/kvm/"},{"title":"Linux","uri":"https://blog.standuke.top/tags/linux/"},{"title":"Linux Bridge","uri":"https://blog.standuke.top/tags/linux-bridge/"},{"title":"macOS","uri":"https://blog.standuke.top/tags/macos/"},{"title":"Markdown","uri":"https://blog.standuke.top/tags/markdown/"},{"title":"Network","uri":"https://blog.standuke.top/tags/network/"},{"title":"OpenStack","uri":"https://blog.standuke.top/tags/openstack/"},{"title":"PXE","uri":"https://blog.standuke.top/tags/pxe/"},{"title":"qcow2","uri":"https://blog.standuke.top/tags/qcow2/"},{"title":"system","uri":"https://blog.standuke.top/tags/system/"},{"title":"Time Machine","uri":"https://blog.standuke.top/tags/time-machine/"},{"title":"tools","uri":"https://blog.standuke.top/tags/tools/"},{"title":"vCenter","uri":"https://blog.standuke.top/tags/vcenter/"},{"title":"Virtualization","uri":"https://blog.standuke.top/tags/virtualization/"},{"title":"vSphere","uri":"https://blog.standuke.top/tags/vsphere/"},{"title":"Windows","uri":"https://blog.standuke.top/tags/windows/"}]}